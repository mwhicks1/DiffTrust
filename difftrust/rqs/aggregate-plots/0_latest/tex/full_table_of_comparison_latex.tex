\begin{table*}\scriptsize
\begin{tabular}{llllll}
\toprule
\textbf{Model} & \textbf{Raw Err Mean} & \textbf{Raw Dis Mean} & \textbf{Spearman Rho err vs. diss} & \textbf{Detection Rate (Detected / Errors)} & \textbf{Error Mean When Confident}\\
\midrule
\textbf{MBPP} &  &  &  &  &  & \\
LLaMA 4 Maverick 17B & 0.2980 & 0.0680 & 0.4291 & 0.4741 & 0.2352\\
GPT-o4 Mini & 0.3109 & 0.1045 & 0.5646 & 0.7543 & 0.1784\\
Claude 4 Sonnet & 0.2693 & 0.0452 & 0.4151 & 0.4016 & 0.2150\\
Claude 4 Opus & 0.2715 & 0.0583 & 0.4508 & 0.4815 & 0.2140\\
Gemini 1.5 Pro & 0.2960 & 0.0995 & 0.5276 & 0.6866 & 0.2071\\
DeepSeek-Coder R1 & 0.2286 & 0.0811 & 0.5650 & 0.6453 & 0.1640\\
GPT-4 Turbo & 0.2825 & 0.1195 & 0.6186 & 0.7249 & 0.1556\\
LLaMA 3 8B Instruct & 0.4022 & 0.2978 & 0.6509 & 0.9427 & 0.1544\\
LLaMA 3 70B Instruct & 0.3574 & 0.1689 & 0.5419 & 0.8139 & 0.2288\\
GPT-4o & 0.2773 & 0.1123 & 0.6105 & 0.7243 & 0.1638\\
Gemini 2.0 Flash Lite & 0.2913 & 0.1097 & 0.6237 & 0.6782 & 0.1586\\
Gemini 1.5 Flash & 0.2949 & 0.0936 & 0.5216 & 0.7122 & 0.2183\\
DeepSeek-V3 (Mar 2024) & 0.2659 & 0.1185 & 0.6112 & 0.7406 & 0.1555\\
Mistral 8B & 0.3741 & 0.1641 & 0.5892 & 0.7037 & 0.2107\\
GPT-3.5 & 0.3041 & 0.1334 & 0.6115 & 0.7027 & 0.1698\\
GPT-4 & 0.2906 & 0.1511 & 0.6619 & 0.7840 & 0.1570\\
\textbf{MBPP (Mean)} & 0.3009 & 0.1203 & 0.5621 & 0.6857 & 0.1866\\
\midrule
\textbf{HumanEval} &  &  &  &  &  & \\
LLaMA 4 Maverick 17B & 0.0876 & 0.0367 & 0.6242 & 0.5397 & 0.0583\\
GPT-o4 Mini & 0.0893 & 0.0388 & 0.7092 & 0.7051 & 0.0420\\
Claude 4 Sonnet & 0.0605 & 0.0076 & 0.4098 & 0.2778 & 0.0533\\
Claude 4 Opus & 0.0632 & 0.0067 & 0.4041 & 0.3000 & 0.0601\\
Gemini 1.5 Pro & 0.0763 & 0.0295 & 0.7171 & 0.7188 & 0.0417\\
DeepSeek-Coder R1 & 0.0724 & 0.0356 & 0.7994 & 0.7538 & 0.0180\\
GPT-4 Turbo & 0.0912 & 0.0477 & 0.7528 & 0.7606 & 0.0398\\
LLaMA 3 8B Instruct & 0.2140 & 0.1954 & 0.8890 & 0.9245 & 0.0261\\
LLaMA 3 70B Instruct & 0.1223 & 0.0928 & 0.8173 & 0.8395 & 0.0314\\
GPT-4o & 0.0927 & 0.0483 & 0.7181 & 0.7042 & 0.0460\\
Gemini 2.0 Flash Lite & 0.1165 & 0.0343 & 0.4829 & 0.4118 & 0.0851\\
Gemini 1.5 Flash & 0.0796 & 0.0347 & 0.7584 & 0.7538 & 0.0339\\
DeepSeek-V3 (Mar 2024) & 0.0781 & 0.0235 & 0.5346 & 0.4576 & 0.0552\\
Mistral 8B & 0.1585 & 0.0911 & 0.7282 & 0.7381 & 0.0737\\
GPT-3.5 & 0.1635 & 0.0906 & 0.8192 & 0.8537 & 0.0458\\
GPT-4 & 0.1144 & 0.0823 & 0.8127 & 0.8471 & 0.0424\\
\textbf{HumanEval (Mean)} & 0.1050 & 0.0560 & 0.6861 & 0.6616 & 0.0471\\
\bottomrule
\end{tabular}
\caption{\todo{Add caption.}}
\label{tab:rq1_full}
\end{table*}