[
  {
    "name": "has_close_elements",
    "task_id": "HumanEval/0",
    "Dis": 0.0,
    "Err": 0.0574,
    "TotalTime": 3.0352983474731445
  },
  {
    "name": "separate_paren_groups",
    "task_id": "HumanEval/1",
    "Dis": 0.3792,
    "Err": 0.3084,
    "TotalTime": 2.211261034011841
  },
  {
    "name": "truncate_number",
    "task_id": "HumanEval/2",
    "Dis": 0.0452,
    "Err": 0.228,
    "TotalTime": 1.7181336879730225
  },
  {
    "name": "below_zero",
    "task_id": "HumanEval/3",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.7550277709960938
  },
  {
    "name": "mean_absolute_deviation",
    "task_id": "HumanEval/4",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.0386970043182373
  },
  {
    "name": "intersperse",
    "task_id": "HumanEval/5",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.4759397506713867
  },
  {
    "name": "parse_nested_parens",
    "task_id": "HumanEval/6",
    "Dis": 0.0512,
    "Err": 0.3892,
    "TotalTime": 2.1343414783477783
  },
  {
    "name": "filter_by_substring",
    "task_id": "HumanEval/7",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.787370204925537
  },
  {
    "name": "sum_product",
    "task_id": "HumanEval/8",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.6936614513397217
  },
  {
    "name": "rolling_max",
    "task_id": "HumanEval/9",
    "Dis": 0.0386,
    "Err": 0.0622,
    "TotalTime": 2.633413791656494
  },
  {
    "name": "make_palindrome",
    "task_id": "HumanEval/10",
    "Dis": 0.0102,
    "Err": 0.0054,
    "TotalTime": 2.3342554569244385
  },
  {
    "name": "string_xor",
    "task_id": "HumanEval/11",
    "Dis": 0.197,
    "Err": 0.9832,
    "TotalTime": 2.8183653354644775
  },
  {
    "name": "longest",
    "task_id": "HumanEval/12",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.065079927444458
  },
  {
    "name": "greatest_common_divisor",
    "task_id": "HumanEval/13",
    "Dis": 0.0902,
    "Err": 0.1326,
    "TotalTime": 1.8377058506011963
  },
  {
    "name": "all_prefixes",
    "task_id": "HumanEval/14",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.1275956630706787
  },
  {
    "name": "string_sequence",
    "task_id": "HumanEval/15",
    "Dis": 0.203,
    "Err": 0.103,
    "TotalTime": 1.6473665237426758
  },
  {
    "name": "count_distinct_characters",
    "task_id": "HumanEval/16",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.0628724098205566
  },
  {
    "name": "parse_music",
    "task_id": "HumanEval/17",
    "Dis": 0.6178,
    "Err": 0.562,
    "TotalTime": 4.28413462638855
  },
  {
    "name": "how_many_times",
    "task_id": "HumanEval/18",
    "Dis": 0.0118,
    "Err": 0.0684,
    "TotalTime": 2.5750155448913574
  },
  {
    "name": "sort_numbers",
    "task_id": "HumanEval/19",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 6.148743391036987
  },
  {
    "name": "find_closest_elements",
    "task_id": "HumanEval/20",
    "Dis": 0.1962,
    "Err": 0.1046,
    "TotalTime": 2.8063647747039795
  },
  {
    "name": "rescale_to_unit",
    "task_id": "HumanEval/21",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.869948625564575
  },
  {
    "name": "filter_integers",
    "task_id": "HumanEval/22",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.6710851192474365
  },
  {
    "name": "strlen",
    "task_id": "HumanEval/23",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.9328432083129883
  },
  {
    "name": "largest_divisor",
    "task_id": "HumanEval/24",
    "Dis": 0.1186,
    "Err": 0.0976,
    "TotalTime": 1.6035223007202148
  },
  {
    "name": "factorize",
    "task_id": "HumanEval/25",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 17.885398149490356
  },
  {
    "name": "remove_duplicates",
    "task_id": "HumanEval/26",
    "Dis": 0.0912,
    "Err": 0.048,
    "TotalTime": 2.687026023864746
  },
  {
    "name": "flip_case",
    "task_id": "HumanEval/27",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.014146327972412
  },
  {
    "name": "concatenate",
    "task_id": "HumanEval/28",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.3050622940063477
  },
  {
    "name": "filter_by_prefix",
    "task_id": "HumanEval/29",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.410521507263184
  },
  {
    "name": "get_positive",
    "task_id": "HumanEval/30",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.8352394104003906
  },
  {
    "name": "is_prime",
    "task_id": "HumanEval/31",
    "Dis": 0.1962,
    "Err": 0.106,
    "TotalTime": 2.698253870010376
  },
  {
    "name": "unique",
    "task_id": "HumanEval/34",
    "Dis": 0.1878,
    "Err": 0.0974,
    "TotalTime": 2.883915901184082
  },
  {
    "name": "max_element",
    "task_id": "HumanEval/35",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.7288613319396973
  },
  {
    "name": "sort_even",
    "task_id": "HumanEval/37",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.960286855697632
  },
  {
    "name": "triples_sum_to_zero",
    "task_id": "HumanEval/40",
    "Dis": 0.0166,
    "Err": 0.0126,
    "TotalTime": 2.681293249130249
  },
  {
    "name": "car_race_collision",
    "task_id": "HumanEval/41",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.6592438220977783
  },
  {
    "name": "incr_list",
    "task_id": "HumanEval/42",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.8460891246795654
  },
  {
    "name": "pairs_sum_to_zero",
    "task_id": "HumanEval/43",
    "Dis": 0.0068,
    "Err": 0.03,
    "TotalTime": 2.6780076026916504
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/45",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.8248751163482666
  },
  {
    "name": "fib4",
    "task_id": "HumanEval/46",
    "Dis": 0.1674,
    "Err": 0.1042,
    "TotalTime": 1.803295612335205
  },
  {
    "name": "median",
    "task_id": "HumanEval/47",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.733978509902954
  },
  {
    "name": "is_palindrome",
    "task_id": "HumanEval/48",
    "Dis": 0.0062,
    "Err": 0.0094,
    "TotalTime": 2.037290573120117
  },
  {
    "name": "modp",
    "task_id": "HumanEval/49",
    "Dis": 0.0444,
    "Err": 0.18,
    "TotalTime": 1.9804141521453857
  },
  {
    "name": "remove_vowels",
    "task_id": "HumanEval/51",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.1058309078216553
  },
  {
    "name": "below_threshold",
    "task_id": "HumanEval/52",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.8125836849212646
  },
  {
    "name": "add",
    "task_id": "HumanEval/53",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.7652559280395508
  },
  {
    "name": "same_chars",
    "task_id": "HumanEval/54",
    "Dis": 0.0024,
    "Err": 0.0022,
    "TotalTime": 2.5947494506835938
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/56",
    "Dis": 0.0,
    "Err": 0.4102,
    "TotalTime": 2.038478136062622
  },
  {
    "name": "monotonic",
    "task_id": "HumanEval/57",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.6094791889190674
  },
  {
    "name": "common",
    "task_id": "HumanEval/58",
    "Dis": 0.0,
    "Err": 0.3702,
    "TotalTime": 3.2088351249694824
  },
  {
    "name": "largest_prime_factor",
    "task_id": "HumanEval/59",
    "Dis": 0.2594,
    "Err": 0.2092,
    "TotalTime": 6.7306859493255615
  },
  {
    "name": "sum_to_n",
    "task_id": "HumanEval/60",
    "Dis": 0.0,
    "Err": 0.2046,
    "TotalTime": 1.647127389907837
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/61",
    "Dis": 0.0,
    "Err": 0.4094,
    "TotalTime": 2.076017379760742
  },
  {
    "name": "derivative",
    "task_id": "HumanEval/62",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.499295949935913
  },
  {
    "name": "vowels_count",
    "task_id": "HumanEval/64",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.2150535583496094
  },
  {
    "name": "circular_shift",
    "task_id": "HumanEval/65",
    "Dis": 0.1546,
    "Err": 0.3518,
    "TotalTime": 2.019752264022827
  },
  {
    "name": "digitSum",
    "task_id": "HumanEval/66",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.9911510944366455
  },
  {
    "name": "fruit_distribution",
    "task_id": "HumanEval/67",
    "Dis": 0.4478,
    "Err": 0.531,
    "TotalTime": 2.4757542610168457
  },
  {
    "name": "pluck",
    "task_id": "HumanEval/68",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.58602237701416
  },
  {
    "name": "search",
    "task_id": "HumanEval/69",
    "Dis": 0.0772,
    "Err": 0.1482,
    "TotalTime": 3.266369104385376
  },
  {
    "name": "strange_sort_list",
    "task_id": "HumanEval/70",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.508632183074951
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/71",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.9582509994506836
  },
  {
    "name": "will_it_fly",
    "task_id": "HumanEval/72",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.827934741973877
  },
  {
    "name": "smallest_change",
    "task_id": "HumanEval/73",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.3043158054351807
  },
  {
    "name": "total_match",
    "task_id": "HumanEval/74",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 5.235105514526367
  },
  {
    "name": "iscube",
    "task_id": "HumanEval/77",
    "Dis": 0.2006,
    "Err": 0.0972,
    "TotalTime": 1.5849294662475586
  },
  {
    "name": "hex_key",
    "task_id": "HumanEval/78",
    "Dis": 0.288,
    "Err": 0.4608,
    "TotalTime": 2.6753480434417725
  },
  {
    "name": "decimal_to_binary",
    "task_id": "HumanEval/79",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.6029167175292969
  },
  {
    "name": "is_happy",
    "task_id": "HumanEval/80",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.970463514328003
  },
  {
    "name": "numerical_letter_grade",
    "task_id": "HumanEval/81",
    "Dis": 0.3068,
    "Err": 0.1596,
    "TotalTime": 2.764387369155884
  },
  {
    "name": "prime_length",
    "task_id": "HumanEval/82",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.2739131450653076
  },
  {
    "name": "starts_one_ends",
    "task_id": "HumanEval/83",
    "Dis": 0.9308,
    "Err": 0.798,
    "TotalTime": 2.434115171432495
  },
  {
    "name": "solve",
    "task_id": "HumanEval/84",
    "Dis": 0.1922,
    "Err": 0.8918,
    "TotalTime": 1.7252702713012695
  },
  {
    "name": "add",
    "task_id": "HumanEval/85",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.3366410732269287
  },
  {
    "name": "anti_shuffle",
    "task_id": "HumanEval/86",
    "Dis": 0.3096,
    "Err": 0.1782,
    "TotalTime": 2.0558090209960938
  },
  {
    "name": "get_row",
    "task_id": "HumanEval/87",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.274315595626831
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/88",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.646113634109497
  },
  {
    "name": "encrypt",
    "task_id": "HumanEval/89",
    "Dis": 0.1994,
    "Err": 0.416,
    "TotalTime": 2.173367738723755
  },
  {
    "name": "next_smallest",
    "task_id": "HumanEval/90",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.509065628051758
  },
  {
    "name": "is_bored",
    "task_id": "HumanEval/91",
    "Dis": 0.0014,
    "Err": 0.153,
    "TotalTime": 2.051927328109741
  },
  {
    "name": "any_int",
    "task_id": "HumanEval/92",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.0190558433532715
  },
  {
    "name": "encode",
    "task_id": "HumanEval/93",
    "Dis": 0.5758,
    "Err": 0.5548,
    "TotalTime": 2.254519462585449
  },
  {
    "name": "skjkasdkd",
    "task_id": "HumanEval/94",
    "Dis": 0.001,
    "Err": 0.0132,
    "TotalTime": 3.659914255142212
  },
  {
    "name": "check_dict_case",
    "task_id": "HumanEval/95",
    "Dis": 0.0,
    "Err": 0.0078,
    "TotalTime": 2.628465175628662
  },
  {
    "name": "count_up_to",
    "task_id": "HumanEval/96",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.2685141563415527
  },
  {
    "name": "multiply",
    "task_id": "HumanEval/97",
    "Dis": 0.0,
    "Err": 0.2178,
    "TotalTime": 1.7115306854248047
  },
  {
    "name": "count_upper",
    "task_id": "HumanEval/98",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.014237403869629
  },
  {
    "name": "closest_integer",
    "task_id": "HumanEval/99",
    "Dis": 0.0196,
    "Err": 0.009,
    "TotalTime": 4.312383413314819
  },
  {
    "name": "make_a_pile",
    "task_id": "HumanEval/100",
    "Dis": 0.0606,
    "Err": 0.4036,
    "TotalTime": 1.6430132389068604
  },
  {
    "name": "words_string",
    "task_id": "HumanEval/101",
    "Dis": 0.1218,
    "Err": 0.0634,
    "TotalTime": 2.046969413757324
  },
  {
    "name": "choose_num",
    "task_id": "HumanEval/102",
    "Dis": 0.0104,
    "Err": 0.0088,
    "TotalTime": 3.038970947265625
  },
  {
    "name": "rounded_avg",
    "task_id": "HumanEval/103",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.966315507888794
  },
  {
    "name": "unique_digits",
    "task_id": "HumanEval/104",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.0373857021331787
  },
  {
    "name": "by_length",
    "task_id": "HumanEval/105",
    "Dis": 0.0274,
    "Err": 0.053,
    "TotalTime": 2.6392509937286377
  },
  {
    "name": "f",
    "task_id": "HumanEval/106",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.5305335521698
  },
  {
    "name": "even_odd_palindrome",
    "task_id": "HumanEval/107",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.266038179397583
  },
  {
    "name": "count_nums",
    "task_id": "HumanEval/108",
    "Dis": 0.7228,
    "Err": 0.6026,
    "TotalTime": 3.0363759994506836
  },
  {
    "name": "move_one_ball",
    "task_id": "HumanEval/109",
    "Dis": 0.0022,
    "Err": 0.0034,
    "TotalTime": 2.847879648208618
  },
  {
    "name": "exchange",
    "task_id": "HumanEval/110",
    "Dis": 0.2158,
    "Err": 0.1446,
    "TotalTime": 4.865207195281982
  },
  {
    "name": "histogram",
    "task_id": "HumanEval/111",
    "Dis": 0.3012,
    "Err": 0.4184,
    "TotalTime": 2.0851738452911377
  },
  {
    "name": "reverse_delete",
    "task_id": "HumanEval/112",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.603863000869751
  },
  {
    "name": "odd_count",
    "task_id": "HumanEval/113",
    "Dis": 0.1532,
    "Err": 0.0816,
    "TotalTime": 4.95133900642395
  },
  {
    "name": "minSubArraySum",
    "task_id": "HumanEval/114",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.726372003555298
  },
  {
    "name": "max_fill",
    "task_id": "HumanEval/115",
    "Dis": 0.5472,
    "Err": 0.4248,
    "TotalTime": 4.5261390209198
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/116",
    "Dis": 0.0,
    "Err": 0.3652,
    "TotalTime": 3.371629476547241
  },
  {
    "name": "select_words",
    "task_id": "HumanEval/117",
    "Dis": 0.0258,
    "Err": 0.046,
    "TotalTime": 2.6892993450164795
  },
  {
    "name": "get_closest_vowel",
    "task_id": "HumanEval/118",
    "Dis": 0.21,
    "Err": 0.1928,
    "TotalTime": 2.007951498031616
  },
  {
    "name": "match_parens",
    "task_id": "HumanEval/119",
    "Dis": 0.1316,
    "Err": 0.0856,
    "TotalTime": 3.4366416931152344
  },
  {
    "name": "maximum",
    "task_id": "HumanEval/120",
    "Dis": 0.1148,
    "Err": 0.1098,
    "TotalTime": 2.985776424407959
  },
  {
    "name": "solution",
    "task_id": "HumanEval/121",
    "Dis": 0.313,
    "Err": 0.1976,
    "TotalTime": 2.5843536853790283
  },
  {
    "name": "add_elements",
    "task_id": "HumanEval/122",
    "Dis": 0.2454,
    "Err": 0.2748,
    "TotalTime": 3.045839786529541
  },
  {
    "name": "get_odd_collatz",
    "task_id": "HumanEval/123",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "valid_date",
    "task_id": "HumanEval/124",
    "Dis": 0.0072,
    "Err": 0.0198,
    "TotalTime": 2.1562345027923584
  },
  {
    "name": "split_words",
    "task_id": "HumanEval/125",
    "Dis": 0.3432,
    "Err": 0.334,
    "TotalTime": 2.0360050201416016
  },
  {
    "name": "is_sorted",
    "task_id": "HumanEval/126",
    "Dis": 0.0,
    "Err": 0.0484,
    "TotalTime": 2.7727932929992676
  },
  {
    "name": "intersection",
    "task_id": "HumanEval/127",
    "Dis": 0.3314,
    "Err": 0.2674,
    "TotalTime": 5.928109407424927
  },
  {
    "name": "prod_signs",
    "task_id": "HumanEval/128",
    "Dis": 0.0062,
    "Err": 0.0038,
    "TotalTime": 2.844336986541748
  },
  {
    "name": "minPath",
    "task_id": "HumanEval/129",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "tri",
    "task_id": "HumanEval/130",
    "Dis": 0.7432,
    "Err": 0.579,
    "TotalTime": 2.8235409259796143
  },
  {
    "name": "digits",
    "task_id": "HumanEval/131",
    "Dis": 0.1306,
    "Err": 0.0718,
    "TotalTime": 1.6504576206207275
  },
  {
    "name": "is_nested",
    "task_id": "HumanEval/132",
    "Dis": 0.0382,
    "Err": 0.1082,
    "TotalTime": 2.024815559387207
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/133",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.747738838195801
  },
  {
    "name": "check_if_last_char_is_a_letter",
    "task_id": "HumanEval/134",
    "Dis": 0.2078,
    "Err": 0.1534,
    "TotalTime": 2.0969316959381104
  },
  {
    "name": "can_arrange",
    "task_id": "HumanEval/135",
    "Dis": 0.0364,
    "Err": 0.0212,
    "TotalTime": 2.782813787460327
  },
  {
    "name": "largest_smallest_integers",
    "task_id": "HumanEval/136",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.00482177734375
  },
  {
    "name": "compare_one",
    "task_id": "HumanEval/137",
    "Dis": 0.0302,
    "Err": 0.021,
    "TotalTime": 3.09159517288208
  },
  {
    "name": "is_equal_to_sum_even",
    "task_id": "HumanEval/138",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 14.310837030410767
  },
  {
    "name": "special_factorial",
    "task_id": "HumanEval/139",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "fix_spaces",
    "task_id": "HumanEval/140",
    "Dis": 0.0894,
    "Err": 0.1142,
    "TotalTime": 2.0663576126098633
  },
  {
    "name": "file_name_check",
    "task_id": "HumanEval/141",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.075242757797241
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/142",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.8350162506103516
  },
  {
    "name": "words_in_sentence",
    "task_id": "HumanEval/143",
    "Dis": 0.361,
    "Err": 0.2034,
    "TotalTime": 2.286876916885376
  },
  {
    "name": "simplify",
    "task_id": "HumanEval/144",
    "Dis": 0.0008,
    "Err": 0.0,
    "TotalTime": 73.35003519058228
  },
  {
    "name": "order_by_points",
    "task_id": "HumanEval/145",
    "Dis": 0.5992,
    "Err": 0.8034,
    "TotalTime": 3.5444495677948
  },
  {
    "name": "specialFilter",
    "task_id": "HumanEval/146",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.8206379413604736
  },
  {
    "name": "bf",
    "task_id": "HumanEval/148",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.584536552429199
  },
  {
    "name": "sorted_list_sum",
    "task_id": "HumanEval/149",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.399871587753296
  },
  {
    "name": "x_or_y",
    "task_id": "HumanEval/150",
    "Dis": 0.0,
    "Err": 0.221,
    "TotalTime": 2.4491286277770996
  },
  {
    "name": "double_the_difference",
    "task_id": "HumanEval/151",
    "Dis": 0.0952,
    "Err": 0.0482,
    "TotalTime": 4.223220109939575
  },
  {
    "name": "compare",
    "task_id": "HumanEval/152",
    "Dis": 0.3062,
    "Err": 0.1886,
    "TotalTime": 4.499723434448242
  },
  {
    "name": "Strongest_Extension",
    "task_id": "HumanEval/153",
    "Dis": 0.0616,
    "Err": 0.0414,
    "TotalTime": 4.648175954818726
  },
  {
    "name": "cycpattern_check",
    "task_id": "HumanEval/154",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "even_odd_count",
    "task_id": "HumanEval/155",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.6541213989257812
  },
  {
    "name": "right_angle_triangle",
    "task_id": "HumanEval/157",
    "Dis": 0.0008,
    "Err": 0.0018,
    "TotalTime": 2.031580686569214
  },
  {
    "name": "find_max",
    "task_id": "HumanEval/158",
    "Dis": 0.0134,
    "Err": 0.009,
    "TotalTime": 3.4133644104003906
  },
  {
    "name": "eat",
    "task_id": "HumanEval/159",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.935915231704712
  },
  {
    "name": "solve",
    "task_id": "HumanEval/161",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.130284309387207
  },
  {
    "name": "string_to_md5",
    "task_id": "HumanEval/162",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.4311399459838867
  },
  {
    "name": "generate_integers",
    "task_id": "HumanEval/163",
    "Dis": 0.3426,
    "Err": 0.861,
    "TotalTime": 1.9793505668640137
  }
]