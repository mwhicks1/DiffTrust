[
  {
    "name": "has_close_elements",
    "task_id": "HumanEval/0",
    "Dis": 0.0,
    "Err": 0.0585,
    "TotalTime": 4.578158617019653
  },
  {
    "name": "separate_paren_groups",
    "task_id": "HumanEval/1",
    "Dis": 0.3815,
    "Err": 0.3029,
    "TotalTime": 3.168832302093506
  },
  {
    "name": "truncate_number",
    "task_id": "HumanEval/2",
    "Dis": 0.0441,
    "Err": 0.2209,
    "TotalTime": 2.2701268196105957
  },
  {
    "name": "below_zero",
    "task_id": "HumanEval/3",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.902766466140747
  },
  {
    "name": "mean_absolute_deviation",
    "task_id": "HumanEval/4",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.351304292678833
  },
  {
    "name": "intersperse",
    "task_id": "HumanEval/5",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.5987708568573
  },
  {
    "name": "parse_nested_parens",
    "task_id": "HumanEval/6",
    "Dis": 0.0539,
    "Err": 0.3839,
    "TotalTime": 2.9922451972961426
  },
  {
    "name": "filter_by_substring",
    "task_id": "HumanEval/7",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 6.0410919189453125
  },
  {
    "name": "sum_product",
    "task_id": "HumanEval/8",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.986297845840454
  },
  {
    "name": "rolling_max",
    "task_id": "HumanEval/9",
    "Dis": 0.0343,
    "Err": 0.0571,
    "TotalTime": 3.915275812149048
  },
  {
    "name": "make_palindrome",
    "task_id": "HumanEval/10",
    "Dis": 0.0091,
    "Err": 0.0044,
    "TotalTime": 3.2022104263305664
  },
  {
    "name": "string_xor",
    "task_id": "HumanEval/11",
    "Dis": 0.1991,
    "Err": 0.9842,
    "TotalTime": 4.341376543045044
  },
  {
    "name": "longest",
    "task_id": "HumanEval/12",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.459948301315308
  },
  {
    "name": "greatest_common_divisor",
    "task_id": "HumanEval/13",
    "Dis": 0.0892,
    "Err": 0.1342,
    "TotalTime": 2.5223305225372314
  },
  {
    "name": "all_prefixes",
    "task_id": "HumanEval/14",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.0843870639801025
  },
  {
    "name": "string_sequence",
    "task_id": "HumanEval/15",
    "Dis": 0.1983,
    "Err": 0.0939,
    "TotalTime": 2.282346725463867
  },
  {
    "name": "count_distinct_characters",
    "task_id": "HumanEval/16",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.80314040184021
  },
  {
    "name": "parse_music",
    "task_id": "HumanEval/17",
    "Dis": 0.6153,
    "Err": 0.5749,
    "TotalTime": 7.115780830383301
  },
  {
    "name": "how_many_times",
    "task_id": "HumanEval/18",
    "Dis": 0.0146,
    "Err": 0.0762,
    "TotalTime": 3.8286571502685547
  },
  {
    "name": "sort_numbers",
    "task_id": "HumanEval/19",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 10.440767765045166
  },
  {
    "name": "find_closest_elements",
    "task_id": "HumanEval/20",
    "Dis": 0.2086,
    "Err": 0.1055,
    "TotalTime": 4.384080171585083
  },
  {
    "name": "rescale_to_unit",
    "task_id": "HumanEval/21",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.288130044937134
  },
  {
    "name": "filter_integers",
    "task_id": "HumanEval/22",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.9053263664245605
  },
  {
    "name": "strlen",
    "task_id": "HumanEval/23",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.750948667526245
  },
  {
    "name": "largest_divisor",
    "task_id": "HumanEval/24",
    "Dis": 0.115,
    "Err": 0.0959,
    "TotalTime": 2.2192511558532715
  },
  {
    "name": "factorize",
    "task_id": "HumanEval/25",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 24.975842237472534
  },
  {
    "name": "remove_duplicates",
    "task_id": "HumanEval/26",
    "Dis": 0.0969,
    "Err": 0.0504,
    "TotalTime": 4.051527261734009
  },
  {
    "name": "flip_case",
    "task_id": "HumanEval/27",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.9422144889831543
  },
  {
    "name": "concatenate",
    "task_id": "HumanEval/28",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 5.0187599658966064
  },
  {
    "name": "filter_by_prefix",
    "task_id": "HumanEval/29",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 7.187899351119995
  },
  {
    "name": "get_positive",
    "task_id": "HumanEval/30",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.401543855667114
  },
  {
    "name": "is_prime",
    "task_id": "HumanEval/31",
    "Dis": 0.1987,
    "Err": 0.0998,
    "TotalTime": 3.9561619758605957
  },
  {
    "name": "unique",
    "task_id": "HumanEval/34",
    "Dis": 0.1988,
    "Err": 0.1012,
    "TotalTime": 4.428242206573486
  },
  {
    "name": "max_element",
    "task_id": "HumanEval/35",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.398039102554321
  },
  {
    "name": "sort_even",
    "task_id": "HumanEval/37",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.474357604980469
  },
  {
    "name": "triples_sum_to_zero",
    "task_id": "HumanEval/40",
    "Dis": 0.0195,
    "Err": 0.0149,
    "TotalTime": 4.103215456008911
  },
  {
    "name": "car_race_collision",
    "task_id": "HumanEval/41",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.138990879058838
  },
  {
    "name": "incr_list",
    "task_id": "HumanEval/42",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.123384714126587
  },
  {
    "name": "pairs_sum_to_zero",
    "task_id": "HumanEval/43",
    "Dis": 0.0058,
    "Err": 0.031,
    "TotalTime": 4.000666618347168
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/45",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.4791572093963623
  },
  {
    "name": "fib4",
    "task_id": "HumanEval/46",
    "Dis": 0.1685,
    "Err": 0.1046,
    "TotalTime": 2.4661028385162354
  },
  {
    "name": "median",
    "task_id": "HumanEval/47",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.9805803298950195
  },
  {
    "name": "is_palindrome",
    "task_id": "HumanEval/48",
    "Dis": 0.0069,
    "Err": 0.0099,
    "TotalTime": 2.8948495388031006
  },
  {
    "name": "modp",
    "task_id": "HumanEval/49",
    "Dis": 0.0411,
    "Err": 0.1838,
    "TotalTime": 2.65847110748291
  },
  {
    "name": "remove_vowels",
    "task_id": "HumanEval/51",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.1129910945892334
  },
  {
    "name": "below_threshold",
    "task_id": "HumanEval/52",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.033889293670654
  },
  {
    "name": "add",
    "task_id": "HumanEval/53",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.4853363037109375
  },
  {
    "name": "same_chars",
    "task_id": "HumanEval/54",
    "Dis": 0.0036,
    "Err": 0.002,
    "TotalTime": 3.978792428970337
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/56",
    "Dis": 0.0,
    "Err": 0.4041,
    "TotalTime": 2.9503090381622314
  },
  {
    "name": "monotonic",
    "task_id": "HumanEval/57",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.8687796592712402
  },
  {
    "name": "common",
    "task_id": "HumanEval/58",
    "Dis": 0.0,
    "Err": 0.3679,
    "TotalTime": 5.000983238220215
  },
  {
    "name": "largest_prime_factor",
    "task_id": "HumanEval/59",
    "Dis": 0.2567,
    "Err": 0.221,
    "TotalTime": 10.614445924758911
  },
  {
    "name": "sum_to_n",
    "task_id": "HumanEval/60",
    "Dis": 0.0,
    "Err": 0.2049,
    "TotalTime": 2.1115951538085938
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/61",
    "Dis": 0.0,
    "Err": 0.4008,
    "TotalTime": 2.884845495223999
  },
  {
    "name": "derivative",
    "task_id": "HumanEval/62",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.696394443511963
  },
  {
    "name": "vowels_count",
    "task_id": "HumanEval/64",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.9380791187286377
  },
  {
    "name": "circular_shift",
    "task_id": "HumanEval/65",
    "Dis": 0.1565,
    "Err": 0.3657,
    "TotalTime": 2.696378231048584
  },
  {
    "name": "digitSum",
    "task_id": "HumanEval/66",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.924718141555786
  },
  {
    "name": "fruit_distribution",
    "task_id": "HumanEval/67",
    "Dis": 0.441,
    "Err": 0.5152,
    "TotalTime": 3.6491456031799316
  },
  {
    "name": "pluck",
    "task_id": "HumanEval/68",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.978715419769287
  },
  {
    "name": "search",
    "task_id": "HumanEval/69",
    "Dis": 0.0802,
    "Err": 0.1443,
    "TotalTime": 5.270151138305664
  },
  {
    "name": "strange_sort_list",
    "task_id": "HumanEval/70",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.845482587814331
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/71",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.810818910598755
  },
  {
    "name": "will_it_fly",
    "task_id": "HumanEval/72",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.5264201164245605
  },
  {
    "name": "smallest_change",
    "task_id": "HumanEval/73",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.3463504314422607
  },
  {
    "name": "total_match",
    "task_id": "HumanEval/74",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 8.973187446594238
  },
  {
    "name": "iscube",
    "task_id": "HumanEval/77",
    "Dis": 0.2045,
    "Err": 0.1003,
    "TotalTime": 2.1174800395965576
  },
  {
    "name": "hex_key",
    "task_id": "HumanEval/78",
    "Dis": 0.2864,
    "Err": 0.4701,
    "TotalTime": 3.6334409713745117
  },
  {
    "name": "decimal_to_binary",
    "task_id": "HumanEval/79",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.0995521545410156
  },
  {
    "name": "is_happy",
    "task_id": "HumanEval/80",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.852078914642334
  },
  {
    "name": "numerical_letter_grade",
    "task_id": "HumanEval/81",
    "Dis": 0.3067,
    "Err": 0.1657,
    "TotalTime": 4.20404052734375
  },
  {
    "name": "prime_length",
    "task_id": "HumanEval/82",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.095482110977173
  },
  {
    "name": "starts_one_ends",
    "task_id": "HumanEval/83",
    "Dis": 0.9262,
    "Err": 0.7935,
    "TotalTime": 2.8394362926483154
  },
  {
    "name": "solve",
    "task_id": "HumanEval/84",
    "Dis": 0.1984,
    "Err": 0.8916,
    "TotalTime": 2.234745979309082
  },
  {
    "name": "add",
    "task_id": "HumanEval/85",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.5236752033233643
  },
  {
    "name": "anti_shuffle",
    "task_id": "HumanEval/86",
    "Dis": 0.3162,
    "Err": 0.1781,
    "TotalTime": 2.9540228843688965
  },
  {
    "name": "get_row",
    "task_id": "HumanEval/87",
    "Dis": 0.0,
    "Err": 0.0002,
    "TotalTime": 7.064423322677612
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/88",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.050652027130127
  },
  {
    "name": "encrypt",
    "task_id": "HumanEval/89",
    "Dis": 0.1966,
    "Err": 0.4122,
    "TotalTime": 3.0712921619415283
  },
  {
    "name": "next_smallest",
    "task_id": "HumanEval/90",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.795889139175415
  },
  {
    "name": "is_bored",
    "task_id": "HumanEval/91",
    "Dis": 0.0023,
    "Err": 0.1488,
    "TotalTime": 2.969701051712036
  },
  {
    "name": "any_int",
    "task_id": "HumanEval/92",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.789771556854248
  },
  {
    "name": "encode",
    "task_id": "HumanEval/93",
    "Dis": 0.569,
    "Err": 0.5696,
    "TotalTime": 3.165998697280884
  },
  {
    "name": "skjkasdkd",
    "task_id": "HumanEval/94",
    "Dis": 0.0016,
    "Err": 0.0162,
    "TotalTime": 5.395585298538208
  },
  {
    "name": "check_dict_case",
    "task_id": "HumanEval/95",
    "Dis": 0.0,
    "Err": 0.0087,
    "TotalTime": 3.9463131427764893
  },
  {
    "name": "count_up_to",
    "task_id": "HumanEval/96",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.9855518341064453
  },
  {
    "name": "multiply",
    "task_id": "HumanEval/97",
    "Dis": 0.0,
    "Err": 0.2172,
    "TotalTime": 2.441898822784424
  },
  {
    "name": "count_upper",
    "task_id": "HumanEval/98",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.8358664512634277
  },
  {
    "name": "closest_integer",
    "task_id": "HumanEval/99",
    "Dis": 0.0213,
    "Err": 0.0095,
    "TotalTime": 6.800825357437134
  },
  {
    "name": "make_a_pile",
    "task_id": "HumanEval/100",
    "Dis": 0.058,
    "Err": 0.3993,
    "TotalTime": 2.253857135772705
  },
  {
    "name": "words_string",
    "task_id": "HumanEval/101",
    "Dis": 0.1148,
    "Err": 0.0537,
    "TotalTime": 3.0065155029296875
  },
  {
    "name": "choose_num",
    "task_id": "HumanEval/102",
    "Dis": 0.0104,
    "Err": 0.009,
    "TotalTime": 4.7600767612457275
  },
  {
    "name": "rounded_avg",
    "task_id": "HumanEval/103",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.701568126678467
  },
  {
    "name": "unique_digits",
    "task_id": "HumanEval/104",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.5281453132629395
  },
  {
    "name": "by_length",
    "task_id": "HumanEval/105",
    "Dis": 0.0254,
    "Err": 0.0546,
    "TotalTime": 3.9781057834625244
  },
  {
    "name": "f",
    "task_id": "HumanEval/106",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.3197433948516846
  },
  {
    "name": "even_odd_palindrome",
    "task_id": "HumanEval/107",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.150613307952881
  },
  {
    "name": "count_nums",
    "task_id": "HumanEval/108",
    "Dis": 0.7235,
    "Err": 0.5956,
    "TotalTime": 4.81371808052063
  },
  {
    "name": "move_one_ball",
    "task_id": "HumanEval/109",
    "Dis": 0.0007,
    "Err": 0.0051,
    "TotalTime": 4.097526550292969
  },
  {
    "name": "exchange",
    "task_id": "HumanEval/110",
    "Dis": 0.2185,
    "Err": 0.1503,
    "TotalTime": 7.66567063331604
  },
  {
    "name": "histogram",
    "task_id": "HumanEval/111",
    "Dis": 0.3025,
    "Err": 0.4233,
    "TotalTime": 3.05035138130188
  },
  {
    "name": "reverse_delete",
    "task_id": "HumanEval/112",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.881591320037842
  },
  {
    "name": "odd_count",
    "task_id": "HumanEval/113",
    "Dis": 0.1666,
    "Err": 0.0825,
    "TotalTime": 7.645772695541382
  },
  {
    "name": "minSubArraySum",
    "task_id": "HumanEval/114",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.042723655700684
  },
  {
    "name": "max_fill",
    "task_id": "HumanEval/115",
    "Dis": 0.5626,
    "Err": 0.4215,
    "TotalTime": 6.882677316665649
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/116",
    "Dis": 0.0,
    "Err": 0.3722,
    "TotalTime": 4.6975178718566895
  },
  {
    "name": "select_words",
    "task_id": "HumanEval/117",
    "Dis": 0.0259,
    "Err": 0.0459,
    "TotalTime": 3.736931085586548
  },
  {
    "name": "get_closest_vowel",
    "task_id": "HumanEval/118",
    "Dis": 0.2217,
    "Err": 0.1874,
    "TotalTime": 2.8353271484375
  },
  {
    "name": "match_parens",
    "task_id": "HumanEval/119",
    "Dis": 0.1344,
    "Err": 0.0824,
    "TotalTime": 5.31997275352478
  },
  {
    "name": "maximum",
    "task_id": "HumanEval/120",
    "Dis": 0.1166,
    "Err": 0.1014,
    "TotalTime": 4.43457818031311
  },
  {
    "name": "solution",
    "task_id": "HumanEval/121",
    "Dis": 0.3141,
    "Err": 0.1996,
    "TotalTime": 3.6666207313537598
  },
  {
    "name": "add_elements",
    "task_id": "HumanEval/122",
    "Dis": 0.2509,
    "Err": 0.265,
    "TotalTime": 4.287566661834717
  },
  {
    "name": "get_odd_collatz",
    "task_id": "HumanEval/123",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "valid_date",
    "task_id": "HumanEval/124",
    "Dis": 0.0058,
    "Err": 0.0205,
    "TotalTime": 3.07255482673645
  },
  {
    "name": "split_words",
    "task_id": "HumanEval/125",
    "Dis": 0.3552,
    "Err": 0.3239,
    "TotalTime": 2.9198977947235107
  },
  {
    "name": "is_sorted",
    "task_id": "HumanEval/126",
    "Dis": 0.0,
    "Err": 0.0501,
    "TotalTime": 3.999058961868286
  },
  {
    "name": "intersection",
    "task_id": "HumanEval/127",
    "Dis": 0.3245,
    "Err": 0.2695,
    "TotalTime": 9.742189168930054
  },
  {
    "name": "prod_signs",
    "task_id": "HumanEval/128",
    "Dis": 0.0072,
    "Err": 0.0036,
    "TotalTime": 4.2204649448394775
  },
  {
    "name": "minPath",
    "task_id": "HumanEval/129",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "tri",
    "task_id": "HumanEval/130",
    "Dis": 0.7579,
    "Err": 0.586,
    "TotalTime": 4.093022584915161
  },
  {
    "name": "digits",
    "task_id": "HumanEval/131",
    "Dis": 0.1202,
    "Err": 0.0692,
    "TotalTime": 2.152089834213257
  },
  {
    "name": "is_nested",
    "task_id": "HumanEval/132",
    "Dis": 0.0353,
    "Err": 0.1107,
    "TotalTime": 2.871574640274048
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/133",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.83591628074646
  },
  {
    "name": "check_if_last_char_is_a_letter",
    "task_id": "HumanEval/134",
    "Dis": 0.2057,
    "Err": 0.1556,
    "TotalTime": 2.908492088317871
  },
  {
    "name": "can_arrange",
    "task_id": "HumanEval/135",
    "Dis": 0.0403,
    "Err": 0.0211,
    "TotalTime": 3.786407232284546
  },
  {
    "name": "largest_smallest_integers",
    "task_id": "HumanEval/136",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.295078992843628
  },
  {
    "name": "compare_one",
    "task_id": "HumanEval/137",
    "Dis": 0.0339,
    "Err": 0.0213,
    "TotalTime": 4.29008936882019
  },
  {
    "name": "is_equal_to_sum_even",
    "task_id": "HumanEval/138",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 24.160029649734497
  },
  {
    "name": "special_factorial",
    "task_id": "HumanEval/139",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "fix_spaces",
    "task_id": "HumanEval/140",
    "Dis": 0.0948,
    "Err": 0.1181,
    "TotalTime": 3.025132417678833
  },
  {
    "name": "file_name_check",
    "task_id": "HumanEval/141",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.012485980987549
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/142",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.471779108047485
  },
  {
    "name": "words_in_sentence",
    "task_id": "HumanEval/143",
    "Dis": 0.3534,
    "Err": 0.2011,
    "TotalTime": 3.0997085571289062
  },
  {
    "name": "simplify",
    "task_id": "HumanEval/144",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "order_by_points",
    "task_id": "HumanEval/145",
    "Dis": 0.6023,
    "Err": 0.7952,
    "TotalTime": 5.492483854293823
  },
  {
    "name": "specialFilter",
    "task_id": "HumanEval/146",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.133790731430054
  },
  {
    "name": "bf",
    "task_id": "HumanEval/148",
    "Dis": 0.0003,
    "Err": 0.0,
    "TotalTime": 3.828432083129883
  },
  {
    "name": "sorted_list_sum",
    "task_id": "HumanEval/149",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 5.3745129108428955
  },
  {
    "name": "x_or_y",
    "task_id": "HumanEval/150",
    "Dis": 0.0,
    "Err": 0.2228,
    "TotalTime": 3.2616724967956543
  },
  {
    "name": "double_the_difference",
    "task_id": "HumanEval/151",
    "Dis": 0.0939,
    "Err": 0.0468,
    "TotalTime": 6.315045356750488
  },
  {
    "name": "compare",
    "task_id": "HumanEval/152",
    "Dis": 0.2929,
    "Err": 0.1986,
    "TotalTime": 7.049708843231201
  },
  {
    "name": "Strongest_Extension",
    "task_id": "HumanEval/153",
    "Dis": 0.0638,
    "Err": 0.0433,
    "TotalTime": 6.95097017288208
  },
  {
    "name": "cycpattern_check",
    "task_id": "HumanEval/154",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "even_odd_count",
    "task_id": "HumanEval/155",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.149864673614502
  },
  {
    "name": "right_angle_triangle",
    "task_id": "HumanEval/157",
    "Dis": 0.0009,
    "Err": 0.001,
    "TotalTime": 2.7211873531341553
  },
  {
    "name": "find_max",
    "task_id": "HumanEval/158",
    "Dis": 0.0153,
    "Err": 0.0094,
    "TotalTime": 5.176908731460571
  },
  {
    "name": "eat",
    "task_id": "HumanEval/159",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.808026075363159
  },
  {
    "name": "solve",
    "task_id": "HumanEval/161",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.0449001789093018
  },
  {
    "name": "string_to_md5",
    "task_id": "HumanEval/162",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.5424575805664062
  },
  {
    "name": "generate_integers",
    "task_id": "HumanEval/163",
    "Dis": 0.3371,
    "Err": 0.8611,
    "TotalTime": 2.7500596046447754
  }
]