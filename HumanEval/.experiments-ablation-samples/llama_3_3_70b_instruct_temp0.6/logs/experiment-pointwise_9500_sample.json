[
  {
    "name": "has_close_elements",
    "task_id": "HumanEval/0",
    "Dis": 0.0,
    "Err": 0.05210526315789474,
    "TotalTime": 4.374771595001221
  },
  {
    "name": "separate_paren_groups",
    "task_id": "HumanEval/1",
    "Dis": 0.3874736842105263,
    "Err": 0.3078947368421053,
    "TotalTime": 2.9644837379455566
  },
  {
    "name": "truncate_number",
    "task_id": "HumanEval/2",
    "Dis": 0.04231578947368421,
    "Err": 0.21726315789473685,
    "TotalTime": 2.140564203262329
  },
  {
    "name": "below_zero",
    "task_id": "HumanEval/3",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.6547837257385254
  },
  {
    "name": "mean_absolute_deviation",
    "task_id": "HumanEval/4",
    "Dis": 0.0,
    "Err": 0.00010526315789473685,
    "TotalTime": 4.292785167694092
  },
  {
    "name": "intersperse",
    "task_id": "HumanEval/5",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.5371477603912354
  },
  {
    "name": "parse_nested_parens",
    "task_id": "HumanEval/6",
    "Dis": 0.04684210526315789,
    "Err": 0.39621052631578946,
    "TotalTime": 2.9860849380493164
  },
  {
    "name": "filter_by_substring",
    "task_id": "HumanEval/7",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 5.890605211257935
  },
  {
    "name": "sum_product",
    "task_id": "HumanEval/8",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.988839626312256
  },
  {
    "name": "rolling_max",
    "task_id": "HumanEval/9",
    "Dis": 0.0351578947368421,
    "Err": 0.06305263157894737,
    "TotalTime": 3.7543115615844727
  },
  {
    "name": "make_palindrome",
    "task_id": "HumanEval/10",
    "Dis": 0.008421052631578947,
    "Err": 0.003789473684210526,
    "TotalTime": 3.135690212249756
  },
  {
    "name": "string_xor",
    "task_id": "HumanEval/11",
    "Dis": 0.20305263157894737,
    "Err": 0.986,
    "TotalTime": 4.048714876174927
  },
  {
    "name": "longest",
    "task_id": "HumanEval/12",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.419410467147827
  },
  {
    "name": "greatest_common_divisor",
    "task_id": "HumanEval/13",
    "Dis": 0.09336842105263157,
    "Err": 0.1328421052631579,
    "TotalTime": 2.447171688079834
  },
  {
    "name": "all_prefixes",
    "task_id": "HumanEval/14",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.96260142326355
  },
  {
    "name": "string_sequence",
    "task_id": "HumanEval/15",
    "Dis": 0.1986315789473684,
    "Err": 0.09442105263157895,
    "TotalTime": 2.183570623397827
  },
  {
    "name": "count_distinct_characters",
    "task_id": "HumanEval/16",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.875852346420288
  },
  {
    "name": "parse_music",
    "task_id": "HumanEval/17",
    "Dis": 0.6085263157894737,
    "Err": 0.5814736842105264,
    "TotalTime": 7.247868776321411
  },
  {
    "name": "how_many_times",
    "task_id": "HumanEval/18",
    "Dis": 0.012842105263157894,
    "Err": 0.07221052631578948,
    "TotalTime": 3.7851884365081787
  },
  {
    "name": "sort_numbers",
    "task_id": "HumanEval/19",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 10.117818832397461
  },
  {
    "name": "find_closest_elements",
    "task_id": "HumanEval/20",
    "Dis": 0.19621052631578947,
    "Err": 0.09568421052631579,
    "TotalTime": 4.242533445358276
  },
  {
    "name": "rescale_to_unit",
    "task_id": "HumanEval/21",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.28535795211792
  },
  {
    "name": "filter_integers",
    "task_id": "HumanEval/22",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.916940450668335
  },
  {
    "name": "strlen",
    "task_id": "HumanEval/23",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.7735116481781006
  },
  {
    "name": "largest_divisor",
    "task_id": "HumanEval/24",
    "Dis": 0.11694736842105263,
    "Err": 0.08810526315789474,
    "TotalTime": 2.1924426555633545
  },
  {
    "name": "factorize",
    "task_id": "HumanEval/25",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 26.779582262039185
  },
  {
    "name": "remove_duplicates",
    "task_id": "HumanEval/26",
    "Dis": 0.09926315789473684,
    "Err": 0.044421052631578944,
    "TotalTime": 3.9076645374298096
  },
  {
    "name": "flip_case",
    "task_id": "HumanEval/27",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.9536800384521484
  },
  {
    "name": "concatenate",
    "task_id": "HumanEval/28",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 5.020732402801514
  },
  {
    "name": "filter_by_prefix",
    "task_id": "HumanEval/29",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 7.127265930175781
  },
  {
    "name": "get_positive",
    "task_id": "HumanEval/30",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.101207256317139
  },
  {
    "name": "is_prime",
    "task_id": "HumanEval/31",
    "Dis": 0.20589473684210527,
    "Err": 0.0968421052631579,
    "TotalTime": 3.922517776489258
  },
  {
    "name": "unique",
    "task_id": "HumanEval/34",
    "Dis": 0.20463157894736841,
    "Err": 0.09947368421052631,
    "TotalTime": 4.2222089767456055
  },
  {
    "name": "max_element",
    "task_id": "HumanEval/35",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.1803624629974365
  },
  {
    "name": "sort_even",
    "task_id": "HumanEval/37",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.229557514190674
  },
  {
    "name": "triples_sum_to_zero",
    "task_id": "HumanEval/40",
    "Dis": 0.01757894736842105,
    "Err": 0.011263157894736841,
    "TotalTime": 4.091065883636475
  },
  {
    "name": "car_race_collision",
    "task_id": "HumanEval/41",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.1666672229766846
  },
  {
    "name": "incr_list",
    "task_id": "HumanEval/42",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.214896202087402
  },
  {
    "name": "pairs_sum_to_zero",
    "task_id": "HumanEval/43",
    "Dis": 0.006210526315789474,
    "Err": 0.03105263157894737,
    "TotalTime": 3.978473663330078
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/45",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.444281816482544
  },
  {
    "name": "fib4",
    "task_id": "HumanEval/46",
    "Dis": 0.16778947368421052,
    "Err": 0.1028421052631579,
    "TotalTime": 2.4213409423828125
  },
  {
    "name": "median",
    "task_id": "HumanEval/47",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.9602253437042236
  },
  {
    "name": "is_palindrome",
    "task_id": "HumanEval/48",
    "Dis": 0.006105263157894737,
    "Err": 0.009473684210526316,
    "TotalTime": 2.824920892715454
  },
  {
    "name": "modp",
    "task_id": "HumanEval/49",
    "Dis": 0.03863157894736842,
    "Err": 0.18368421052631578,
    "TotalTime": 2.6795268058776855
  },
  {
    "name": "remove_vowels",
    "task_id": "HumanEval/51",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.9850246906280518
  },
  {
    "name": "below_threshold",
    "task_id": "HumanEval/52",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.9297330379486084
  },
  {
    "name": "add",
    "task_id": "HumanEval/53",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.36136531829834
  },
  {
    "name": "same_chars",
    "task_id": "HumanEval/54",
    "Dis": 0.004,
    "Err": 0.0017894736842105263,
    "TotalTime": 3.931392192840576
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/56",
    "Dis": 0.0,
    "Err": 0.40621052631578947,
    "TotalTime": 2.8588600158691406
  },
  {
    "name": "monotonic",
    "task_id": "HumanEval/57",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.85011625289917
  },
  {
    "name": "common",
    "task_id": "HumanEval/58",
    "Dis": 0.0,
    "Err": 0.3644210526315789,
    "TotalTime": 4.8674561977386475
  },
  {
    "name": "largest_prime_factor",
    "task_id": "HumanEval/59",
    "Dis": 0.2603157894736842,
    "Err": 0.21463157894736842,
    "TotalTime": 9.664937257766724
  },
  {
    "name": "sum_to_n",
    "task_id": "HumanEval/60",
    "Dis": 0.0,
    "Err": 0.21157894736842106,
    "TotalTime": 2.1351609230041504
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/61",
    "Dis": 0.0,
    "Err": 0.40821052631578947,
    "TotalTime": 2.791062593460083
  },
  {
    "name": "derivative",
    "task_id": "HumanEval/62",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.629838466644287
  },
  {
    "name": "vowels_count",
    "task_id": "HumanEval/64",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.98209285736084
  },
  {
    "name": "circular_shift",
    "task_id": "HumanEval/65",
    "Dis": 0.1611578947368421,
    "Err": 0.3661052631578947,
    "TotalTime": 2.5622963905334473
  },
  {
    "name": "digitSum",
    "task_id": "HumanEval/66",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.840463399887085
  },
  {
    "name": "fruit_distribution",
    "task_id": "HumanEval/67",
    "Dis": 0.43536842105263157,
    "Err": 0.514421052631579,
    "TotalTime": 3.587480306625366
  },
  {
    "name": "pluck",
    "task_id": "HumanEval/68",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.9715869426727295
  },
  {
    "name": "search",
    "task_id": "HumanEval/69",
    "Dis": 0.0703157894736842,
    "Err": 0.15336842105263157,
    "TotalTime": 5.1352033615112305
  },
  {
    "name": "strange_sort_list",
    "task_id": "HumanEval/70",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.669671058654785
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/71",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.747654676437378
  },
  {
    "name": "will_it_fly",
    "task_id": "HumanEval/72",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.420427322387695
  },
  {
    "name": "smallest_change",
    "task_id": "HumanEval/73",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.345780611038208
  },
  {
    "name": "total_match",
    "task_id": "HumanEval/74",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 9.03808879852295
  },
  {
    "name": "iscube",
    "task_id": "HumanEval/77",
    "Dis": 0.20442105263157895,
    "Err": 0.1008421052631579,
    "TotalTime": 2.0835976600646973
  },
  {
    "name": "hex_key",
    "task_id": "HumanEval/78",
    "Dis": 0.28378947368421054,
    "Err": 0.4612631578947368,
    "TotalTime": 3.654766798019409
  },
  {
    "name": "decimal_to_binary",
    "task_id": "HumanEval/79",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.0976033210754395
  },
  {
    "name": "is_happy",
    "task_id": "HumanEval/80",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.849254846572876
  },
  {
    "name": "numerical_letter_grade",
    "task_id": "HumanEval/81",
    "Dis": 0.30094736842105263,
    "Err": 0.1631578947368421,
    "TotalTime": 4.254036903381348
  },
  {
    "name": "prime_length",
    "task_id": "HumanEval/82",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.111602544784546
  },
  {
    "name": "starts_one_ends",
    "task_id": "HumanEval/83",
    "Dis": 0.9313684210526316,
    "Err": 0.7937894736842105,
    "TotalTime": 2.9928197860717773
  },
  {
    "name": "solve",
    "task_id": "HumanEval/84",
    "Dis": 0.20073684210526316,
    "Err": 0.897578947368421,
    "TotalTime": 2.3317246437072754
  },
  {
    "name": "add",
    "task_id": "HumanEval/85",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.478445053100586
  },
  {
    "name": "anti_shuffle",
    "task_id": "HumanEval/86",
    "Dis": 0.31557894736842107,
    "Err": 0.17305263157894737,
    "TotalTime": 3.0012052059173584
  },
  {
    "name": "get_row",
    "task_id": "HumanEval/87",
    "Dis": 0.0,
    "Err": 0.00010526315789473685,
    "TotalTime": 7.10107421875
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/88",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.105142831802368
  },
  {
    "name": "encrypt",
    "task_id": "HumanEval/89",
    "Dis": 0.19642105263157894,
    "Err": 0.4129473684210526,
    "TotalTime": 3.112340211868286
  },
  {
    "name": "next_smallest",
    "task_id": "HumanEval/90",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.8651344776153564
  },
  {
    "name": "is_bored",
    "task_id": "HumanEval/91",
    "Dis": 0.0013684210526315789,
    "Err": 0.14378947368421052,
    "TotalTime": 2.9356184005737305
  },
  {
    "name": "any_int",
    "task_id": "HumanEval/92",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.834669589996338
  },
  {
    "name": "encode",
    "task_id": "HumanEval/93",
    "Dis": 0.5704210526315789,
    "Err": 0.5644210526315789,
    "TotalTime": 3.2060956954956055
  },
  {
    "name": "skjkasdkd",
    "task_id": "HumanEval/94",
    "Dis": 0.002,
    "Err": 0.014421052631578947,
    "TotalTime": 5.511377811431885
  },
  {
    "name": "check_dict_case",
    "task_id": "HumanEval/95",
    "Dis": 0.0,
    "Err": 0.007684210526315789,
    "TotalTime": 4.073108196258545
  },
  {
    "name": "count_up_to",
    "task_id": "HumanEval/96",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.160062074661255
  },
  {
    "name": "multiply",
    "task_id": "HumanEval/97",
    "Dis": 0.0,
    "Err": 0.22073684210526315,
    "TotalTime": 2.463656187057495
  },
  {
    "name": "count_upper",
    "task_id": "HumanEval/98",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.815303087234497
  },
  {
    "name": "closest_integer",
    "task_id": "HumanEval/99",
    "Dis": 0.020736842105263158,
    "Err": 0.008526315789473684,
    "TotalTime": 6.685833930969238
  },
  {
    "name": "make_a_pile",
    "task_id": "HumanEval/100",
    "Dis": 0.058,
    "Err": 0.40610526315789475,
    "TotalTime": 2.2382545471191406
  },
  {
    "name": "words_string",
    "task_id": "HumanEval/101",
    "Dis": 0.1196842105263158,
    "Err": 0.05652631578947368,
    "TotalTime": 2.8702566623687744
  },
  {
    "name": "choose_num",
    "task_id": "HumanEval/102",
    "Dis": 0.008736842105263157,
    "Err": 0.008842105263157894,
    "TotalTime": 4.697480201721191
  },
  {
    "name": "rounded_avg",
    "task_id": "HumanEval/103",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.6769816875457764
  },
  {
    "name": "unique_digits",
    "task_id": "HumanEval/104",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.55217719078064
  },
  {
    "name": "by_length",
    "task_id": "HumanEval/105",
    "Dis": 0.024,
    "Err": 0.05515789473684211,
    "TotalTime": 3.869171380996704
  },
  {
    "name": "f",
    "task_id": "HumanEval/106",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.2612464427948
  },
  {
    "name": "even_odd_palindrome",
    "task_id": "HumanEval/107",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.094817638397217
  },
  {
    "name": "count_nums",
    "task_id": "HumanEval/108",
    "Dis": 0.7249473684210527,
    "Err": 0.5933684210526315,
    "TotalTime": 4.676451921463013
  },
  {
    "name": "move_one_ball",
    "task_id": "HumanEval/109",
    "Dis": 0.0016842105263157896,
    "Err": 0.004105263157894737,
    "TotalTime": 4.165675401687622
  },
  {
    "name": "exchange",
    "task_id": "HumanEval/110",
    "Dis": 0.21736842105263157,
    "Err": 0.1425263157894737,
    "TotalTime": 7.7751758098602295
  },
  {
    "name": "histogram",
    "task_id": "HumanEval/111",
    "Dis": 0.3005263157894737,
    "Err": 0.42747368421052634,
    "TotalTime": 3.018420934677124
  },
  {
    "name": "reverse_delete",
    "task_id": "HumanEval/112",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.860220193862915
  },
  {
    "name": "odd_count",
    "task_id": "HumanEval/113",
    "Dis": 0.16589473684210526,
    "Err": 0.08610526315789474,
    "TotalTime": 7.608532905578613
  },
  {
    "name": "minSubArraySum",
    "task_id": "HumanEval/114",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.206078767776489
  },
  {
    "name": "max_fill",
    "task_id": "HumanEval/115",
    "Dis": 0.5572631578947368,
    "Err": 0.4222105263157895,
    "TotalTime": 6.852876663208008
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/116",
    "Dis": 0.0,
    "Err": 0.3728421052631579,
    "TotalTime": 4.711919784545898
  },
  {
    "name": "select_words",
    "task_id": "HumanEval/117",
    "Dis": 0.024210526315789474,
    "Err": 0.044,
    "TotalTime": 3.699453592300415
  },
  {
    "name": "get_closest_vowel",
    "task_id": "HumanEval/118",
    "Dis": 0.22421052631578947,
    "Err": 0.18589473684210525,
    "TotalTime": 2.894862174987793
  },
  {
    "name": "match_parens",
    "task_id": "HumanEval/119",
    "Dis": 0.13094736842105262,
    "Err": 0.08210526315789474,
    "TotalTime": 5.278827905654907
  },
  {
    "name": "maximum",
    "task_id": "HumanEval/120",
    "Dis": 0.11747368421052631,
    "Err": 0.10178947368421053,
    "TotalTime": 4.401421308517456
  },
  {
    "name": "solution",
    "task_id": "HumanEval/121",
    "Dis": 0.31136842105263157,
    "Err": 0.19589473684210526,
    "TotalTime": 3.6357738971710205
  },
  {
    "name": "add_elements",
    "task_id": "HumanEval/122",
    "Dis": 0.2411578947368421,
    "Err": 0.2748421052631579,
    "TotalTime": 4.3382439613342285
  },
  {
    "name": "get_odd_collatz",
    "task_id": "HumanEval/123",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "valid_date",
    "task_id": "HumanEval/124",
    "Dis": 0.0074736842105263155,
    "Err": 0.018947368421052633,
    "TotalTime": 3.0321004390716553
  },
  {
    "name": "split_words",
    "task_id": "HumanEval/125",
    "Dis": 0.3582105263157895,
    "Err": 0.3350526315789474,
    "TotalTime": 2.8946220874786377
  },
  {
    "name": "is_sorted",
    "task_id": "HumanEval/126",
    "Dis": 0.0,
    "Err": 0.04831578947368421,
    "TotalTime": 3.9125118255615234
  },
  {
    "name": "intersection",
    "task_id": "HumanEval/127",
    "Dis": 0.33389473684210524,
    "Err": 0.26957894736842103,
    "TotalTime": 9.529410362243652
  },
  {
    "name": "prod_signs",
    "task_id": "HumanEval/128",
    "Dis": 0.005789473684210527,
    "Err": 0.003473684210526316,
    "TotalTime": 4.131152153015137
  },
  {
    "name": "minPath",
    "task_id": "HumanEval/129",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "tri",
    "task_id": "HumanEval/130",
    "Dis": 0.7488421052631579,
    "Err": 0.5821052631578948,
    "TotalTime": 3.8423011302948
  },
  {
    "name": "digits",
    "task_id": "HumanEval/131",
    "Dis": 0.11947368421052632,
    "Err": 0.07294736842105264,
    "TotalTime": 2.05965256690979
  },
  {
    "name": "is_nested",
    "task_id": "HumanEval/132",
    "Dis": 0.039473684210526314,
    "Err": 0.10694736842105264,
    "TotalTime": 2.8673202991485596
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/133",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.9396939277648926
  },
  {
    "name": "check_if_last_char_is_a_letter",
    "task_id": "HumanEval/134",
    "Dis": 0.2031578947368421,
    "Err": 0.14894736842105263,
    "TotalTime": 2.8186967372894287
  },
  {
    "name": "can_arrange",
    "task_id": "HumanEval/135",
    "Dis": 0.03673684210526316,
    "Err": 0.02168421052631579,
    "TotalTime": 3.8090295791625977
  },
  {
    "name": "largest_smallest_integers",
    "task_id": "HumanEval/136",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.116572141647339
  },
  {
    "name": "compare_one",
    "task_id": "HumanEval/137",
    "Dis": 0.03231578947368421,
    "Err": 0.020105263157894737,
    "TotalTime": 4.214533805847168
  },
  {
    "name": "is_equal_to_sum_even",
    "task_id": "HumanEval/138",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 19.775510787963867
  },
  {
    "name": "special_factorial",
    "task_id": "HumanEval/139",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "fix_spaces",
    "task_id": "HumanEval/140",
    "Dis": 0.0948421052631579,
    "Err": 0.114,
    "TotalTime": 3.1272618770599365
  },
  {
    "name": "file_name_check",
    "task_id": "HumanEval/141",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.9373867511749268
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/142",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.414377212524414
  },
  {
    "name": "words_in_sentence",
    "task_id": "HumanEval/143",
    "Dis": 0.35768421052631577,
    "Err": 0.19894736842105262,
    "TotalTime": 3.1098155975341797
  },
  {
    "name": "simplify",
    "task_id": "HumanEval/144",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "order_by_points",
    "task_id": "HumanEval/145",
    "Dis": 0.6027368421052631,
    "Err": 0.8024210526315789,
    "TotalTime": 5.1396496295928955
  },
  {
    "name": "specialFilter",
    "task_id": "HumanEval/146",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.144286632537842
  },
  {
    "name": "bf",
    "task_id": "HumanEval/148",
    "Dis": 0.0005263157894736842,
    "Err": 0.0002105263157894737,
    "TotalTime": 3.802499532699585
  },
  {
    "name": "sorted_list_sum",
    "task_id": "HumanEval/149",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 5.228330612182617
  },
  {
    "name": "x_or_y",
    "task_id": "HumanEval/150",
    "Dis": 0.0,
    "Err": 0.22178947368421054,
    "TotalTime": 3.3547604084014893
  },
  {
    "name": "double_the_difference",
    "task_id": "HumanEval/151",
    "Dis": 0.09084210526315789,
    "Err": 0.048842105263157895,
    "TotalTime": 6.22437858581543
  },
  {
    "name": "compare",
    "task_id": "HumanEval/152",
    "Dis": 0.28842105263157897,
    "Err": 0.18547368421052632,
    "TotalTime": 6.903874635696411
  },
  {
    "name": "Strongest_Extension",
    "task_id": "HumanEval/153",
    "Dis": 0.05957894736842105,
    "Err": 0.03831578947368421,
    "TotalTime": 7.061843156814575
  },
  {
    "name": "cycpattern_check",
    "task_id": "HumanEval/154",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "even_odd_count",
    "task_id": "HumanEval/155",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.203218460083008
  },
  {
    "name": "right_angle_triangle",
    "task_id": "HumanEval/157",
    "Dis": 0.0007368421052631579,
    "Err": 0.0013684210526315789,
    "TotalTime": 2.7461862564086914
  },
  {
    "name": "find_max",
    "task_id": "HumanEval/158",
    "Dis": 0.014421052631578947,
    "Err": 0.009263157894736843,
    "TotalTime": 4.887863397598267
  },
  {
    "name": "eat",
    "task_id": "HumanEval/159",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.846773386001587
  },
  {
    "name": "solve",
    "task_id": "HumanEval/161",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.9198801517486572
  },
  {
    "name": "string_to_md5",
    "task_id": "HumanEval/162",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.3995301723480225
  },
  {
    "name": "generate_integers",
    "task_id": "HumanEval/163",
    "Dis": 0.33873684210526317,
    "Err": 0.8633684210526316,
    "TotalTime": 2.7802646160125732
  }
]