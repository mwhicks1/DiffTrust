[
  {
    "name": "has_close_elements",
    "task_id": "HumanEval/0",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 232.77878737449646
  },
  {
    "name": "separate_paren_groups",
    "task_id": "HumanEval/1",
    "Dis": 0.534,
    "Err": 0.542,
    "TotalTime": 141.86036610603333
  },
  {
    "name": "truncate_number",
    "task_id": "HumanEval/2",
    "Dis": 0.0,
    "Err": 0.213,
    "TotalTime": 93.92192268371582
  },
  {
    "name": "below_zero",
    "task_id": "HumanEval/3",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 186.442973613739
  },
  {
    "name": "mean_absolute_deviation",
    "task_id": "HumanEval/4",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 274.3837671279907
  },
  {
    "name": "intersperse",
    "task_id": "HumanEval/5",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 140.24185800552368
  },
  {
    "name": "parse_nested_parens",
    "task_id": "HumanEval/6",
    "Dis": 0.0,
    "Err": 0.379,
    "TotalTime": 142.556138753891
  },
  {
    "name": "filter_by_substring",
    "task_id": "HumanEval/7",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 97.4770998954773
  },
  {
    "name": "sum_product",
    "task_id": "HumanEval/8",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 187.046706199646
  },
  {
    "name": "rolling_max",
    "task_id": "HumanEval/9",
    "Dis": 0.0,
    "Err": 0.018,
    "TotalTime": 140.48015904426575
  },
  {
    "name": "make_palindrome",
    "task_id": "HumanEval/10",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 95.35682225227356
  },
  {
    "name": "string_xor",
    "task_id": "HumanEval/11",
    "Dis": 0.0,
    "Err": 0.919,
    "TotalTime": 97.97872304916382
  },
  {
    "name": "longest",
    "task_id": "HumanEval/12",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 142.38957452774048
  },
  {
    "name": "greatest_common_divisor",
    "task_id": "HumanEval/13",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 139.75319242477417
  },
  {
    "name": "all_prefixes",
    "task_id": "HumanEval/14",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 322.1946940422058
  },
  {
    "name": "string_sequence",
    "task_id": "HumanEval/15",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 184.6005072593689
  },
  {
    "name": "count_distinct_characters",
    "task_id": "HumanEval/16",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 93.92669653892517
  },
  {
    "name": "parse_music",
    "task_id": "HumanEval/17",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 55.29682374000549
  },
  {
    "name": "how_many_times",
    "task_id": "HumanEval/18",
    "Dis": 0.037,
    "Err": 0.051,
    "TotalTime": 52.29948401451111
  },
  {
    "name": "sort_numbers",
    "task_id": "HumanEval/19",
    "Dis": 0.376,
    "Err": 0.273,
    "TotalTime": 52.85039710998535
  },
  {
    "name": "find_closest_elements",
    "task_id": "HumanEval/20",
    "Dis": 0.001,
    "Err": 0.001,
    "TotalTime": 51.84662961959839
  },
  {
    "name": "rescale_to_unit",
    "task_id": "HumanEval/21",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 141.08268117904663
  },
  {
    "name": "filter_integers",
    "task_id": "HumanEval/22",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 138.68683075904846
  },
  {
    "name": "strlen",
    "task_id": "HumanEval/23",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 182.7377631664276
  },
  {
    "name": "largest_divisor",
    "task_id": "HumanEval/24",
    "Dis": 0.042,
    "Err": 0.213,
    "TotalTime": 185.80429935455322
  },
  {
    "name": "remove_duplicates",
    "task_id": "HumanEval/26",
    "Dis": 0.099,
    "Err": 0.429,
    "TotalTime": 96.74088287353516
  },
  {
    "name": "flip_case",
    "task_id": "HumanEval/27",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 95.07323741912842
  },
  {
    "name": "concatenate",
    "task_id": "HumanEval/28",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 319.5885691642761
  },
  {
    "name": "filter_by_prefix",
    "task_id": "HumanEval/29",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 93.18846797943115
  },
  {
    "name": "get_positive",
    "task_id": "HumanEval/30",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 93.51022982597351
  },
  {
    "name": "is_prime",
    "task_id": "HumanEval/31",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 139.43248462677002
  },
  {
    "name": "unique",
    "task_id": "HumanEval/34",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 183.6595823764801
  },
  {
    "name": "max_element",
    "task_id": "HumanEval/35",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 98.3717770576477
  },
  {
    "name": "sort_even",
    "task_id": "HumanEval/37",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 50.34284710884094
  },
  {
    "name": "triples_sum_to_zero",
    "task_id": "HumanEval/40",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 274.6121039390564
  },
  {
    "name": "car_race_collision",
    "task_id": "HumanEval/41",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 185.8151183128357
  },
  {
    "name": "incr_list",
    "task_id": "HumanEval/42",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 95.84284400939941
  },
  {
    "name": "pairs_sum_to_zero",
    "task_id": "HumanEval/43",
    "Dis": 0.0,
    "Err": 0.009,
    "TotalTime": 94.53997755050659
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/45",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 93.24433732032776
  },
  {
    "name": "fib4",
    "task_id": "HumanEval/46",
    "Dis": 0.016,
    "Err": 0.014,
    "TotalTime": 138.9309787750244
  },
  {
    "name": "median",
    "task_id": "HumanEval/47",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 138.59858417510986
  },
  {
    "name": "is_palindrome",
    "task_id": "HumanEval/48",
    "Dis": 0.048,
    "Err": 0.114,
    "TotalTime": 276.27636218070984
  },
  {
    "name": "modp",
    "task_id": "HumanEval/49",
    "Dis": 0.184,
    "Err": 0.107,
    "TotalTime": 140.37888407707214
  },
  {
    "name": "remove_vowels",
    "task_id": "HumanEval/51",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 367.64675998687744
  },
  {
    "name": "below_threshold",
    "task_id": "HumanEval/52",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 137.1351442337036
  },
  {
    "name": "add",
    "task_id": "HumanEval/53",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 92.19160890579224
  },
  {
    "name": "same_chars",
    "task_id": "HumanEval/54",
    "Dis": 0.002,
    "Err": 0.005,
    "TotalTime": 95.10359573364258
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/56",
    "Dis": 0.0,
    "Err": 0.405,
    "TotalTime": 138.9495289325714
  },
  {
    "name": "monotonic",
    "task_id": "HumanEval/57",
    "Dis": 0.051,
    "Err": 0.021,
    "TotalTime": 416.6582934856415
  },
  {
    "name": "common",
    "task_id": "HumanEval/58",
    "Dis": 0.0,
    "Err": 0.375,
    "TotalTime": 47.90542411804199
  },
  {
    "name": "sum_to_n",
    "task_id": "HumanEval/60",
    "Dis": 0.036,
    "Err": 0.022,
    "TotalTime": 230.59292793273926
  },
  {
    "name": "derivative",
    "task_id": "HumanEval/62",
    "Dis": 0.17,
    "Err": 0.097,
    "TotalTime": 94.64933109283447
  },
  {
    "name": "vowels_count",
    "task_id": "HumanEval/64",
    "Dis": 0.028,
    "Err": 0.02,
    "TotalTime": 94.88889145851135
  },
  {
    "name": "circular_shift",
    "task_id": "HumanEval/65",
    "Dis": 0.223,
    "Err": 0.216,
    "TotalTime": 277.9548165798187
  },
  {
    "name": "digitSum",
    "task_id": "HumanEval/66",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 186.58969521522522
  },
  {
    "name": "fruit_distribution",
    "task_id": "HumanEval/67",
    "Dis": 0.528,
    "Err": 0.724,
    "TotalTime": 325.339560508728
  },
  {
    "name": "pluck",
    "task_id": "HumanEval/68",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 139.38201022148132
  },
  {
    "name": "search",
    "task_id": "HumanEval/69",
    "Dis": 0.165,
    "Err": 0.222,
    "TotalTime": 54.67237067222595
  },
  {
    "name": "strange_sort_list",
    "task_id": "HumanEval/70",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 235.49061965942383
  },
  {
    "name": "will_it_fly",
    "task_id": "HumanEval/72",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 93.55628871917725
  },
  {
    "name": "smallest_change",
    "task_id": "HumanEval/73",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 147.11046957969666
  },
  {
    "name": "total_match",
    "task_id": "HumanEval/74",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 143.5639090538025
  },
  {
    "name": "iscube",
    "task_id": "HumanEval/77",
    "Dis": 0.551,
    "Err": 0.592,
    "TotalTime": 95.96792411804199
  },
  {
    "name": "hex_key",
    "task_id": "HumanEval/78",
    "Dis": 0.0,
    "Err": 0.039,
    "TotalTime": 142.8218104839325
  },
  {
    "name": "decimal_to_binary",
    "task_id": "HumanEval/79",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 50.86138916015625
  },
  {
    "name": "is_happy",
    "task_id": "HumanEval/80",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 279.09220147132874
  },
  {
    "name": "numerical_letter_grade",
    "task_id": "HumanEval/81",
    "Dis": 0.427,
    "Err": 0.711,
    "TotalTime": 185.610187292099
  },
  {
    "name": "prime_length",
    "task_id": "HumanEval/82",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 52.12583875656128
  },
  {
    "name": "solve",
    "task_id": "HumanEval/84",
    "Dis": 0.466,
    "Err": 0.288,
    "TotalTime": 140.02651929855347
  },
  {
    "name": "anti_shuffle",
    "task_id": "HumanEval/86",
    "Dis": 0.155,
    "Err": 0.146,
    "TotalTime": 94.62767124176025
  },
  {
    "name": "get_row",
    "task_id": "HumanEval/87",
    "Dis": 0.098,
    "Err": 0.058,
    "TotalTime": 139.5274920463562
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/88",
    "Dis": 0.01,
    "Err": 0.0,
    "TotalTime": 96.9197199344635
  },
  {
    "name": "encrypt",
    "task_id": "HumanEval/89",
    "Dis": 0.242,
    "Err": 0.423,
    "TotalTime": 141.69254183769226
  },
  {
    "name": "next_smallest",
    "task_id": "HumanEval/90",
    "Dis": 0.0,
    "Err": 0.011,
    "TotalTime": 94.39161992073059
  },
  {
    "name": "is_bored",
    "task_id": "HumanEval/91",
    "Dis": 0.706,
    "Err": 0.825,
    "TotalTime": 142.23849749565125
  },
  {
    "name": "any_int",
    "task_id": "HumanEval/92",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 94.57867383956909
  },
  {
    "name": "encode",
    "task_id": "HumanEval/93",
    "Dis": 0.146,
    "Err": 0.453,
    "TotalTime": 229.8727900981903
  },
  {
    "name": "skjkasdkd",
    "task_id": "HumanEval/94",
    "Dis": 0.0,
    "Err": 0.019,
    "TotalTime": 98.24554586410522
  },
  {
    "name": "check_dict_case",
    "task_id": "HumanEval/95",
    "Dis": 0.362,
    "Err": 0.805,
    "TotalTime": 97.75712776184082
  },
  {
    "name": "count_up_to",
    "task_id": "HumanEval/96",
    "Dis": 0.35,
    "Err": 0.216,
    "TotalTime": 6.463196039199829
  },
  {
    "name": "multiply",
    "task_id": "HumanEval/97",
    "Dis": 0.0,
    "Err": 0.245,
    "TotalTime": 51.22932696342468
  },
  {
    "name": "count_upper",
    "task_id": "HumanEval/98",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 142.29146003723145
  },
  {
    "name": "closest_integer",
    "task_id": "HumanEval/99",
    "Dis": 0.073,
    "Err": 0.089,
    "TotalTime": 139.7351131439209
  },
  {
    "name": "make_a_pile",
    "task_id": "HumanEval/100",
    "Dis": 0.265,
    "Err": 0.693,
    "TotalTime": 325.02749276161194
  },
  {
    "name": "words_string",
    "task_id": "HumanEval/101",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 95.15475583076477
  },
  {
    "name": "choose_num",
    "task_id": "HumanEval/102",
    "Dis": 0.319,
    "Err": 0.391,
    "TotalTime": 138.99202799797058
  },
  {
    "name": "rounded_avg",
    "task_id": "HumanEval/103",
    "Dis": 0.062,
    "Err": 0.068,
    "TotalTime": 232.88855576515198
  },
  {
    "name": "unique_digits",
    "task_id": "HumanEval/104",
    "Dis": 0.022,
    "Err": 0.011,
    "TotalTime": 95.86505699157715
  },
  {
    "name": "by_length",
    "task_id": "HumanEval/105",
    "Dis": 0.005,
    "Err": 0.066,
    "TotalTime": 141.54687666893005
  },
  {
    "name": "f",
    "task_id": "HumanEval/106",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 141.0541534423828
  },
  {
    "name": "even_odd_palindrome",
    "task_id": "HumanEval/107",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 50.889082193374634
  },
  {
    "name": "count_nums",
    "task_id": "HumanEval/108",
    "Dis": 0.522,
    "Err": 0.44,
    "TotalTime": 139.38845467567444
  },
  {
    "name": "move_one_ball",
    "task_id": "HumanEval/109",
    "Dis": 0.059,
    "Err": 0.048,
    "TotalTime": 138.72863006591797
  },
  {
    "name": "exchange",
    "task_id": "HumanEval/110",
    "Dis": 0.059,
    "Err": 0.042,
    "TotalTime": 190.8189549446106
  },
  {
    "name": "histogram",
    "task_id": "HumanEval/111",
    "Dis": 0.002,
    "Err": 0.321,
    "TotalTime": 365.85417199134827
  },
  {
    "name": "reverse_delete",
    "task_id": "HumanEval/112",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 48.30487895011902
  },
  {
    "name": "odd_count",
    "task_id": "HumanEval/113",
    "Dis": 0.008,
    "Err": 0.025,
    "TotalTime": 140.9757125377655
  },
  {
    "name": "minSubArraySum",
    "task_id": "HumanEval/114",
    "Dis": 0.123,
    "Err": 0.061,
    "TotalTime": 186.15828442573547
  },
  {
    "name": "max_fill",
    "task_id": "HumanEval/115",
    "Dis": 0.733,
    "Err": 0.765,
    "TotalTime": 237.80585074424744
  },
  {
    "name": "select_words",
    "task_id": "HumanEval/117",
    "Dis": 0.007,
    "Err": 0.063,
    "TotalTime": 322.7847754955292
  },
  {
    "name": "get_closest_vowel",
    "task_id": "HumanEval/118",
    "Dis": 0.022,
    "Err": 0.004,
    "TotalTime": 48.47991585731506
  },
  {
    "name": "match_parens",
    "task_id": "HumanEval/119",
    "Dis": 0.145,
    "Err": 0.544,
    "TotalTime": 143.2651722431183
  },
  {
    "name": "maximum",
    "task_id": "HumanEval/120",
    "Dis": 0.0,
    "Err": 0.553,
    "TotalTime": 139.24062490463257
  },
  {
    "name": "solution",
    "task_id": "HumanEval/121",
    "Dis": 0.0,
    "Err": 0.033,
    "TotalTime": 94.57802486419678
  },
  {
    "name": "add_elements",
    "task_id": "HumanEval/122",
    "Dis": 0.23,
    "Err": 0.444,
    "TotalTime": 138.54491353034973
  },
  {
    "name": "valid_date",
    "task_id": "HumanEval/124",
    "Dis": 0.009,
    "Err": 0.017,
    "TotalTime": 97.02815008163452
  },
  {
    "name": "split_words",
    "task_id": "HumanEval/125",
    "Dis": 0.205,
    "Err": 0.129,
    "TotalTime": 274.1408932209015
  },
  {
    "name": "is_sorted",
    "task_id": "HumanEval/126",
    "Dis": 0.001,
    "Err": 0.1,
    "TotalTime": 98.90932726860046
  },
  {
    "name": "intersection",
    "task_id": "HumanEval/127",
    "Dis": 0.242,
    "Err": 0.226,
    "TotalTime": 277.0074625015259
  },
  {
    "name": "prod_signs",
    "task_id": "HumanEval/128",
    "Dis": 0.126,
    "Err": 0.09,
    "TotalTime": 231.1689224243164
  },
  {
    "name": "tri",
    "task_id": "HumanEval/130",
    "Dis": 0.0,
    "Err": 1.0,
    "TotalTime": 189.5239760875702
  },
  {
    "name": "digits",
    "task_id": "HumanEval/131",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 47.528504610061646
  },
  {
    "name": "is_nested",
    "task_id": "HumanEval/132",
    "Dis": 0.407,
    "Err": 0.408,
    "TotalTime": 187.4040288925171
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/133",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 140.21240329742432
  },
  {
    "name": "check_if_last_char_is_a_letter",
    "task_id": "HumanEval/134",
    "Dis": 0.283,
    "Err": 0.298,
    "TotalTime": 184.76578521728516
  },
  {
    "name": "can_arrange",
    "task_id": "HumanEval/135",
    "Dis": 0.413,
    "Err": 0.246,
    "TotalTime": 94.86190629005432
  },
  {
    "name": "largest_smallest_integers",
    "task_id": "HumanEval/136",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 138.8838677406311
  },
  {
    "name": "compare_one",
    "task_id": "HumanEval/137",
    "Dis": 0.461,
    "Err": 0.304,
    "TotalTime": 52.45888018608093
  },
  {
    "name": "is_equal_to_sum_even",
    "task_id": "HumanEval/138",
    "Dis": 0.087,
    "Err": 0.136,
    "TotalTime": 138.6960587501526
  },
  {
    "name": "fix_spaces",
    "task_id": "HumanEval/140",
    "Dis": 0.5,
    "Err": 0.489,
    "TotalTime": 320.6236455440521
  },
  {
    "name": "file_name_check",
    "task_id": "HumanEval/141",
    "Dis": 0.006,
    "Err": 0.003,
    "TotalTime": 96.01301288604736
  },
  {
    "name": "words_in_sentence",
    "task_id": "HumanEval/143",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 50.40762710571289
  },
  {
    "name": "simplify",
    "task_id": "HumanEval/144",
    "Dis": 0.185,
    "Err": 0.096,
    "TotalTime": 291.5895199775696
  },
  {
    "name": "order_by_points",
    "task_id": "HumanEval/145",
    "Dis": 0.037,
    "Err": 0.708,
    "TotalTime": 93.59780263900757
  },
  {
    "name": "specialFilter",
    "task_id": "HumanEval/146",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 141.82601308822632
  },
  {
    "name": "bf",
    "task_id": "HumanEval/148",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 95.84959745407104
  },
  {
    "name": "x_or_y",
    "task_id": "HumanEval/150",
    "Dis": 0.0,
    "Err": 0.205,
    "TotalTime": 232.9158034324646
  },
  {
    "name": "double_the_difference",
    "task_id": "HumanEval/151",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 230.78975820541382
  },
  {
    "name": "compare",
    "task_id": "HumanEval/152",
    "Dis": 0.42,
    "Err": 0.547,
    "TotalTime": 93.18515062332153
  },
  {
    "name": "Strongest_Extension",
    "task_id": "HumanEval/153",
    "Dis": 0.013,
    "Err": 0.008,
    "TotalTime": 141.6192865371704
  },
  {
    "name": "cycpattern_check",
    "task_id": "HumanEval/154",
    "Dis": 0.0,
    "Err": 0.044,
    "TotalTime": 183.91914057731628
  },
  {
    "name": "even_odd_count",
    "task_id": "HumanEval/155",
    "Dis": 0.548,
    "Err": 0.499,
    "TotalTime": 95.77874445915222
  },
  {
    "name": "right_angle_triangle",
    "task_id": "HumanEval/157",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 98.78993391990662
  },
  {
    "name": "find_max",
    "task_id": "HumanEval/158",
    "Dis": 0.022,
    "Err": 0.033,
    "TotalTime": 93.59819769859314
  },
  {
    "name": "eat",
    "task_id": "HumanEval/159",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 276.2511191368103
  },
  {
    "name": "string_to_md5",
    "task_id": "HumanEval/162",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 49.42493438720703
  },
  {
    "name": "generate_integers",
    "task_id": "HumanEval/163",
    "Dis": 0.117,
    "Err": 0.976,
    "TotalTime": 230.7244894504547
  }
]