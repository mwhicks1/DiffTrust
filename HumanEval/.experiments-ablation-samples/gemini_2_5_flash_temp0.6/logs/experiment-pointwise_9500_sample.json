[
  {
    "name": "has_close_elements",
    "task_id": "HumanEval/0",
    "Dis": 0.03178947368421053,
    "Err": 0.035263157894736843,
    "TotalTime": 4.698894739151001
  },
  {
    "name": "separate_paren_groups",
    "task_id": "HumanEval/1",
    "Dis": 0.0,
    "Err": 0.6103157894736843,
    "TotalTime": 3.296358346939087
  },
  {
    "name": "truncate_number",
    "task_id": "HumanEval/2",
    "Dis": 0.0,
    "Err": 0.21547368421052632,
    "TotalTime": 2.477414846420288
  },
  {
    "name": "below_zero",
    "task_id": "HumanEval/3",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.138964653015137
  },
  {
    "name": "mean_absolute_deviation",
    "task_id": "HumanEval/4",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.218756198883057
  },
  {
    "name": "intersperse",
    "task_id": "HumanEval/5",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.863765001296997
  },
  {
    "name": "parse_nested_parens",
    "task_id": "HumanEval/6",
    "Dis": 0.13631578947368422,
    "Err": 0.3376842105263158,
    "TotalTime": 3.206468343734741
  },
  {
    "name": "filter_by_substring",
    "task_id": "HumanEval/7",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 6.081536531448364
  },
  {
    "name": "sum_product",
    "task_id": "HumanEval/8",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.301788091659546
  },
  {
    "name": "rolling_max",
    "task_id": "HumanEval/9",
    "Dis": 0.032105263157894734,
    "Err": 0.06936842105263158,
    "TotalTime": 4.102327108383179
  },
  {
    "name": "make_palindrome",
    "task_id": "HumanEval/10",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.333446979522705
  },
  {
    "name": "string_xor",
    "task_id": "HumanEval/11",
    "Dis": 0.20694736842105263,
    "Err": 0.8809473684210526,
    "TotalTime": 4.387621164321899
  },
  {
    "name": "longest",
    "task_id": "HumanEval/12",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.655788898468018
  },
  {
    "name": "greatest_common_divisor",
    "task_id": "HumanEval/13",
    "Dis": 0.0,
    "Err": 0.19421052631578947,
    "TotalTime": 2.6610639095306396
  },
  {
    "name": "all_prefixes",
    "task_id": "HumanEval/14",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.2594940662384033
  },
  {
    "name": "string_sequence",
    "task_id": "HumanEval/15",
    "Dis": 0.06757894736842106,
    "Err": 0.03442105263157895,
    "TotalTime": 2.605020761489868
  },
  {
    "name": "count_distinct_characters",
    "task_id": "HumanEval/16",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.0743632316589355
  },
  {
    "name": "parse_music",
    "task_id": "HumanEval/17",
    "Dis": 0.22442105263157894,
    "Err": 0.12505263157894736,
    "TotalTime": 7.2652764320373535
  },
  {
    "name": "how_many_times",
    "task_id": "HumanEval/18",
    "Dis": 0.016,
    "Err": 0.0070526315789473685,
    "TotalTime": 4.037718057632446
  },
  {
    "name": "sort_numbers",
    "task_id": "HumanEval/19",
    "Dis": 0.03568421052631579,
    "Err": 0.02526315789473684,
    "TotalTime": 10.240484237670898
  },
  {
    "name": "find_closest_elements",
    "task_id": "HumanEval/20",
    "Dis": 0.0007368421052631579,
    "Err": 0.003368421052631579,
    "TotalTime": 4.520246267318726
  },
  {
    "name": "rescale_to_unit",
    "task_id": "HumanEval/21",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.487023115158081
  },
  {
    "name": "filter_integers",
    "task_id": "HumanEval/22",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.058159351348877
  },
  {
    "name": "strlen",
    "task_id": "HumanEval/23",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.004668951034546
  },
  {
    "name": "largest_divisor",
    "task_id": "HumanEval/24",
    "Dis": 0.1723157894736842,
    "Err": 0.15105263157894736,
    "TotalTime": 2.4141063690185547
  },
  {
    "name": "factorize",
    "task_id": "HumanEval/25",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "remove_duplicates",
    "task_id": "HumanEval/26",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.128598928451538
  },
  {
    "name": "flip_case",
    "task_id": "HumanEval/27",
    "Dis": 0.08621052631578947,
    "Err": 0.043789473684210524,
    "TotalTime": 3.124734878540039
  },
  {
    "name": "concatenate",
    "task_id": "HumanEval/28",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 5.080329895019531
  },
  {
    "name": "filter_by_prefix",
    "task_id": "HumanEval/29",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 7.136207580566406
  },
  {
    "name": "get_positive",
    "task_id": "HumanEval/30",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.290367364883423
  },
  {
    "name": "is_prime",
    "task_id": "HumanEval/31",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.8540878295898438
  },
  {
    "name": "unique",
    "task_id": "HumanEval/34",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.402815580368042
  },
  {
    "name": "max_element",
    "task_id": "HumanEval/35",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.380311012268066
  },
  {
    "name": "sort_even",
    "task_id": "HumanEval/37",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.324885368347168
  },
  {
    "name": "triples_sum_to_zero",
    "task_id": "HumanEval/40",
    "Dis": 0.0016842105263157896,
    "Err": 0.0017894736842105263,
    "TotalTime": 4.011004447937012
  },
  {
    "name": "car_race_collision",
    "task_id": "HumanEval/41",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.3631081581115723
  },
  {
    "name": "incr_list",
    "task_id": "HumanEval/42",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.366974115371704
  },
  {
    "name": "pairs_sum_to_zero",
    "task_id": "HumanEval/43",
    "Dis": 0.006842105263157895,
    "Err": 0.012421052631578947,
    "TotalTime": 4.130817651748657
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/45",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.730374574661255
  },
  {
    "name": "fib4",
    "task_id": "HumanEval/46",
    "Dis": 0.034842105263157896,
    "Err": 0.04536842105263158,
    "TotalTime": 2.7291245460510254
  },
  {
    "name": "median",
    "task_id": "HumanEval/47",
    "Dis": 0.2083157894736842,
    "Err": 0.1511578947368421,
    "TotalTime": 4.263473749160767
  },
  {
    "name": "is_palindrome",
    "task_id": "HumanEval/48",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.025299549102783
  },
  {
    "name": "modp",
    "task_id": "HumanEval/49",
    "Dis": 0.0,
    "Err": 0.20210526315789473,
    "TotalTime": 2.971855640411377
  },
  {
    "name": "remove_vowels",
    "task_id": "HumanEval/51",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.1265151500701904
  },
  {
    "name": "below_threshold",
    "task_id": "HumanEval/52",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.241737365722656
  },
  {
    "name": "add",
    "task_id": "HumanEval/53",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.761997699737549
  },
  {
    "name": "same_chars",
    "task_id": "HumanEval/54",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.052192449569702
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/56",
    "Dis": 0.0,
    "Err": 0.4069473684210526,
    "TotalTime": 3.1738710403442383
  },
  {
    "name": "monotonic",
    "task_id": "HumanEval/57",
    "Dis": 0.00010526315789473685,
    "Err": 0.0,
    "TotalTime": 4.0647594928741455
  },
  {
    "name": "common",
    "task_id": "HumanEval/58",
    "Dis": 0.0,
    "Err": 0.36957894736842106,
    "TotalTime": 5.2242536544799805
  },
  {
    "name": "largest_prime_factor",
    "task_id": "HumanEval/59",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "sum_to_n",
    "task_id": "HumanEval/60",
    "Dis": 0.0,
    "Err": 0.21452631578947368,
    "TotalTime": 2.421344757080078
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/61",
    "Dis": 0.0,
    "Err": 0.41336842105263155,
    "TotalTime": 3.1382992267608643
  },
  {
    "name": "derivative",
    "task_id": "HumanEval/62",
    "Dis": 0.03252631578947368,
    "Err": 0.018947368421052633,
    "TotalTime": 3.9287590980529785
  },
  {
    "name": "vowels_count",
    "task_id": "HumanEval/64",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.160121202468872
  },
  {
    "name": "circular_shift",
    "task_id": "HumanEval/65",
    "Dis": 0.048,
    "Err": 0.13042105263157894,
    "TotalTime": 2.7671704292297363
  },
  {
    "name": "digitSum",
    "task_id": "HumanEval/66",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.1313681602478027
  },
  {
    "name": "fruit_distribution",
    "task_id": "HumanEval/67",
    "Dis": 0.4763157894736842,
    "Err": 0.8312631578947368,
    "TotalTime": 3.866115093231201
  },
  {
    "name": "pluck",
    "task_id": "HumanEval/68",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.356458902359009
  },
  {
    "name": "search",
    "task_id": "HumanEval/69",
    "Dis": 0.06073684210526316,
    "Err": 0.13736842105263158,
    "TotalTime": 5.3379974365234375
  },
  {
    "name": "strange_sort_list",
    "task_id": "HumanEval/70",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.937981367111206
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/71",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.017681360244751
  },
  {
    "name": "will_it_fly",
    "task_id": "HumanEval/72",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.636213779449463
  },
  {
    "name": "smallest_change",
    "task_id": "HumanEval/73",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.612060785293579
  },
  {
    "name": "total_match",
    "task_id": "HumanEval/74",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 9.107676982879639
  },
  {
    "name": "iscube",
    "task_id": "HumanEval/77",
    "Dis": 0.04621052631578947,
    "Err": 0.023263157894736843,
    "TotalTime": 2.474695920944214
  },
  {
    "name": "hex_key",
    "task_id": "HumanEval/78",
    "Dis": 0.3156842105263158,
    "Err": 0.24010526315789474,
    "TotalTime": 3.2426061630249023
  },
  {
    "name": "decimal_to_binary",
    "task_id": "HumanEval/79",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.416024684906006
  },
  {
    "name": "is_happy",
    "task_id": "HumanEval/80",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.0935535430908203
  },
  {
    "name": "numerical_letter_grade",
    "task_id": "HumanEval/81",
    "Dis": 0.2431578947368421,
    "Err": 0.28021052631578947,
    "TotalTime": 4.398881673812866
  },
  {
    "name": "prime_length",
    "task_id": "HumanEval/82",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.2711308002471924
  },
  {
    "name": "starts_one_ends",
    "task_id": "HumanEval/83",
    "Dis": 0.18168421052631578,
    "Err": 0.1248421052631579,
    "TotalTime": 2.47737717628479
  },
  {
    "name": "solve",
    "task_id": "HumanEval/84",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.467832326889038
  },
  {
    "name": "add",
    "task_id": "HumanEval/85",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.7060935497283936
  },
  {
    "name": "anti_shuffle",
    "task_id": "HumanEval/86",
    "Dis": 0.112,
    "Err": 0.07557894736842105,
    "TotalTime": 3.209928274154663
  },
  {
    "name": "get_row",
    "task_id": "HumanEval/87",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 7.118559122085571
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/88",
    "Dis": 0.010210526315789474,
    "Err": 0.009157894736842104,
    "TotalTime": 4.229732275009155
  },
  {
    "name": "encrypt",
    "task_id": "HumanEval/89",
    "Dis": 0.22136842105263158,
    "Err": 0.19126315789473683,
    "TotalTime": 3.1635243892669678
  },
  {
    "name": "next_smallest",
    "task_id": "HumanEval/90",
    "Dis": 0.007894736842105263,
    "Err": 0.0046315789473684215,
    "TotalTime": 4.119365453720093
  },
  {
    "name": "is_bored",
    "task_id": "HumanEval/91",
    "Dis": 0.005894736842105263,
    "Err": 0.01431578947368421,
    "TotalTime": 3.145109176635742
  },
  {
    "name": "any_int",
    "task_id": "HumanEval/92",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.069383382797241
  },
  {
    "name": "encode",
    "task_id": "HumanEval/93",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.1740381717681885
  },
  {
    "name": "skjkasdkd",
    "task_id": "HumanEval/94",
    "Dis": 0.09105263157894737,
    "Err": 0.08831578947368421,
    "TotalTime": 5.606964349746704
  },
  {
    "name": "check_dict_case",
    "task_id": "HumanEval/95",
    "Dis": 0.01368421052631579,
    "Err": 0.016210526315789474,
    "TotalTime": 4.260512590408325
  },
  {
    "name": "count_up_to",
    "task_id": "HumanEval/96",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.2812318801879883
  },
  {
    "name": "multiply",
    "task_id": "HumanEval/97",
    "Dis": 0.046,
    "Err": 0.025052631578947368,
    "TotalTime": 2.6655056476593018
  },
  {
    "name": "count_upper",
    "task_id": "HumanEval/98",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.9514756202697754
  },
  {
    "name": "closest_integer",
    "task_id": "HumanEval/99",
    "Dis": 0.0,
    "Err": 0.0002105263157894737,
    "TotalTime": 7.077915191650391
  },
  {
    "name": "make_a_pile",
    "task_id": "HumanEval/100",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.471736431121826
  },
  {
    "name": "words_string",
    "task_id": "HumanEval/101",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.041398048400879
  },
  {
    "name": "choose_num",
    "task_id": "HumanEval/102",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.734323024749756
  },
  {
    "name": "rounded_avg",
    "task_id": "HumanEval/103",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.898668050765991
  },
  {
    "name": "unique_digits",
    "task_id": "HumanEval/104",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.7725677490234375
  },
  {
    "name": "by_length",
    "task_id": "HumanEval/105",
    "Dis": 0.027473684210526317,
    "Err": 0.05578947368421053,
    "TotalTime": 4.1193528175354
  },
  {
    "name": "f",
    "task_id": "HumanEval/106",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.8945693969726562
  },
  {
    "name": "even_odd_palindrome",
    "task_id": "HumanEval/107",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.8906350135803223
  },
  {
    "name": "count_nums",
    "task_id": "HumanEval/108",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.671489953994751
  },
  {
    "name": "move_one_ball",
    "task_id": "HumanEval/109",
    "Dis": 0.007894736842105263,
    "Err": 0.009263157894736843,
    "TotalTime": 4.125037670135498
  },
  {
    "name": "exchange",
    "task_id": "HumanEval/110",
    "Dis": 0.0,
    "Err": 0.011894736842105263,
    "TotalTime": 7.6592116355896
  },
  {
    "name": "histogram",
    "task_id": "HumanEval/111",
    "Dis": 0.0,
    "Err": 0.30905263157894736,
    "TotalTime": 3.260796308517456
  },
  {
    "name": "reverse_delete",
    "task_id": "HumanEval/112",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.153260231018066
  },
  {
    "name": "odd_count",
    "task_id": "HumanEval/113",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 7.681195974349976
  },
  {
    "name": "minSubArraySum",
    "task_id": "HumanEval/114",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.15571665763855
  },
  {
    "name": "max_fill",
    "task_id": "HumanEval/115",
    "Dis": 0.1036842105263158,
    "Err": 0.22831578947368422,
    "TotalTime": 7.065871000289917
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/116",
    "Dis": 0.26873684210526316,
    "Err": 0.5611578947368421,
    "TotalTime": 4.3995490074157715
  },
  {
    "name": "select_words",
    "task_id": "HumanEval/117",
    "Dis": 0.02336842105263158,
    "Err": 0.044,
    "TotalTime": 3.6743528842926025
  },
  {
    "name": "get_closest_vowel",
    "task_id": "HumanEval/118",
    "Dis": 0.12105263157894737,
    "Err": 0.08610526315789474,
    "TotalTime": 3.4267661571502686
  },
  {
    "name": "match_parens",
    "task_id": "HumanEval/119",
    "Dis": 0.11842105263157894,
    "Err": 0.2231578947368421,
    "TotalTime": 5.489008188247681
  },
  {
    "name": "maximum",
    "task_id": "HumanEval/120",
    "Dis": 0.09189473684210527,
    "Err": 0.0731578947368421,
    "TotalTime": 4.65842604637146
  },
  {
    "name": "solution",
    "task_id": "HumanEval/121",
    "Dis": 0.0,
    "Err": 0.030105263157894736,
    "TotalTime": 3.863680839538574
  },
  {
    "name": "add_elements",
    "task_id": "HumanEval/122",
    "Dis": 0.09747368421052631,
    "Err": 0.4663157894736842,
    "TotalTime": 4.354306936264038
  },
  {
    "name": "get_odd_collatz",
    "task_id": "HumanEval/123",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "valid_date",
    "task_id": "HumanEval/124",
    "Dis": 0.014421052631578947,
    "Err": 0.013157894736842105,
    "TotalTime": 3.069486379623413
  },
  {
    "name": "split_words",
    "task_id": "HumanEval/125",
    "Dis": 0.03063157894736842,
    "Err": 0.2537894736842105,
    "TotalTime": 3.218949794769287
  },
  {
    "name": "is_sorted",
    "task_id": "HumanEval/126",
    "Dis": 0.002842105263157895,
    "Err": 0.003368421052631579,
    "TotalTime": 4.061132192611694
  },
  {
    "name": "intersection",
    "task_id": "HumanEval/127",
    "Dis": 0.021368421052631578,
    "Err": 0.7362105263157894,
    "TotalTime": 10.01874566078186
  },
  {
    "name": "prod_signs",
    "task_id": "HumanEval/128",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.194128751754761
  },
  {
    "name": "minPath",
    "task_id": "HumanEval/129",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "tri",
    "task_id": "HumanEval/130",
    "Dis": 0.3178947368421053,
    "Err": 0.4049473684210526,
    "TotalTime": 2.631664752960205
  },
  {
    "name": "digits",
    "task_id": "HumanEval/131",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.3898916244506836
  },
  {
    "name": "is_nested",
    "task_id": "HumanEval/132",
    "Dis": 0.015473684210526317,
    "Err": 0.09357894736842105,
    "TotalTime": 3.247830867767334
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/133",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.126782655715942
  },
  {
    "name": "check_if_last_char_is_a_letter",
    "task_id": "HumanEval/134",
    "Dis": 0.03178947368421053,
    "Err": 0.025894736842105262,
    "TotalTime": 2.940858840942383
  },
  {
    "name": "can_arrange",
    "task_id": "HumanEval/135",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.9943177700042725
  },
  {
    "name": "largest_smallest_integers",
    "task_id": "HumanEval/136",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.293816089630127
  },
  {
    "name": "compare_one",
    "task_id": "HumanEval/137",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.359147071838379
  },
  {
    "name": "is_equal_to_sum_even",
    "task_id": "HumanEval/138",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.394196033477783
  },
  {
    "name": "special_factorial",
    "task_id": "HumanEval/139",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "fix_spaces",
    "task_id": "HumanEval/140",
    "Dis": 0.0851578947368421,
    "Err": 0.04673684210526316,
    "TotalTime": 3.1537327766418457
  },
  {
    "name": "file_name_check",
    "task_id": "HumanEval/141",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.023545265197754
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/142",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.4052910804748535
  },
  {
    "name": "words_in_sentence",
    "task_id": "HumanEval/143",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.425278425216675
  },
  {
    "name": "simplify",
    "task_id": "HumanEval/144",
    "Dis": 0.0008421052631578948,
    "Err": 0.0013684210526315789,
    "TotalTime": 119.35397291183472
  },
  {
    "name": "order_by_points",
    "task_id": "HumanEval/145",
    "Dis": 0.13957894736842105,
    "Err": 0.6285263157894737,
    "TotalTime": 5.345665216445923
  },
  {
    "name": "specialFilter",
    "task_id": "HumanEval/146",
    "Dis": 0.00031578947368421053,
    "Err": 0.0007368421052631579,
    "TotalTime": 4.102517127990723
  },
  {
    "name": "bf",
    "task_id": "HumanEval/148",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.0622851848602295
  },
  {
    "name": "sorted_list_sum",
    "task_id": "HumanEval/149",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 5.393001079559326
  },
  {
    "name": "x_or_y",
    "task_id": "HumanEval/150",
    "Dis": 0.0,
    "Err": 0.22105263157894736,
    "TotalTime": 3.4803318977355957
  },
  {
    "name": "double_the_difference",
    "task_id": "HumanEval/151",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 6.301288604736328
  },
  {
    "name": "compare",
    "task_id": "HumanEval/152",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 6.864027500152588
  },
  {
    "name": "Strongest_Extension",
    "task_id": "HumanEval/153",
    "Dis": 0.009157894736842104,
    "Err": 0.006,
    "TotalTime": 6.748308181762695
  },
  {
    "name": "cycpattern_check",
    "task_id": "HumanEval/154",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.019424676895142
  },
  {
    "name": "even_odd_count",
    "task_id": "HumanEval/155",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.3924994468688965
  },
  {
    "name": "right_angle_triangle",
    "task_id": "HumanEval/157",
    "Dis": 0.0008421052631578948,
    "Err": 0.0015789473684210526,
    "TotalTime": 2.9771249294281006
  },
  {
    "name": "find_max",
    "task_id": "HumanEval/158",
    "Dis": 0.0004210526315789474,
    "Err": 0.002,
    "TotalTime": 4.923595190048218
  },
  {
    "name": "eat",
    "task_id": "HumanEval/159",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.0524091720581055
  },
  {
    "name": "solve",
    "task_id": "HumanEval/161",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.154906749725342
  },
  {
    "name": "string_to_md5",
    "task_id": "HumanEval/162",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.6236684322357178
  },
  {
    "name": "generate_integers",
    "task_id": "HumanEval/163",
    "Dis": 0.29757894736842105,
    "Err": 0.29126315789473683,
    "TotalTime": 2.796769380569458
  }
]