[
  {
    "name": "has_close_elements",
    "task_id": "HumanEval/0",
    "Dis": 0.0,
    "Err": 0.0548,
    "TotalTime": 4.4395036697387695
  },
  {
    "name": "separate_paren_groups",
    "task_id": "HumanEval/1",
    "Dis": 0.31106666666666666,
    "Err": 0.19453333333333334,
    "TotalTime": 2.973705530166626
  },
  {
    "name": "truncate_number",
    "task_id": "HumanEval/2",
    "Dis": 0.0,
    "Err": 0.216,
    "TotalTime": 2.1987464427948
  },
  {
    "name": "below_zero",
    "task_id": "HumanEval/3",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.58229923248291
  },
  {
    "name": "mean_absolute_deviation",
    "task_id": "HumanEval/4",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.9332308769226074
  },
  {
    "name": "intersperse",
    "task_id": "HumanEval/5",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.554349899291992
  },
  {
    "name": "parse_nested_parens",
    "task_id": "HumanEval/6",
    "Dis": 0.0,
    "Err": 0.38706666666666667,
    "TotalTime": 3.038372039794922
  },
  {
    "name": "filter_by_substring",
    "task_id": "HumanEval/7",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 5.57009220123291
  },
  {
    "name": "sum_product",
    "task_id": "HumanEval/8",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.872220516204834
  },
  {
    "name": "rolling_max",
    "task_id": "HumanEval/9",
    "Dis": 0.0032,
    "Err": 0.0252,
    "TotalTime": 3.6823530197143555
  },
  {
    "name": "make_palindrome",
    "task_id": "HumanEval/10",
    "Dis": 0.4804,
    "Err": 0.5245333333333333,
    "TotalTime": 2.79567289352417
  },
  {
    "name": "string_xor",
    "task_id": "HumanEval/11",
    "Dis": 0.0,
    "Err": 0.9793333333333333,
    "TotalTime": 3.7680656909942627
  },
  {
    "name": "longest",
    "task_id": "HumanEval/12",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.260319232940674
  },
  {
    "name": "greatest_common_divisor",
    "task_id": "HumanEval/13",
    "Dis": 0.0,
    "Err": 0.1908,
    "TotalTime": 2.2675607204437256
  },
  {
    "name": "all_prefixes",
    "task_id": "HumanEval/14",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.025397539138794
  },
  {
    "name": "string_sequence",
    "task_id": "HumanEval/15",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.059011459350586
  },
  {
    "name": "count_distinct_characters",
    "task_id": "HumanEval/16",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.7066493034362793
  },
  {
    "name": "parse_music",
    "task_id": "HumanEval/17",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 6.412726879119873
  },
  {
    "name": "how_many_times",
    "task_id": "HumanEval/18",
    "Dis": 0.0,
    "Err": 0.0772,
    "TotalTime": 3.4198763370513916
  },
  {
    "name": "sort_numbers",
    "task_id": "HumanEval/19",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 8.620873212814331
  },
  {
    "name": "find_closest_elements",
    "task_id": "HumanEval/20",
    "Dis": 0.0,
    "Err": 0.0018666666666666666,
    "TotalTime": 4.249324321746826
  },
  {
    "name": "rescale_to_unit",
    "task_id": "HumanEval/21",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.257532119750977
  },
  {
    "name": "filter_integers",
    "task_id": "HumanEval/22",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.752634286880493
  },
  {
    "name": "strlen",
    "task_id": "HumanEval/23",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.6609721183776855
  },
  {
    "name": "largest_divisor",
    "task_id": "HumanEval/24",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.972799301147461
  },
  {
    "name": "factorize",
    "task_id": "HumanEval/25",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 5.884899377822876
  },
  {
    "name": "remove_duplicates",
    "task_id": "HumanEval/26",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.7785983085632324
  },
  {
    "name": "flip_case",
    "task_id": "HumanEval/27",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.6168737411499023
  },
  {
    "name": "concatenate",
    "task_id": "HumanEval/28",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.5139312744140625
  },
  {
    "name": "filter_by_prefix",
    "task_id": "HumanEval/29",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 6.678693056106567
  },
  {
    "name": "get_positive",
    "task_id": "HumanEval/30",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.059010982513428
  },
  {
    "name": "is_prime",
    "task_id": "HumanEval/31",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.481689453125
  },
  {
    "name": "unique",
    "task_id": "HumanEval/34",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.116686820983887
  },
  {
    "name": "max_element",
    "task_id": "HumanEval/35",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.074522495269775
  },
  {
    "name": "sort_even",
    "task_id": "HumanEval/37",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.012898683547974
  },
  {
    "name": "triples_sum_to_zero",
    "task_id": "HumanEval/40",
    "Dis": 0.023733333333333332,
    "Err": 0.0376,
    "TotalTime": 3.838580846786499
  },
  {
    "name": "car_race_collision",
    "task_id": "HumanEval/41",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.8782496452331543
  },
  {
    "name": "incr_list",
    "task_id": "HumanEval/42",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.07173228263855
  },
  {
    "name": "pairs_sum_to_zero",
    "task_id": "HumanEval/43",
    "Dis": 0.0,
    "Err": 0.0108,
    "TotalTime": 3.6327643394470215
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/45",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.4050405025482178
  },
  {
    "name": "fib4",
    "task_id": "HumanEval/46",
    "Dis": 0.013066666666666667,
    "Err": 0.06826666666666667,
    "TotalTime": 2.508101224899292
  },
  {
    "name": "median",
    "task_id": "HumanEval/47",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.6489813327789307
  },
  {
    "name": "is_palindrome",
    "task_id": "HumanEval/48",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.425365447998047
  },
  {
    "name": "modp",
    "task_id": "HumanEval/49",
    "Dis": 0.038,
    "Err": 0.019066666666666666,
    "TotalTime": 2.7314906120300293
  },
  {
    "name": "remove_vowels",
    "task_id": "HumanEval/51",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.744028091430664
  },
  {
    "name": "below_threshold",
    "task_id": "HumanEval/52",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.931746482849121
  },
  {
    "name": "add",
    "task_id": "HumanEval/53",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.149888038635254
  },
  {
    "name": "same_chars",
    "task_id": "HumanEval/54",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.547760009765625
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/56",
    "Dis": 0.0,
    "Err": 0.40773333333333334,
    "TotalTime": 2.626558303833008
  },
  {
    "name": "monotonic",
    "task_id": "HumanEval/57",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.798269748687744
  },
  {
    "name": "common",
    "task_id": "HumanEval/58",
    "Dis": 0.0,
    "Err": 0.37733333333333335,
    "TotalTime": 4.66657280921936
  },
  {
    "name": "largest_prime_factor",
    "task_id": "HumanEval/59",
    "Dis": 0.0,
    "Err": 0.07293333333333334,
    "TotalTime": 6.632287502288818
  },
  {
    "name": "sum_to_n",
    "task_id": "HumanEval/60",
    "Dis": 0.0,
    "Err": 0.2116,
    "TotalTime": 2.1405627727508545
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/61",
    "Dis": 0.22786666666666666,
    "Err": 0.21573333333333333,
    "TotalTime": 2.7100987434387207
  },
  {
    "name": "derivative",
    "task_id": "HumanEval/62",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.602365493774414
  },
  {
    "name": "vowels_count",
    "task_id": "HumanEval/64",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.739995241165161
  },
  {
    "name": "circular_shift",
    "task_id": "HumanEval/65",
    "Dis": 0.0,
    "Err": 0.406,
    "TotalTime": 2.2818334102630615
  },
  {
    "name": "digitSum",
    "task_id": "HumanEval/66",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.7465052604675293
  },
  {
    "name": "fruit_distribution",
    "task_id": "HumanEval/67",
    "Dis": 0.5110666666666667,
    "Err": 0.5412,
    "TotalTime": 3.36358380317688
  },
  {
    "name": "pluck",
    "task_id": "HumanEval/68",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.957792282104492
  },
  {
    "name": "search",
    "task_id": "HumanEval/69",
    "Dis": 0.013466666666666667,
    "Err": 0.08053333333333333,
    "TotalTime": 5.1490747928619385
  },
  {
    "name": "strange_sort_list",
    "task_id": "HumanEval/70",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.6210148334503174
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/71",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.718674659729004
  },
  {
    "name": "will_it_fly",
    "task_id": "HumanEval/72",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.260432481765747
  },
  {
    "name": "smallest_change",
    "task_id": "HumanEval/73",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.1366963386535645
  },
  {
    "name": "total_match",
    "task_id": "HumanEval/74",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 8.400621891021729
  },
  {
    "name": "iscube",
    "task_id": "HumanEval/77",
    "Dis": 0.06533333333333333,
    "Err": 0.04,
    "TotalTime": 2.090959310531616
  },
  {
    "name": "hex_key",
    "task_id": "HumanEval/78",
    "Dis": 0.0,
    "Err": 0.03626666666666667,
    "TotalTime": 2.9531333446502686
  },
  {
    "name": "decimal_to_binary",
    "task_id": "HumanEval/79",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.9448013305664062
  },
  {
    "name": "is_happy",
    "task_id": "HumanEval/80",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.5764365196228027
  },
  {
    "name": "numerical_letter_grade",
    "task_id": "HumanEval/81",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.007155179977417
  },
  {
    "name": "prime_length",
    "task_id": "HumanEval/82",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.8203248977661133
  },
  {
    "name": "starts_one_ends",
    "task_id": "HumanEval/83",
    "Dis": 0.5450666666666667,
    "Err": 0.4924,
    "TotalTime": 2.16756010055542
  },
  {
    "name": "solve",
    "task_id": "HumanEval/84",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.120833396911621
  },
  {
    "name": "add",
    "task_id": "HumanEval/85",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.4362432956695557
  },
  {
    "name": "anti_shuffle",
    "task_id": "HumanEval/86",
    "Dis": 0.122,
    "Err": 0.061733333333333335,
    "TotalTime": 2.7489943504333496
  },
  {
    "name": "get_row",
    "task_id": "HumanEval/87",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 6.76705265045166
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/88",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.947024345397949
  },
  {
    "name": "encrypt",
    "task_id": "HumanEval/89",
    "Dis": 0.0,
    "Err": 0.46413333333333334,
    "TotalTime": 2.7353878021240234
  },
  {
    "name": "next_smallest",
    "task_id": "HumanEval/90",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.7471821308135986
  },
  {
    "name": "is_bored",
    "task_id": "HumanEval/91",
    "Dis": 0.0012,
    "Err": 0.14226666666666668,
    "TotalTime": 2.5716452598571777
  },
  {
    "name": "any_int",
    "task_id": "HumanEval/92",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.59024977684021
  },
  {
    "name": "encode",
    "task_id": "HumanEval/93",
    "Dis": 0.24506666666666665,
    "Err": 0.13186666666666666,
    "TotalTime": 2.7348086833953857
  },
  {
    "name": "skjkasdkd",
    "task_id": "HumanEval/94",
    "Dis": 0.0,
    "Err": 0.0152,
    "TotalTime": 5.288070440292358
  },
  {
    "name": "check_dict_case",
    "task_id": "HumanEval/95",
    "Dis": 0.0,
    "Err": 0.009466666666666667,
    "TotalTime": 4.005343914031982
  },
  {
    "name": "count_up_to",
    "task_id": "HumanEval/96",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.15395450592041
  },
  {
    "name": "multiply",
    "task_id": "HumanEval/97",
    "Dis": 0.0,
    "Err": 0.21973333333333334,
    "TotalTime": 2.2955167293548584
  },
  {
    "name": "count_upper",
    "task_id": "HumanEval/98",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.6850366592407227
  },
  {
    "name": "closest_integer",
    "task_id": "HumanEval/99",
    "Dis": 0.0,
    "Err": 0.0002666666666666667,
    "TotalTime": 5.9660725593566895
  },
  {
    "name": "make_a_pile",
    "task_id": "HumanEval/100",
    "Dis": 0.0,
    "Err": 0.372,
    "TotalTime": 2.425143241882324
  },
  {
    "name": "words_string",
    "task_id": "HumanEval/101",
    "Dis": 0.1188,
    "Err": 0.05733333333333333,
    "TotalTime": 3.0157012939453125
  },
  {
    "name": "choose_num",
    "task_id": "HumanEval/102",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.39668607711792
  },
  {
    "name": "rounded_avg",
    "task_id": "HumanEval/103",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.515566825866699
  },
  {
    "name": "unique_digits",
    "task_id": "HumanEval/104",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.393810033798218
  },
  {
    "name": "by_length",
    "task_id": "HumanEval/105",
    "Dis": 0.1916,
    "Err": 0.1668,
    "TotalTime": 4.0455262660980225
  },
  {
    "name": "f",
    "task_id": "HumanEval/106",
    "Dis": 0.30266666666666664,
    "Err": 0.15746666666666667,
    "TotalTime": 3.4705970287323
  },
  {
    "name": "even_odd_palindrome",
    "task_id": "HumanEval/107",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.031421661376953
  },
  {
    "name": "count_nums",
    "task_id": "HumanEval/108",
    "Dis": 0.05826666666666667,
    "Err": 0.2810666666666667,
    "TotalTime": 4.351205110549927
  },
  {
    "name": "move_one_ball",
    "task_id": "HumanEval/109",
    "Dis": 0.09173333333333333,
    "Err": 0.0664,
    "TotalTime": 3.8978490829467773
  },
  {
    "name": "exchange",
    "task_id": "HumanEval/110",
    "Dis": 0.0,
    "Err": 0.009866666666666666,
    "TotalTime": 6.986270904541016
  },
  {
    "name": "histogram",
    "task_id": "HumanEval/111",
    "Dis": 0.4688,
    "Err": 0.5156,
    "TotalTime": 2.843167543411255
  },
  {
    "name": "reverse_delete",
    "task_id": "HumanEval/112",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.6611993312835693
  },
  {
    "name": "odd_count",
    "task_id": "HumanEval/113",
    "Dis": 0.16413333333333333,
    "Err": 0.09066666666666667,
    "TotalTime": 6.870710134506226
  },
  {
    "name": "minSubArraySum",
    "task_id": "HumanEval/114",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.8405120372772217
  },
  {
    "name": "max_fill",
    "task_id": "HumanEval/115",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 6.336915969848633
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/116",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.979940176010132
  },
  {
    "name": "select_words",
    "task_id": "HumanEval/117",
    "Dis": 0.0072,
    "Err": 0.0572,
    "TotalTime": 3.4542222023010254
  },
  {
    "name": "get_closest_vowel",
    "task_id": "HumanEval/118",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.8396334648132324
  },
  {
    "name": "match_parens",
    "task_id": "HumanEval/119",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.617945671081543
  },
  {
    "name": "maximum",
    "task_id": "HumanEval/120",
    "Dis": 0.012533333333333334,
    "Err": 0.0156,
    "TotalTime": 3.9843759536743164
  },
  {
    "name": "solution",
    "task_id": "HumanEval/121",
    "Dis": 0.0,
    "Err": 0.031466666666666664,
    "TotalTime": 3.28520131111145
  },
  {
    "name": "add_elements",
    "task_id": "HumanEval/122",
    "Dis": 0.0021333333333333334,
    "Err": 0.15746666666666667,
    "TotalTime": 3.640377998352051
  },
  {
    "name": "get_odd_collatz",
    "task_id": "HumanEval/123",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "valid_date",
    "task_id": "HumanEval/124",
    "Dis": 0.0002666666666666667,
    "Err": 0.0244,
    "TotalTime": 2.6641945838928223
  },
  {
    "name": "split_words",
    "task_id": "HumanEval/125",
    "Dis": 0.08386666666666667,
    "Err": 0.41733333333333333,
    "TotalTime": 2.8406195640563965
  },
  {
    "name": "is_sorted",
    "task_id": "HumanEval/126",
    "Dis": 0.0,
    "Err": 0.0388,
    "TotalTime": 3.686461925506592
  },
  {
    "name": "intersection",
    "task_id": "HumanEval/127",
    "Dis": 0.14613333333333334,
    "Err": 0.1808,
    "TotalTime": 8.135273694992065
  },
  {
    "name": "prod_signs",
    "task_id": "HumanEval/128",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.7831003665924072
  },
  {
    "name": "minPath",
    "task_id": "HumanEval/129",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "tri",
    "task_id": "HumanEval/130",
    "Dis": 0.6842666666666667,
    "Err": 0.9264,
    "TotalTime": 2.3922970294952393
  },
  {
    "name": "digits",
    "task_id": "HumanEval/131",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.0775203704833984
  },
  {
    "name": "is_nested",
    "task_id": "HumanEval/132",
    "Dis": 0.0,
    "Err": 0.1376,
    "TotalTime": 2.635326623916626
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/133",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.6957809925079346
  },
  {
    "name": "check_if_last_char_is_a_letter",
    "task_id": "HumanEval/134",
    "Dis": 0.0848,
    "Err": 0.09146666666666667,
    "TotalTime": 2.6540989875793457
  },
  {
    "name": "can_arrange",
    "task_id": "HumanEval/135",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.619544267654419
  },
  {
    "name": "largest_smallest_integers",
    "task_id": "HumanEval/136",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.819472312927246
  },
  {
    "name": "compare_one",
    "task_id": "HumanEval/137",
    "Dis": 0.19133333333333333,
    "Err": 0.0956,
    "TotalTime": 3.506970167160034
  },
  {
    "name": "is_equal_to_sum_even",
    "task_id": "HumanEval/138",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.071582794189453
  },
  {
    "name": "special_factorial",
    "task_id": "HumanEval/139",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "fix_spaces",
    "task_id": "HumanEval/140",
    "Dis": 0.0844,
    "Err": 0.10613333333333333,
    "TotalTime": 2.811034917831421
  },
  {
    "name": "file_name_check",
    "task_id": "HumanEval/141",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.597177505493164
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/142",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.0249457359313965
  },
  {
    "name": "words_in_sentence",
    "task_id": "HumanEval/143",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.9634716510772705
  },
  {
    "name": "simplify",
    "task_id": "HumanEval/144",
    "Dis": 0.0004,
    "Err": 0.0016,
    "TotalTime": 102.73089456558228
  },
  {
    "name": "order_by_points",
    "task_id": "HumanEval/145",
    "Dis": 0.0,
    "Err": 0.6793333333333333,
    "TotalTime": 4.7520458698272705
  },
  {
    "name": "specialFilter",
    "task_id": "HumanEval/146",
    "Dis": 0.08626666666666667,
    "Err": 0.2650666666666667,
    "TotalTime": 3.965129852294922
  },
  {
    "name": "bf",
    "task_id": "HumanEval/148",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.469045877456665
  },
  {
    "name": "sorted_list_sum",
    "task_id": "HumanEval/149",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.776999473571777
  },
  {
    "name": "x_or_y",
    "task_id": "HumanEval/150",
    "Dis": 0.0,
    "Err": 0.21173333333333333,
    "TotalTime": 3.1561315059661865
  },
  {
    "name": "double_the_difference",
    "task_id": "HumanEval/151",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 5.894655466079712
  },
  {
    "name": "compare",
    "task_id": "HumanEval/152",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 6.644661903381348
  },
  {
    "name": "Strongest_Extension",
    "task_id": "HumanEval/153",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 6.097355365753174
  },
  {
    "name": "cycpattern_check",
    "task_id": "HumanEval/154",
    "Dis": 0.0336,
    "Err": 0.028,
    "TotalTime": 3.6554114818573
  },
  {
    "name": "even_odd_count",
    "task_id": "HumanEval/155",
    "Dis": 0.0029333333333333334,
    "Err": 0.0034666666666666665,
    "TotalTime": 2.399094820022583
  },
  {
    "name": "right_angle_triangle",
    "task_id": "HumanEval/157",
    "Dis": 0.0,
    "Err": 0.0009333333333333333,
    "TotalTime": 2.6840553283691406
  },
  {
    "name": "find_max",
    "task_id": "HumanEval/158",
    "Dis": 0.0204,
    "Err": 0.014266666666666667,
    "TotalTime": 4.573290109634399
  },
  {
    "name": "eat",
    "task_id": "HumanEval/159",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.823791980743408
  },
  {
    "name": "solve",
    "task_id": "HumanEval/161",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.818297863006592
  },
  {
    "name": "string_to_md5",
    "task_id": "HumanEval/162",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.4497148990631104
  },
  {
    "name": "generate_integers",
    "task_id": "HumanEval/163",
    "Dis": 0.0,
    "Err": 0.9793333333333333,
    "TotalTime": 2.7416372299194336
  }
]