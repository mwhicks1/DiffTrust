[
  {
    "name": "has_close_elements",
    "task_id": "HumanEval/0",
    "Dis": 0.0,
    "Err": 0.04957142857142857,
    "TotalTime": 3.7340829372406006
  },
  {
    "name": "separate_paren_groups",
    "task_id": "HumanEval/1",
    "Dis": 0.2735714285714286,
    "Err": 0.4725714285714286,
    "TotalTime": 2.650881052017212
  },
  {
    "name": "truncate_number",
    "task_id": "HumanEval/2",
    "Dis": 0.0,
    "Err": 0.20842857142857144,
    "TotalTime": 1.967158555984497
  },
  {
    "name": "below_zero",
    "task_id": "HumanEval/3",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.313265800476074
  },
  {
    "name": "mean_absolute_deviation",
    "task_id": "HumanEval/4",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.4401471614837646
  },
  {
    "name": "intersperse",
    "task_id": "HumanEval/5",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.3298447132110596
  },
  {
    "name": "parse_nested_parens",
    "task_id": "HumanEval/6",
    "Dis": 0.0,
    "Err": 0.38171428571428573,
    "TotalTime": 2.633798122406006
  },
  {
    "name": "filter_by_substring",
    "task_id": "HumanEval/7",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 5.257216215133667
  },
  {
    "name": "sum_product",
    "task_id": "HumanEval/8",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.82084584236145
  },
  {
    "name": "rolling_max",
    "task_id": "HumanEval/9",
    "Dis": 0.032857142857142856,
    "Err": 0.05342857142857143,
    "TotalTime": 3.697831630706787
  },
  {
    "name": "make_palindrome",
    "task_id": "HumanEval/10",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.668238401412964
  },
  {
    "name": "string_xor",
    "task_id": "HumanEval/11",
    "Dis": 0.419,
    "Err": 0.2807142857142857,
    "TotalTime": 3.446019411087036
  },
  {
    "name": "longest",
    "task_id": "HumanEval/12",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.8604767322540283
  },
  {
    "name": "greatest_common_divisor",
    "task_id": "HumanEval/13",
    "Dis": 0.09142857142857143,
    "Err": 0.13257142857142856,
    "TotalTime": 2.1923632621765137
  },
  {
    "name": "all_prefixes",
    "task_id": "HumanEval/14",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.625527858734131
  },
  {
    "name": "string_sequence",
    "task_id": "HumanEval/15",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.8762969970703125
  },
  {
    "name": "count_distinct_characters",
    "task_id": "HumanEval/16",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.5096023082733154
  },
  {
    "name": "parse_music",
    "task_id": "HumanEval/17",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 5.807497024536133
  },
  {
    "name": "how_many_times",
    "task_id": "HumanEval/18",
    "Dis": 0.03471428571428571,
    "Err": 0.052714285714285714,
    "TotalTime": 3.316042423248291
  },
  {
    "name": "sort_numbers",
    "task_id": "HumanEval/19",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 8.279818058013916
  },
  {
    "name": "find_closest_elements",
    "task_id": "HumanEval/20",
    "Dis": 0.0005714285714285715,
    "Err": 0.003285714285714286,
    "TotalTime": 3.918696641921997
  },
  {
    "name": "rescale_to_unit",
    "task_id": "HumanEval/21",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.6288044452667236
  },
  {
    "name": "filter_integers",
    "task_id": "HumanEval/22",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.5755720138549805
  },
  {
    "name": "strlen",
    "task_id": "HumanEval/23",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.4282243251800537
  },
  {
    "name": "largest_divisor",
    "task_id": "HumanEval/24",
    "Dis": 0.10828571428571429,
    "Err": 0.16114285714285714,
    "TotalTime": 1.9391155242919922
  },
  {
    "name": "factorize",
    "task_id": "HumanEval/25",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "remove_duplicates",
    "task_id": "HumanEval/26",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.3492231369018555
  },
  {
    "name": "flip_case",
    "task_id": "HumanEval/27",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.4692978858947754
  },
  {
    "name": "concatenate",
    "task_id": "HumanEval/28",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.122347831726074
  },
  {
    "name": "filter_by_prefix",
    "task_id": "HumanEval/29",
    "Dis": 0.2037142857142857,
    "Err": 0.09928571428571428,
    "TotalTime": 6.126919984817505
  },
  {
    "name": "get_positive",
    "task_id": "HumanEval/30",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.5485219955444336
  },
  {
    "name": "is_prime",
    "task_id": "HumanEval/31",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.3801026344299316
  },
  {
    "name": "unique",
    "task_id": "HumanEval/34",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.5606837272644043
  },
  {
    "name": "max_element",
    "task_id": "HumanEval/35",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.682299852371216
  },
  {
    "name": "sort_even",
    "task_id": "HumanEval/37",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.480764865875244
  },
  {
    "name": "triples_sum_to_zero",
    "task_id": "HumanEval/40",
    "Dis": 0.006571428571428572,
    "Err": 0.018857142857142857,
    "TotalTime": 3.313985824584961
  },
  {
    "name": "car_race_collision",
    "task_id": "HumanEval/41",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.920577049255371
  },
  {
    "name": "incr_list",
    "task_id": "HumanEval/42",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.6963188648223877
  },
  {
    "name": "pairs_sum_to_zero",
    "task_id": "HumanEval/43",
    "Dis": 0.0,
    "Err": 0.012571428571428572,
    "TotalTime": 3.333355665206909
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/45",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.1532490253448486
  },
  {
    "name": "fib4",
    "task_id": "HumanEval/46",
    "Dis": 0.026714285714285715,
    "Err": 0.014714285714285714,
    "TotalTime": 2.1258440017700195
  },
  {
    "name": "median",
    "task_id": "HumanEval/47",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.5839011669158936
  },
  {
    "name": "is_palindrome",
    "task_id": "HumanEval/48",
    "Dis": 0.06942857142857142,
    "Err": 0.052142857142857144,
    "TotalTime": 2.393683910369873
  },
  {
    "name": "modp",
    "task_id": "HumanEval/49",
    "Dis": 0.0,
    "Err": 0.2037142857142857,
    "TotalTime": 2.418661117553711
  },
  {
    "name": "remove_vowels",
    "task_id": "HumanEval/51",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.5498993396759033
  },
  {
    "name": "below_threshold",
    "task_id": "HumanEval/52",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.4879086017608643
  },
  {
    "name": "add",
    "task_id": "HumanEval/53",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.1569368839263916
  },
  {
    "name": "same_chars",
    "task_id": "HumanEval/54",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.3142406940460205
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/56",
    "Dis": 0.0,
    "Err": 0.41285714285714287,
    "TotalTime": 2.50301194190979
  },
  {
    "name": "monotonic",
    "task_id": "HumanEval/57",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.3005828857421875
  },
  {
    "name": "common",
    "task_id": "HumanEval/58",
    "Dis": 0.0,
    "Err": 0.36714285714285716,
    "TotalTime": 4.502191066741943
  },
  {
    "name": "largest_prime_factor",
    "task_id": "HumanEval/59",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "sum_to_n",
    "task_id": "HumanEval/60",
    "Dis": 0.0,
    "Err": 0.21371428571428572,
    "TotalTime": 1.8860409259796143
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/61",
    "Dis": 0.0,
    "Err": 0.4057142857142857,
    "TotalTime": 2.4811606407165527
  },
  {
    "name": "derivative",
    "task_id": "HumanEval/62",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.5428309440612793
  },
  {
    "name": "vowels_count",
    "task_id": "HumanEval/64",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.553919553756714
  },
  {
    "name": "circular_shift",
    "task_id": "HumanEval/65",
    "Dis": 0.013,
    "Err": 0.142,
    "TotalTime": 2.162627935409546
  },
  {
    "name": "digitSum",
    "task_id": "HumanEval/66",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.5070104598999023
  },
  {
    "name": "fruit_distribution",
    "task_id": "HumanEval/67",
    "Dis": 0.3201428571428571,
    "Err": 0.6835714285714286,
    "TotalTime": 3.323352336883545
  },
  {
    "name": "pluck",
    "task_id": "HumanEval/68",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.4890990257263184
  },
  {
    "name": "search",
    "task_id": "HumanEval/69",
    "Dis": 0.02457142857142857,
    "Err": 0.07371428571428572,
    "TotalTime": 4.567555665969849
  },
  {
    "name": "strange_sort_list",
    "task_id": "HumanEval/70",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.3535194396972656
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/71",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.5168654918670654
  },
  {
    "name": "will_it_fly",
    "task_id": "HumanEval/72",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.8422787189483643
  },
  {
    "name": "smallest_change",
    "task_id": "HumanEval/73",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.992553472518921
  },
  {
    "name": "total_match",
    "task_id": "HumanEval/74",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 7.948585748672485
  },
  {
    "name": "iscube",
    "task_id": "HumanEval/77",
    "Dis": 0.007142857142857143,
    "Err": 0.0034285714285714284,
    "TotalTime": 1.9694902896881104
  },
  {
    "name": "hex_key",
    "task_id": "HumanEval/78",
    "Dis": 0.03857142857142857,
    "Err": 0.05671428571428572,
    "TotalTime": 2.5955047607421875
  },
  {
    "name": "decimal_to_binary",
    "task_id": "HumanEval/79",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.8585255146026611
  },
  {
    "name": "is_happy",
    "task_id": "HumanEval/80",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.3979008197784424
  },
  {
    "name": "numerical_letter_grade",
    "task_id": "HumanEval/81",
    "Dis": 0.21585714285714286,
    "Err": 0.7455714285714286,
    "TotalTime": 3.776484966278076
  },
  {
    "name": "prime_length",
    "task_id": "HumanEval/82",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.804252862930298
  },
  {
    "name": "starts_one_ends",
    "task_id": "HumanEval/83",
    "Dis": 0.7691428571428571,
    "Err": 0.8317142857142857,
    "TotalTime": 2.0541694164276123
  },
  {
    "name": "solve",
    "task_id": "HumanEval/84",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.9479446411132812
  },
  {
    "name": "add",
    "task_id": "HumanEval/85",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.093721866607666
  },
  {
    "name": "anti_shuffle",
    "task_id": "HumanEval/86",
    "Dis": 0.04657142857142857,
    "Err": 0.023714285714285716,
    "TotalTime": 2.4566006660461426
  },
  {
    "name": "get_row",
    "task_id": "HumanEval/87",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 6.306216239929199
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/88",
    "Dis": 0.008857142857142857,
    "Err": 0.006571428571428572,
    "TotalTime": 3.6715259552001953
  },
  {
    "name": "encrypt",
    "task_id": "HumanEval/89",
    "Dis": 0.2715714285714286,
    "Err": 0.13757142857142857,
    "TotalTime": 2.6390764713287354
  },
  {
    "name": "next_smallest",
    "task_id": "HumanEval/90",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.307631015777588
  },
  {
    "name": "is_bored",
    "task_id": "HumanEval/91",
    "Dis": 0.17757142857142857,
    "Err": 0.20185714285714285,
    "TotalTime": 2.582646608352661
  },
  {
    "name": "any_int",
    "task_id": "HumanEval/92",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.42891001701355
  },
  {
    "name": "encode",
    "task_id": "HumanEval/93",
    "Dis": 0.12928571428571428,
    "Err": 0.06814285714285714,
    "TotalTime": 2.6631362438201904
  },
  {
    "name": "skjkasdkd",
    "task_id": "HumanEval/94",
    "Dis": 0.0,
    "Err": 0.012428571428571428,
    "TotalTime": 4.691680669784546
  },
  {
    "name": "check_dict_case",
    "task_id": "HumanEval/95",
    "Dis": 0.0,
    "Err": 0.008857142857142857,
    "TotalTime": 3.3806753158569336
  },
  {
    "name": "count_up_to",
    "task_id": "HumanEval/96",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.672255039215088
  },
  {
    "name": "multiply",
    "task_id": "HumanEval/97",
    "Dis": 0.0,
    "Err": 0.21742857142857142,
    "TotalTime": 2.14613938331604
  },
  {
    "name": "count_upper",
    "task_id": "HumanEval/98",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.3780994415283203
  },
  {
    "name": "closest_integer",
    "task_id": "HumanEval/99",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 5.5949060916900635
  },
  {
    "name": "make_a_pile",
    "task_id": "HumanEval/100",
    "Dis": 0.49742857142857144,
    "Err": 0.4005714285714286,
    "TotalTime": 1.9809446334838867
  },
  {
    "name": "words_string",
    "task_id": "HumanEval/101",
    "Dis": 0.04957142857142857,
    "Err": 0.027714285714285716,
    "TotalTime": 2.6273491382598877
  },
  {
    "name": "choose_num",
    "task_id": "HumanEval/102",
    "Dis": 0.14757142857142858,
    "Err": 0.08357142857142857,
    "TotalTime": 2.168492078781128
  },
  {
    "name": "rounded_avg",
    "task_id": "HumanEval/103",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.4253082275390625
  },
  {
    "name": "unique_digits",
    "task_id": "HumanEval/104",
    "Dis": 0.05085714285714286,
    "Err": 0.04914285714285714,
    "TotalTime": 4.105555295944214
  },
  {
    "name": "by_length",
    "task_id": "HumanEval/105",
    "Dis": 0.003,
    "Err": 0.06314285714285714,
    "TotalTime": 3.723334789276123
  },
  {
    "name": "f",
    "task_id": "HumanEval/106",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.7192423343658447
  },
  {
    "name": "even_odd_palindrome",
    "task_id": "HumanEval/107",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.076453924179077
  },
  {
    "name": "count_nums",
    "task_id": "HumanEval/108",
    "Dis": 0.21328571428571427,
    "Err": 0.11885714285714286,
    "TotalTime": 3.9753258228302
  },
  {
    "name": "move_one_ball",
    "task_id": "HumanEval/109",
    "Dis": 0.008571428571428572,
    "Err": 0.011714285714285714,
    "TotalTime": 3.3573482036590576
  },
  {
    "name": "exchange",
    "task_id": "HumanEval/110",
    "Dis": 0.17642857142857143,
    "Err": 0.137,
    "TotalTime": 6.5639283657073975
  },
  {
    "name": "histogram",
    "task_id": "HumanEval/111",
    "Dis": 0.0024285714285714284,
    "Err": 0.31957142857142856,
    "TotalTime": 2.5703954696655273
  },
  {
    "name": "reverse_delete",
    "task_id": "HumanEval/112",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.3746249675750732
  },
  {
    "name": "odd_count",
    "task_id": "HumanEval/113",
    "Dis": 0.020428571428571428,
    "Err": 0.019,
    "TotalTime": 6.5236310958862305
  },
  {
    "name": "minSubArraySum",
    "task_id": "HumanEval/114",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.516963481903076
  },
  {
    "name": "max_fill",
    "task_id": "HumanEval/115",
    "Dis": 0.18128571428571427,
    "Err": 0.10071428571428571,
    "TotalTime": 6.1192522048950195
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/116",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.9409024715423584
  },
  {
    "name": "select_words",
    "task_id": "HumanEval/117",
    "Dis": 0.027,
    "Err": 0.04214285714285714,
    "TotalTime": 3.008852481842041
  },
  {
    "name": "get_closest_vowel",
    "task_id": "HumanEval/118",
    "Dis": 0.02614285714285714,
    "Err": 0.014428571428571428,
    "TotalTime": 2.5162510871887207
  },
  {
    "name": "match_parens",
    "task_id": "HumanEval/119",
    "Dis": 0.15142857142857144,
    "Err": 0.459,
    "TotalTime": 4.639491081237793
  },
  {
    "name": "maximum",
    "task_id": "HumanEval/120",
    "Dis": 0.005,
    "Err": 0.012285714285714285,
    "TotalTime": 4.143849611282349
  },
  {
    "name": "solution",
    "task_id": "HumanEval/121",
    "Dis": 0.0,
    "Err": 0.02942857142857143,
    "TotalTime": 3.011174201965332
  },
  {
    "name": "add_elements",
    "task_id": "HumanEval/122",
    "Dis": 0.0,
    "Err": 0.49328571428571427,
    "TotalTime": 3.936094045639038
  },
  {
    "name": "get_odd_collatz",
    "task_id": "HumanEval/123",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "valid_date",
    "task_id": "HumanEval/124",
    "Dis": 0.015714285714285715,
    "Err": 0.014714285714285714,
    "TotalTime": 2.393939256668091
  },
  {
    "name": "split_words",
    "task_id": "HumanEval/125",
    "Dis": 0.191,
    "Err": 0.14485714285714285,
    "TotalTime": 2.365964651107788
  },
  {
    "name": "is_sorted",
    "task_id": "HumanEval/126",
    "Dis": 0.00028571428571428574,
    "Err": 0.006571428571428572,
    "TotalTime": 3.097752809524536
  },
  {
    "name": "intersection",
    "task_id": "HumanEval/127",
    "Dis": 0.427,
    "Err": 0.32371428571428573,
    "TotalTime": 7.828875780105591
  },
  {
    "name": "prod_signs",
    "task_id": "HumanEval/128",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.217634439468384
  },
  {
    "name": "minPath",
    "task_id": "HumanEval/129",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "tri",
    "task_id": "HumanEval/130",
    "Dis": 0.7091428571428572,
    "Err": 0.8024285714285714,
    "TotalTime": 2.285249710083008
  },
  {
    "name": "digits",
    "task_id": "HumanEval/131",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.8627376556396484
  },
  {
    "name": "is_nested",
    "task_id": "HumanEval/132",
    "Dis": 0.03014285714285714,
    "Err": 0.15257142857142858,
    "TotalTime": 2.407261848449707
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/133",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.252305269241333
  },
  {
    "name": "check_if_last_char_is_a_letter",
    "task_id": "HumanEval/134",
    "Dis": 0.092,
    "Err": 0.107,
    "TotalTime": 2.3292438983917236
  },
  {
    "name": "can_arrange",
    "task_id": "HumanEval/135",
    "Dis": 0.24914285714285714,
    "Err": 0.19157142857142856,
    "TotalTime": 3.16154408454895
  },
  {
    "name": "largest_smallest_integers",
    "task_id": "HumanEval/136",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.5868425369262695
  },
  {
    "name": "compare_one",
    "task_id": "HumanEval/137",
    "Dis": 0.006571428571428572,
    "Err": 0.004428571428571428,
    "TotalTime": 3.4732086658477783
  },
  {
    "name": "is_equal_to_sum_even",
    "task_id": "HumanEval/138",
    "Dis": 0.05757142857142857,
    "Err": 0.027428571428571427,
    "TotalTime": 1.8683271408081055
  },
  {
    "name": "special_factorial",
    "task_id": "HumanEval/139",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "fix_spaces",
    "task_id": "HumanEval/140",
    "Dis": 0.291,
    "Err": 0.37314285714285716,
    "TotalTime": 2.541989803314209
  },
  {
    "name": "file_name_check",
    "task_id": "HumanEval/141",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.3352243900299072
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/142",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.502983570098877
  },
  {
    "name": "words_in_sentence",
    "task_id": "HumanEval/143",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.867938280105591
  },
  {
    "name": "simplify",
    "task_id": "HumanEval/144",
    "Dis": 0.0,
    "Err": 0.0018571428571428571,
    "TotalTime": 98.16504788398743
  },
  {
    "name": "order_by_points",
    "task_id": "HumanEval/145",
    "Dis": 0.018714285714285715,
    "Err": 0.6991428571428572,
    "TotalTime": 4.616419792175293
  },
  {
    "name": "specialFilter",
    "task_id": "HumanEval/146",
    "Dis": 0.05342857142857143,
    "Err": 0.028428571428571428,
    "TotalTime": 3.417208671569824
  },
  {
    "name": "bf",
    "task_id": "HumanEval/148",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.109865188598633
  },
  {
    "name": "sorted_list_sum",
    "task_id": "HumanEval/149",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 4.669900178909302
  },
  {
    "name": "x_or_y",
    "task_id": "HumanEval/150",
    "Dis": 0.0,
    "Err": 0.22071428571428572,
    "TotalTime": 2.91980242729187
  },
  {
    "name": "double_the_difference",
    "task_id": "HumanEval/151",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 5.360421180725098
  },
  {
    "name": "compare",
    "task_id": "HumanEval/152",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 6.230532884597778
  },
  {
    "name": "Strongest_Extension",
    "task_id": "HumanEval/153",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 5.751874208450317
  },
  {
    "name": "cycpattern_check",
    "task_id": "HumanEval/154",
    "Dis": 0.0074285714285714285,
    "Err": 0.03757142857142857,
    "TotalTime": 3.2805533409118652
  },
  {
    "name": "even_odd_count",
    "task_id": "HumanEval/155",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.2451164722442627
  },
  {
    "name": "right_angle_triangle",
    "task_id": "HumanEval/157",
    "Dis": 0.0,
    "Err": 0.001142857142857143,
    "TotalTime": 2.457761287689209
  },
  {
    "name": "find_max",
    "task_id": "HumanEval/158",
    "Dis": 0.0,
    "Err": 0.0017142857142857142,
    "TotalTime": 4.010018348693848
  },
  {
    "name": "eat",
    "task_id": "HumanEval/159",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.468022584915161
  },
  {
    "name": "solve",
    "task_id": "HumanEval/161",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.5065901279449463
  },
  {
    "name": "string_to_md5",
    "task_id": "HumanEval/162",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.0510172843933105
  },
  {
    "name": "generate_integers",
    "task_id": "HumanEval/163",
    "Dis": 0.0,
    "Err": 0.9811428571428571,
    "TotalTime": 2.342682123184204
  }
]