[
  {
    "name": "has_close_elements",
    "task_id": "HumanEval/0",
    "Dis": 0.0,
    "Err": 0.059,
    "TotalTime": 1.410503625869751
  },
  {
    "name": "separate_paren_groups",
    "task_id": "HumanEval/1",
    "Dis": 0.359,
    "Err": 0.3495,
    "TotalTime": 1.5738229751586914
  },
  {
    "name": "truncate_number",
    "task_id": "HumanEval/2",
    "Dis": 0.109,
    "Err": 0.228,
    "TotalTime": 0.8363049030303955
  },
  {
    "name": "below_zero",
    "task_id": "HumanEval/3",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5021703243255615
  },
  {
    "name": "mean_absolute_deviation",
    "task_id": "HumanEval/4",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5538535118103027
  },
  {
    "name": "intersperse",
    "task_id": "HumanEval/5",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.6738402843475342
  },
  {
    "name": "parse_nested_parens",
    "task_id": "HumanEval/6",
    "Dis": 0.0,
    "Err": 0.3835,
    "TotalTime": 1.0790133476257324
  },
  {
    "name": "filter_by_substring",
    "task_id": "HumanEval/7",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.292746067047119
  },
  {
    "name": "sum_product",
    "task_id": "HumanEval/8",
    "Dis": 0.0315,
    "Err": 0.0175,
    "TotalTime": 1.7509496212005615
  },
  {
    "name": "rolling_max",
    "task_id": "HumanEval/9",
    "Dis": 0.088,
    "Err": 0.1355,
    "TotalTime": 1.7737984657287598
  },
  {
    "name": "make_palindrome",
    "task_id": "HumanEval/10",
    "Dis": 0.405,
    "Err": 0.297,
    "TotalTime": 1.0704612731933594
  },
  {
    "name": "string_xor",
    "task_id": "HumanEval/11",
    "Dis": 0.385,
    "Err": 0.93,
    "TotalTime": 1.790867567062378
  },
  {
    "name": "longest",
    "task_id": "HumanEval/12",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.6525049209594727
  },
  {
    "name": "greatest_common_divisor",
    "task_id": "HumanEval/13",
    "Dis": 0.0335,
    "Err": 0.173,
    "TotalTime": 0.9266927242279053
  },
  {
    "name": "all_prefixes",
    "task_id": "HumanEval/14",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.0746371746063232
  },
  {
    "name": "string_sequence",
    "task_id": "HumanEval/15",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.8527500629425049
  },
  {
    "name": "count_distinct_characters",
    "task_id": "HumanEval/16",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.013336420059204
  },
  {
    "name": "parse_music",
    "task_id": "HumanEval/17",
    "Dis": 0.237,
    "Err": 0.129,
    "TotalTime": 2.4760022163391113
  },
  {
    "name": "how_many_times",
    "task_id": "HumanEval/18",
    "Dis": 0.0125,
    "Err": 0.074,
    "TotalTime": 1.2586069107055664
  },
  {
    "name": "sort_numbers",
    "task_id": "HumanEval/19",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.0214943885803223
  },
  {
    "name": "find_closest_elements",
    "task_id": "HumanEval/20",
    "Dis": 0.0015,
    "Err": 0.0015,
    "TotalTime": 1.9186077117919922
  },
  {
    "name": "rescale_to_unit",
    "task_id": "HumanEval/21",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.8044407367706299
  },
  {
    "name": "filter_integers",
    "task_id": "HumanEval/22",
    "Dis": 0.0385,
    "Err": 0.023,
    "TotalTime": 1.7735893726348877
  },
  {
    "name": "strlen",
    "task_id": "HumanEval/23",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2076876163482666
  },
  {
    "name": "largest_divisor",
    "task_id": "HumanEval/24",
    "Dis": 0.1125,
    "Err": 0.1555,
    "TotalTime": 0.8648617267608643
  },
  {
    "name": "factorize",
    "task_id": "HumanEval/25",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9518833160400391
  },
  {
    "name": "remove_duplicates",
    "task_id": "HumanEval/26",
    "Dis": 0.082,
    "Err": 0.057,
    "TotalTime": 1.7867202758789062
  },
  {
    "name": "flip_case",
    "task_id": "HumanEval/27",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.0110032558441162
  },
  {
    "name": "concatenate",
    "task_id": "HumanEval/28",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.8287932872772217
  },
  {
    "name": "filter_by_prefix",
    "task_id": "HumanEval/29",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.4352147579193115
  },
  {
    "name": "get_positive",
    "task_id": "HumanEval/30",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.8457305431365967
  },
  {
    "name": "is_prime",
    "task_id": "HumanEval/31",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.255162000656128
  },
  {
    "name": "unique",
    "task_id": "HumanEval/34",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.850208044052124
  },
  {
    "name": "max_element",
    "task_id": "HumanEval/35",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5392255783081055
  },
  {
    "name": "sort_even",
    "task_id": "HumanEval/37",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.7611680030822754
  },
  {
    "name": "triples_sum_to_zero",
    "task_id": "HumanEval/40",
    "Dis": 0.0115,
    "Err": 0.0105,
    "TotalTime": 1.6676828861236572
  },
  {
    "name": "car_race_collision",
    "task_id": "HumanEval/41",
    "Dis": 0.5305,
    "Err": 0.484,
    "TotalTime": 0.8523445129394531
  },
  {
    "name": "incr_list",
    "task_id": "HumanEval/42",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.7947027683258057
  },
  {
    "name": "pairs_sum_to_zero",
    "task_id": "HumanEval/43",
    "Dis": 0.0435,
    "Err": 0.0345,
    "TotalTime": 1.7569804191589355
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/45",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9003264904022217
  },
  {
    "name": "fib4",
    "task_id": "HumanEval/46",
    "Dis": 0.042,
    "Err": 0.028,
    "TotalTime": 0.9197940826416016
  },
  {
    "name": "median",
    "task_id": "HumanEval/47",
    "Dis": 0.0875,
    "Err": 0.036,
    "TotalTime": 1.5651319026947021
  },
  {
    "name": "is_palindrome",
    "task_id": "HumanEval/48",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.0623788833618164
  },
  {
    "name": "modp",
    "task_id": "HumanEval/49",
    "Dis": 0.0,
    "Err": 0.2105,
    "TotalTime": 1.465700387954712
  },
  {
    "name": "remove_vowels",
    "task_id": "HumanEval/51",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.01017165184021
  },
  {
    "name": "below_threshold",
    "task_id": "HumanEval/52",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5686862468719482
  },
  {
    "name": "add",
    "task_id": "HumanEval/53",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.8995499610900879
  },
  {
    "name": "same_chars",
    "task_id": "HumanEval/54",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2626686096191406
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/56",
    "Dis": 0.0,
    "Err": 0.4005,
    "TotalTime": 1.0085678100585938
  },
  {
    "name": "monotonic",
    "task_id": "HumanEval/57",
    "Dis": 0.062,
    "Err": 0.033,
    "TotalTime": 1.4950683116912842
  },
  {
    "name": "common",
    "task_id": "HumanEval/58",
    "Dis": 0.0,
    "Err": 0.3715,
    "TotalTime": 2.0260744094848633
  },
  {
    "name": "largest_prime_factor",
    "task_id": "HumanEval/59",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "sum_to_n",
    "task_id": "HumanEval/60",
    "Dis": 0.114,
    "Err": 0.09,
    "TotalTime": 0.880601167678833
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/61",
    "Dis": 0.0,
    "Err": 0.4195,
    "TotalTime": 1.2560114860534668
  },
  {
    "name": "derivative",
    "task_id": "HumanEval/62",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.7389624118804932
  },
  {
    "name": "vowels_count",
    "task_id": "HumanEval/64",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1140661239624023
  },
  {
    "name": "circular_shift",
    "task_id": "HumanEval/65",
    "Dis": 0.1255,
    "Err": 0.0935,
    "TotalTime": 0.9494397640228271
  },
  {
    "name": "digitSum",
    "task_id": "HumanEval/66",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.099977970123291
  },
  {
    "name": "fruit_distribution",
    "task_id": "HumanEval/67",
    "Dis": 0.447,
    "Err": 0.5675,
    "TotalTime": 1.692101240158081
  },
  {
    "name": "pluck",
    "task_id": "HumanEval/68",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.8577148914337158
  },
  {
    "name": "search",
    "task_id": "HumanEval/69",
    "Dis": 0.073,
    "Err": 0.146,
    "TotalTime": 1.9045228958129883
  },
  {
    "name": "strange_sort_list",
    "task_id": "HumanEval/70",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.711890697479248
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/71",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.0629644393920898
  },
  {
    "name": "will_it_fly",
    "task_id": "HumanEval/72",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.724113941192627
  },
  {
    "name": "smallest_change",
    "task_id": "HumanEval/73",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.6168043613433838
  },
  {
    "name": "total_match",
    "task_id": "HumanEval/74",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 3.006911516189575
  },
  {
    "name": "iscube",
    "task_id": "HumanEval/77",
    "Dis": 0.129,
    "Err": 0.111,
    "TotalTime": 1.411203145980835
  },
  {
    "name": "hex_key",
    "task_id": "HumanEval/78",
    "Dis": 0.0205,
    "Err": 0.0105,
    "TotalTime": 1.276615858078003
  },
  {
    "name": "decimal_to_binary",
    "task_id": "HumanEval/79",
    "Dis": 0.091,
    "Err": 0.0515,
    "TotalTime": 0.903419017791748
  },
  {
    "name": "is_happy",
    "task_id": "HumanEval/80",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2449359893798828
  },
  {
    "name": "numerical_letter_grade",
    "task_id": "HumanEval/81",
    "Dis": 0.376,
    "Err": 0.2205,
    "TotalTime": 1.8816328048706055
  },
  {
    "name": "prime_length",
    "task_id": "HumanEval/82",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3748793601989746
  },
  {
    "name": "starts_one_ends",
    "task_id": "HumanEval/83",
    "Dis": 0.7085,
    "Err": 0.8735,
    "TotalTime": 0.8742408752441406
  },
  {
    "name": "solve",
    "task_id": "HumanEval/84",
    "Dis": 0.0,
    "Err": 0.988,
    "TotalTime": 1.1028947830200195
  },
  {
    "name": "add",
    "task_id": "HumanEval/85",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4691064357757568
  },
  {
    "name": "anti_shuffle",
    "task_id": "HumanEval/86",
    "Dis": 0.0015,
    "Err": 0.0025,
    "TotalTime": 1.019918441772461
  },
  {
    "name": "get_row",
    "task_id": "HumanEval/87",
    "Dis": 0.0695,
    "Err": 0.0555,
    "TotalTime": 2.534799098968506
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/88",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.7605650424957275
  },
  {
    "name": "encrypt",
    "task_id": "HumanEval/89",
    "Dis": 0.117,
    "Err": 0.453,
    "TotalTime": 1.2634189128875732
  },
  {
    "name": "next_smallest",
    "task_id": "HumanEval/90",
    "Dis": 0.0005,
    "Err": 0.0005,
    "TotalTime": 1.4975543022155762
  },
  {
    "name": "is_bored",
    "task_id": "HumanEval/91",
    "Dis": 0.556,
    "Err": 0.63,
    "TotalTime": 1.5541672706604004
  },
  {
    "name": "any_int",
    "task_id": "HumanEval/92",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2779295444488525
  },
  {
    "name": "encode",
    "task_id": "HumanEval/93",
    "Dis": 0.286,
    "Err": 0.585,
    "TotalTime": 1.1074252128601074
  },
  {
    "name": "skjkasdkd",
    "task_id": "HumanEval/94",
    "Dis": 0.085,
    "Err": 0.078,
    "TotalTime": 2.0330023765563965
  },
  {
    "name": "check_dict_case",
    "task_id": "HumanEval/95",
    "Dis": 0.0455,
    "Err": 0.028,
    "TotalTime": 1.8398282527923584
  },
  {
    "name": "count_up_to",
    "task_id": "HumanEval/96",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5464353561401367
  },
  {
    "name": "multiply",
    "task_id": "HumanEval/97",
    "Dis": 0.152,
    "Err": 0.2385,
    "TotalTime": 0.970116138458252
  },
  {
    "name": "count_upper",
    "task_id": "HumanEval/98",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.06465482711792
  },
  {
    "name": "closest_integer",
    "task_id": "HumanEval/99",
    "Dis": 0.023,
    "Err": 0.008,
    "TotalTime": 2.0551674365997314
  },
  {
    "name": "make_a_pile",
    "task_id": "HumanEval/100",
    "Dis": 0.203,
    "Err": 0.3135,
    "TotalTime": 1.355247974395752
  },
  {
    "name": "words_string",
    "task_id": "HumanEval/101",
    "Dis": 0.0305,
    "Err": 0.025,
    "TotalTime": 1.5416643619537354
  },
  {
    "name": "choose_num",
    "task_id": "HumanEval/102",
    "Dis": 0.028,
    "Err": 0.0145,
    "TotalTime": 0.9224708080291748
  },
  {
    "name": "rounded_avg",
    "task_id": "HumanEval/103",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.015512228012085
  },
  {
    "name": "unique_digits",
    "task_id": "HumanEval/104",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.9172399044036865
  },
  {
    "name": "by_length",
    "task_id": "HumanEval/105",
    "Dis": 0.0125,
    "Err": 0.059,
    "TotalTime": 1.7879691123962402
  },
  {
    "name": "f",
    "task_id": "HumanEval/106",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5550293922424316
  },
  {
    "name": "even_odd_palindrome",
    "task_id": "HumanEval/107",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.6167101860046387
  },
  {
    "name": "count_nums",
    "task_id": "HumanEval/108",
    "Dis": 0.3955,
    "Err": 0.2535,
    "TotalTime": 1.90470290184021
  },
  {
    "name": "move_one_ball",
    "task_id": "HumanEval/109",
    "Dis": 0.0,
    "Err": 0.0025,
    "TotalTime": 1.563147783279419
  },
  {
    "name": "exchange",
    "task_id": "HumanEval/110",
    "Dis": 0.0,
    "Err": 0.012,
    "TotalTime": 2.687152862548828
  },
  {
    "name": "histogram",
    "task_id": "HumanEval/111",
    "Dis": 0.127,
    "Err": 0.355,
    "TotalTime": 1.569633960723877
  },
  {
    "name": "reverse_delete",
    "task_id": "HumanEval/112",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.507432222366333
  },
  {
    "name": "odd_count",
    "task_id": "HumanEval/113",
    "Dis": 0.303,
    "Err": 0.171,
    "TotalTime": 2.708177089691162
  },
  {
    "name": "minSubArraySum",
    "task_id": "HumanEval/114",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.6089434623718262
  },
  {
    "name": "max_fill",
    "task_id": "HumanEval/115",
    "Dis": 0.241,
    "Err": 0.5455,
    "TotalTime": 2.4751620292663574
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/116",
    "Dis": 0.1125,
    "Err": 0.0505,
    "TotalTime": 1.8345110416412354
  },
  {
    "name": "select_words",
    "task_id": "HumanEval/117",
    "Dis": 0.0215,
    "Err": 0.009,
    "TotalTime": 1.702223539352417
  },
  {
    "name": "get_closest_vowel",
    "task_id": "HumanEval/118",
    "Dis": 0.1385,
    "Err": 0.09,
    "TotalTime": 1.0628325939178467
  },
  {
    "name": "match_parens",
    "task_id": "HumanEval/119",
    "Dis": 0.288,
    "Err": 0.2355,
    "TotalTime": 2.1907310485839844
  },
  {
    "name": "maximum",
    "task_id": "HumanEval/120",
    "Dis": 0.1335,
    "Err": 0.0775,
    "TotalTime": 1.9236304759979248
  },
  {
    "name": "solution",
    "task_id": "HumanEval/121",
    "Dis": 0.0095,
    "Err": 0.023,
    "TotalTime": 1.7035748958587646
  },
  {
    "name": "add_elements",
    "task_id": "HumanEval/122",
    "Dis": 0.69,
    "Err": 0.553,
    "TotalTime": 1.7963902950286865
  },
  {
    "name": "get_odd_collatz",
    "task_id": "HumanEval/123",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "valid_date",
    "task_id": "HumanEval/124",
    "Dis": 0.007,
    "Err": 0.008,
    "TotalTime": 1.249150276184082
  },
  {
    "name": "split_words",
    "task_id": "HumanEval/125",
    "Dis": 0.123,
    "Err": 0.1095,
    "TotalTime": 1.3121516704559326
  },
  {
    "name": "is_sorted",
    "task_id": "HumanEval/126",
    "Dis": 0.024,
    "Err": 0.034,
    "TotalTime": 1.8109283447265625
  },
  {
    "name": "intersection",
    "task_id": "HumanEval/127",
    "Dis": 0.0595,
    "Err": 0.032,
    "TotalTime": 3.2730772495269775
  },
  {
    "name": "prod_signs",
    "task_id": "HumanEval/128",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2689902782440186
  },
  {
    "name": "minPath",
    "task_id": "HumanEval/129",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "tri",
    "task_id": "HumanEval/130",
    "Dis": 0.8765,
    "Err": 0.8605,
    "TotalTime": 1.5259003639221191
  },
  {
    "name": "digits",
    "task_id": "HumanEval/131",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.0751628875732422
  },
  {
    "name": "is_nested",
    "task_id": "HumanEval/132",
    "Dis": 0.337,
    "Err": 0.2795,
    "TotalTime": 1.0324828624725342
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/133",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.800825595855713
  },
  {
    "name": "check_if_last_char_is_a_letter",
    "task_id": "HumanEval/134",
    "Dis": 0.072,
    "Err": 0.041,
    "TotalTime": 1.2493481636047363
  },
  {
    "name": "can_arrange",
    "task_id": "HumanEval/135",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5662014484405518
  },
  {
    "name": "largest_smallest_integers",
    "task_id": "HumanEval/136",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.8532822132110596
  },
  {
    "name": "compare_one",
    "task_id": "HumanEval/137",
    "Dis": 0.015,
    "Err": 0.0085,
    "TotalTime": 1.5299019813537598
  },
  {
    "name": "is_equal_to_sum_even",
    "task_id": "HumanEval/138",
    "Dis": 0.026,
    "Err": 0.0135,
    "TotalTime": 1.080484390258789
  },
  {
    "name": "special_factorial",
    "task_id": "HumanEval/139",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "fix_spaces",
    "task_id": "HumanEval/140",
    "Dis": 0.2215,
    "Err": 0.1645,
    "TotalTime": 1.0712265968322754
  },
  {
    "name": "file_name_check",
    "task_id": "HumanEval/141",
    "Dis": 0.025,
    "Err": 0.013,
    "TotalTime": 1.005669355392456
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/142",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.8744423389434814
  },
  {
    "name": "words_in_sentence",
    "task_id": "HumanEval/143",
    "Dis": 0.096,
    "Err": 0.0645,
    "TotalTime": 1.3910107612609863
  },
  {
    "name": "simplify",
    "task_id": "HumanEval/144",
    "Dis": 0.0005,
    "Err": 0.0,
    "TotalTime": 28.301592350006104
  },
  {
    "name": "order_by_points",
    "task_id": "HumanEval/145",
    "Dis": 0.211,
    "Err": 0.691,
    "TotalTime": 1.9892909526824951
  },
  {
    "name": "specialFilter",
    "task_id": "HumanEval/146",
    "Dis": 0.0655,
    "Err": 0.027,
    "TotalTime": 1.705446481704712
  },
  {
    "name": "bf",
    "task_id": "HumanEval/148",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.181708574295044
  },
  {
    "name": "sorted_list_sum",
    "task_id": "HumanEval/149",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.9861814975738525
  },
  {
    "name": "x_or_y",
    "task_id": "HumanEval/150",
    "Dis": 0.0,
    "Err": 0.2075,
    "TotalTime": 1.6423709392547607
  },
  {
    "name": "double_the_difference",
    "task_id": "HumanEval/151",
    "Dis": 0.046,
    "Err": 0.0195,
    "TotalTime": 1.9569578170776367
  },
  {
    "name": "compare",
    "task_id": "HumanEval/152",
    "Dis": 0.1045,
    "Err": 0.0645,
    "TotalTime": 2.436006546020508
  },
  {
    "name": "Strongest_Extension",
    "task_id": "HumanEval/153",
    "Dis": 0.546,
    "Err": 0.41,
    "TotalTime": 2.368964433670044
  },
  {
    "name": "cycpattern_check",
    "task_id": "HumanEval/154",
    "Dis": 0.0,
    "Err": 0.041,
    "TotalTime": 1.2433981895446777
  },
  {
    "name": "even_odd_count",
    "task_id": "HumanEval/155",
    "Dis": 0.001,
    "Err": 0.001,
    "TotalTime": 1.084376335144043
  },
  {
    "name": "right_angle_triangle",
    "task_id": "HumanEval/157",
    "Dis": 0.0,
    "Err": 0.0025,
    "TotalTime": 0.9777927398681641
  },
  {
    "name": "find_max",
    "task_id": "HumanEval/158",
    "Dis": 0.061,
    "Err": 0.0635,
    "TotalTime": 1.7389404773712158
  },
  {
    "name": "eat",
    "task_id": "HumanEval/159",
    "Dis": 0.154,
    "Err": 0.068,
    "TotalTime": 1.5416090488433838
  },
  {
    "name": "solve",
    "task_id": "HumanEval/161",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.0323262214660645
  },
  {
    "name": "string_to_md5",
    "task_id": "HumanEval/162",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3705940246582031
  },
  {
    "name": "generate_integers",
    "task_id": "HumanEval/163",
    "Dis": 0.2605,
    "Err": 0.3645,
    "TotalTime": 1.4375035762786865
  }
]