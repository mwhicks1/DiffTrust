[
  {
    "name": "has_close_elements",
    "task_id": "HumanEval/0",
    "Dis": 0.008666666666666666,
    "Err": 0.051333333333333335,
    "TotalTime": 1.2285244464874268
  },
  {
    "name": "separate_paren_groups",
    "task_id": "HumanEval/1",
    "Dis": 0.29733333333333334,
    "Err": 0.196,
    "TotalTime": 1.0019683837890625
  },
  {
    "name": "truncate_number",
    "task_id": "HumanEval/2",
    "Dis": 0.0,
    "Err": 0.226,
    "TotalTime": 0.8134803771972656
  },
  {
    "name": "below_zero",
    "task_id": "HumanEval/3",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.136171817779541
  },
  {
    "name": "mean_absolute_deviation",
    "task_id": "HumanEval/4",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1240544319152832
  },
  {
    "name": "intersperse",
    "task_id": "HumanEval/5",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.045006275177002
  },
  {
    "name": "parse_nested_parens",
    "task_id": "HumanEval/6",
    "Dis": 0.0,
    "Err": 0.384,
    "TotalTime": 0.9672949314117432
  },
  {
    "name": "filter_by_substring",
    "task_id": "HumanEval/7",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.508387565612793
  },
  {
    "name": "sum_product",
    "task_id": "HumanEval/8",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1093652248382568
  },
  {
    "name": "rolling_max",
    "task_id": "HumanEval/9",
    "Dis": 0.012,
    "Err": 0.03933333333333333,
    "TotalTime": 1.0964422225952148
  },
  {
    "name": "make_palindrome",
    "task_id": "HumanEval/10",
    "Dis": 0.33266666666666667,
    "Err": 0.22266666666666668,
    "TotalTime": 0.9607369899749756
  },
  {
    "name": "string_xor",
    "task_id": "HumanEval/11",
    "Dis": 0.4033333333333333,
    "Err": 0.8626666666666667,
    "TotalTime": 1.1900606155395508
  },
  {
    "name": "longest",
    "task_id": "HumanEval/12",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2225046157836914
  },
  {
    "name": "greatest_common_divisor",
    "task_id": "HumanEval/13",
    "Dis": 0.08466666666666667,
    "Err": 0.048666666666666664,
    "TotalTime": 0.829582691192627
  },
  {
    "name": "all_prefixes",
    "task_id": "HumanEval/14",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9546747207641602
  },
  {
    "name": "string_sequence",
    "task_id": "HumanEval/15",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.7906708717346191
  },
  {
    "name": "count_distinct_characters",
    "task_id": "HumanEval/16",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.0006604194641113
  },
  {
    "name": "parse_music",
    "task_id": "HumanEval/17",
    "Dis": 0.06,
    "Err": 0.03933333333333333,
    "TotalTime": 1.60587477684021
  },
  {
    "name": "how_many_times",
    "task_id": "HumanEval/18",
    "Dis": 0.018,
    "Err": 0.01,
    "TotalTime": 1.112999439239502
  },
  {
    "name": "sort_numbers",
    "task_id": "HumanEval/19",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.304386854171753
  },
  {
    "name": "find_closest_elements",
    "task_id": "HumanEval/20",
    "Dis": 0.0006666666666666666,
    "Err": 0.0026666666666666666,
    "TotalTime": 1.172605276107788
  },
  {
    "name": "rescale_to_unit",
    "task_id": "HumanEval/21",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2767589092254639
  },
  {
    "name": "filter_integers",
    "task_id": "HumanEval/22",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.0747935771942139
  },
  {
    "name": "strlen",
    "task_id": "HumanEval/23",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9060945510864258
  },
  {
    "name": "largest_divisor",
    "task_id": "HumanEval/24",
    "Dis": 0.10133333333333333,
    "Err": 0.07266666666666667,
    "TotalTime": 0.8216142654418945
  },
  {
    "name": "factorize",
    "task_id": "HumanEval/25",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "remove_duplicates",
    "task_id": "HumanEval/26",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1142230033874512
  },
  {
    "name": "flip_case",
    "task_id": "HumanEval/27",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9031939506530762
  },
  {
    "name": "concatenate",
    "task_id": "HumanEval/28",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3069162368774414
  },
  {
    "name": "filter_by_prefix",
    "task_id": "HumanEval/29",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.779789686203003
  },
  {
    "name": "get_positive",
    "task_id": "HumanEval/30",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1972124576568604
  },
  {
    "name": "is_prime",
    "task_id": "HumanEval/31",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2233753204345703
  },
  {
    "name": "unique",
    "task_id": "HumanEval/34",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1817693710327148
  },
  {
    "name": "max_element",
    "task_id": "HumanEval/35",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1542253494262695
  },
  {
    "name": "sort_even",
    "task_id": "HumanEval/37",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2045116424560547
  },
  {
    "name": "triples_sum_to_zero",
    "task_id": "HumanEval/40",
    "Dis": 0.0,
    "Err": 0.0026666666666666666,
    "TotalTime": 1.0960023403167725
  },
  {
    "name": "car_race_collision",
    "task_id": "HumanEval/41",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.761962890625
  },
  {
    "name": "incr_list",
    "task_id": "HumanEval/42",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2282404899597168
  },
  {
    "name": "pairs_sum_to_zero",
    "task_id": "HumanEval/43",
    "Dis": 0.0,
    "Err": 0.011333333333333334,
    "TotalTime": 1.1314036846160889
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/45",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9203569889068604
  },
  {
    "name": "fib4",
    "task_id": "HumanEval/46",
    "Dis": 0.04933333333333333,
    "Err": 0.04066666666666666,
    "TotalTime": 0.8230502605438232
  },
  {
    "name": "median",
    "task_id": "HumanEval/47",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1265573501586914
  },
  {
    "name": "is_palindrome",
    "task_id": "HumanEval/48",
    "Dis": 0.042666666666666665,
    "Err": 0.024666666666666667,
    "TotalTime": 0.8940880298614502
  },
  {
    "name": "modp",
    "task_id": "HumanEval/49",
    "Dis": 0.044,
    "Err": 0.17266666666666666,
    "TotalTime": 0.8898656368255615
  },
  {
    "name": "remove_vowels",
    "task_id": "HumanEval/51",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9307045936584473
  },
  {
    "name": "below_threshold",
    "task_id": "HumanEval/52",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1595168113708496
  },
  {
    "name": "add",
    "task_id": "HumanEval/53",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.8134372234344482
  },
  {
    "name": "same_chars",
    "task_id": "HumanEval/54",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.0799877643585205
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/56",
    "Dis": 0.0,
    "Err": 0.4126666666666667,
    "TotalTime": 0.9332759380340576
  },
  {
    "name": "monotonic",
    "task_id": "HumanEval/57",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1187045574188232
  },
  {
    "name": "common",
    "task_id": "HumanEval/58",
    "Dis": 0.0,
    "Err": 0.36333333333333334,
    "TotalTime": 1.2963533401489258
  },
  {
    "name": "largest_prime_factor",
    "task_id": "HumanEval/59",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "sum_to_n",
    "task_id": "HumanEval/60",
    "Dis": 0.0,
    "Err": 0.21,
    "TotalTime": 0.7975058555603027
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/61",
    "Dis": 0.0,
    "Err": 0.40066666666666667,
    "TotalTime": 0.9055111408233643
  },
  {
    "name": "derivative",
    "task_id": "HumanEval/62",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.101301670074463
  },
  {
    "name": "vowels_count",
    "task_id": "HumanEval/64",
    "Dis": 0.04466666666666667,
    "Err": 0.02666666666666667,
    "TotalTime": 0.9350953102111816
  },
  {
    "name": "circular_shift",
    "task_id": "HumanEval/65",
    "Dis": 0.008666666666666666,
    "Err": 0.13133333333333333,
    "TotalTime": 0.8486456871032715
  },
  {
    "name": "digitSum",
    "task_id": "HumanEval/66",
    "Dis": 0.06533333333333333,
    "Err": 0.034,
    "TotalTime": 0.9213912487030029
  },
  {
    "name": "fruit_distribution",
    "task_id": "HumanEval/67",
    "Dis": 0.5366666666666666,
    "Err": 0.6706666666666666,
    "TotalTime": 1.0465354919433594
  },
  {
    "name": "pluck",
    "task_id": "HumanEval/68",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1546649932861328
  },
  {
    "name": "search",
    "task_id": "HumanEval/69",
    "Dis": 0.0,
    "Err": 0.098,
    "TotalTime": 1.3580749034881592
  },
  {
    "name": "strange_sort_list",
    "task_id": "HumanEval/70",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1424469947814941
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/71",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.8987832069396973
  },
  {
    "name": "will_it_fly",
    "task_id": "HumanEval/72",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.17518949508667
  },
  {
    "name": "smallest_change",
    "task_id": "HumanEval/73",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.0760996341705322
  },
  {
    "name": "total_match",
    "task_id": "HumanEval/74",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.1080007553100586
  },
  {
    "name": "iscube",
    "task_id": "HumanEval/77",
    "Dis": 0.06866666666666667,
    "Err": 0.028,
    "TotalTime": 0.8184826374053955
  },
  {
    "name": "hex_key",
    "task_id": "HumanEval/78",
    "Dis": 0.0,
    "Err": 0.03333333333333333,
    "TotalTime": 0.9300973415374756
  },
  {
    "name": "decimal_to_binary",
    "task_id": "HumanEval/79",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.837268590927124
  },
  {
    "name": "is_happy",
    "task_id": "HumanEval/80",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9432857036590576
  },
  {
    "name": "numerical_letter_grade",
    "task_id": "HumanEval/81",
    "Dis": 0.234,
    "Err": 0.13466666666666666,
    "TotalTime": 1.1704435348510742
  },
  {
    "name": "prime_length",
    "task_id": "HumanEval/82",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2263095378875732
  },
  {
    "name": "starts_one_ends",
    "task_id": "HumanEval/83",
    "Dis": 0.46,
    "Err": 0.966,
    "TotalTime": 0.8142914772033691
  },
  {
    "name": "solve",
    "task_id": "HumanEval/84",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.8102939128875732
  },
  {
    "name": "add",
    "task_id": "HumanEval/85",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1213924884796143
  },
  {
    "name": "anti_shuffle",
    "task_id": "HumanEval/86",
    "Dis": 0.464,
    "Err": 0.47933333333333333,
    "TotalTime": 1.0201544761657715
  },
  {
    "name": "get_row",
    "task_id": "HumanEval/87",
    "Dis": 0.0,
    "Err": 0.0006666666666666666,
    "TotalTime": 1.7523152828216553
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/88",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1104023456573486
  },
  {
    "name": "encrypt",
    "task_id": "HumanEval/89",
    "Dis": 0.09066666666666667,
    "Err": 0.3893333333333333,
    "TotalTime": 0.9235222339630127
  },
  {
    "name": "next_smallest",
    "task_id": "HumanEval/90",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1229677200317383
  },
  {
    "name": "is_bored",
    "task_id": "HumanEval/91",
    "Dis": 0.072,
    "Err": 0.04733333333333333,
    "TotalTime": 0.9550621509552002
  },
  {
    "name": "any_int",
    "task_id": "HumanEval/92",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.936837911605835
  },
  {
    "name": "encode",
    "task_id": "HumanEval/93",
    "Dis": 0.31133333333333335,
    "Err": 0.204,
    "TotalTime": 0.9652888774871826
  },
  {
    "name": "skjkasdkd",
    "task_id": "HumanEval/94",
    "Dis": 0.0,
    "Err": 0.011333333333333334,
    "TotalTime": 1.7691524028778076
  },
  {
    "name": "check_dict_case",
    "task_id": "HumanEval/95",
    "Dis": 0.0,
    "Err": 0.010666666666666666,
    "TotalTime": 1.165879726409912
  },
  {
    "name": "count_up_to",
    "task_id": "HumanEval/96",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9892842769622803
  },
  {
    "name": "multiply",
    "task_id": "HumanEval/97",
    "Dis": 0.0,
    "Err": 0.206,
    "TotalTime": 0.8296024799346924
  },
  {
    "name": "count_upper",
    "task_id": "HumanEval/98",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9252264499664307
  },
  {
    "name": "closest_integer",
    "task_id": "HumanEval/99",
    "Dis": 0.0,
    "Err": 0.0006666666666666666,
    "TotalTime": 1.724724292755127
  },
  {
    "name": "make_a_pile",
    "task_id": "HumanEval/100",
    "Dis": 0.20266666666666666,
    "Err": 0.14733333333333334,
    "TotalTime": 0.818300724029541
  },
  {
    "name": "words_string",
    "task_id": "HumanEval/101",
    "Dis": 0.052,
    "Err": 0.26466666666666666,
    "TotalTime": 0.9700818061828613
  },
  {
    "name": "choose_num",
    "task_id": "HumanEval/102",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.8616247177124023
  },
  {
    "name": "rounded_avg",
    "task_id": "HumanEval/103",
    "Dis": 0.04066666666666666,
    "Err": 0.020666666666666667,
    "TotalTime": 0.9051356315612793
  },
  {
    "name": "unique_digits",
    "task_id": "HumanEval/104",
    "Dis": 0.03666666666666667,
    "Err": 0.02,
    "TotalTime": 1.252920389175415
  },
  {
    "name": "by_length",
    "task_id": "HumanEval/105",
    "Dis": 0.0026666666666666666,
    "Err": 0.07333333333333333,
    "TotalTime": 1.1338844299316406
  },
  {
    "name": "f",
    "task_id": "HumanEval/106",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9246435165405273
  },
  {
    "name": "even_odd_palindrome",
    "task_id": "HumanEval/107",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.111349105834961
  },
  {
    "name": "count_nums",
    "task_id": "HumanEval/108",
    "Dis": 0.032,
    "Err": 0.018,
    "TotalTime": 1.309455394744873
  },
  {
    "name": "move_one_ball",
    "task_id": "HumanEval/109",
    "Dis": 0.025333333333333333,
    "Err": 0.012,
    "TotalTime": 1.1042697429656982
  },
  {
    "name": "exchange",
    "task_id": "HumanEval/110",
    "Dis": 0.0,
    "Err": 0.008666666666666666,
    "TotalTime": 1.8515825271606445
  },
  {
    "name": "histogram",
    "task_id": "HumanEval/111",
    "Dis": 0.30533333333333335,
    "Err": 0.43666666666666665,
    "TotalTime": 0.925609827041626
  },
  {
    "name": "reverse_delete",
    "task_id": "HumanEval/112",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1214649677276611
  },
  {
    "name": "odd_count",
    "task_id": "HumanEval/113",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.7912147045135498
  },
  {
    "name": "minSubArraySum",
    "task_id": "HumanEval/114",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1576929092407227
  },
  {
    "name": "max_fill",
    "task_id": "HumanEval/115",
    "Dis": 0.20466666666666666,
    "Err": 0.18333333333333332,
    "TotalTime": 1.6900780200958252
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/116",
    "Dis": 0.07666666666666666,
    "Err": 0.028,
    "TotalTime": 1.1798582077026367
  },
  {
    "name": "select_words",
    "task_id": "HumanEval/117",
    "Dis": 0.0013333333333333333,
    "Err": 0.051333333333333335,
    "TotalTime": 1.0118927955627441
  },
  {
    "name": "get_closest_vowel",
    "task_id": "HumanEval/118",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.922405481338501
  },
  {
    "name": "match_parens",
    "task_id": "HumanEval/119",
    "Dis": 0.168,
    "Err": 0.20533333333333334,
    "TotalTime": 1.3176159858703613
  },
  {
    "name": "maximum",
    "task_id": "HumanEval/120",
    "Dis": 0.005333333333333333,
    "Err": 0.0033333333333333335,
    "TotalTime": 1.2246434688568115
  },
  {
    "name": "solution",
    "task_id": "HumanEval/121",
    "Dis": 0.0,
    "Err": 0.02666666666666667,
    "TotalTime": 1.0935595035552979
  },
  {
    "name": "add_elements",
    "task_id": "HumanEval/122",
    "Dis": 0.17733333333333334,
    "Err": 0.2653333333333333,
    "TotalTime": 1.1881654262542725
  },
  {
    "name": "get_odd_collatz",
    "task_id": "HumanEval/123",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "valid_date",
    "task_id": "HumanEval/124",
    "Dis": 0.014666666666666666,
    "Err": 0.016666666666666666,
    "TotalTime": 0.9481439590454102
  },
  {
    "name": "split_words",
    "task_id": "HumanEval/125",
    "Dis": 0.06066666666666667,
    "Err": 0.06666666666666667,
    "TotalTime": 0.9266054630279541
  },
  {
    "name": "is_sorted",
    "task_id": "HumanEval/126",
    "Dis": 0.009333333333333334,
    "Err": 0.006,
    "TotalTime": 1.1452455520629883
  },
  {
    "name": "intersection",
    "task_id": "HumanEval/127",
    "Dis": 0.16066666666666668,
    "Err": 0.6873333333333334,
    "TotalTime": 2.5517184734344482
  },
  {
    "name": "prod_signs",
    "task_id": "HumanEval/128",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1453020572662354
  },
  {
    "name": "minPath",
    "task_id": "HumanEval/129",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "tri",
    "task_id": "HumanEval/130",
    "Dis": 0.7546666666666667,
    "Err": 0.7906666666666666,
    "TotalTime": 0.8421132564544678
  },
  {
    "name": "digits",
    "task_id": "HumanEval/131",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.8160433769226074
  },
  {
    "name": "is_nested",
    "task_id": "HumanEval/132",
    "Dis": 0.09266666666666666,
    "Err": 0.12266666666666666,
    "TotalTime": 0.9207446575164795
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/133",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.152557373046875
  },
  {
    "name": "check_if_last_char_is_a_letter",
    "task_id": "HumanEval/134",
    "Dis": 0.082,
    "Err": 0.11133333333333334,
    "TotalTime": 0.9381773471832275
  },
  {
    "name": "can_arrange",
    "task_id": "HumanEval/135",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.136894941329956
  },
  {
    "name": "largest_smallest_integers",
    "task_id": "HumanEval/136",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1516237258911133
  },
  {
    "name": "compare_one",
    "task_id": "HumanEval/137",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1695077419281006
  },
  {
    "name": "is_equal_to_sum_even",
    "task_id": "HumanEval/138",
    "Dis": 0.027333333333333334,
    "Err": 0.01,
    "TotalTime": 0.808478832244873
  },
  {
    "name": "special_factorial",
    "task_id": "HumanEval/139",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "fix_spaces",
    "task_id": "HumanEval/140",
    "Dis": 0.06866666666666667,
    "Err": 0.062,
    "TotalTime": 0.9807493686676025
  },
  {
    "name": "file_name_check",
    "task_id": "HumanEval/141",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9197003841400146
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/142",
    "Dis": 0.138,
    "Err": 0.07,
    "TotalTime": 1.1908926963806152
  },
  {
    "name": "words_in_sentence",
    "task_id": "HumanEval/143",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.312913179397583
  },
  {
    "name": "simplify",
    "task_id": "HumanEval/144",
    "Dis": 0.0,
    "Err": 0.0033333333333333335,
    "TotalTime": 22.594433546066284
  },
  {
    "name": "order_by_points",
    "task_id": "HumanEval/145",
    "Dis": 0.030666666666666665,
    "Err": 0.6973333333333334,
    "TotalTime": 1.292290449142456
  },
  {
    "name": "specialFilter",
    "task_id": "HumanEval/146",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1705248355865479
  },
  {
    "name": "bf",
    "task_id": "HumanEval/148",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.0923805236816406
  },
  {
    "name": "sorted_list_sum",
    "task_id": "HumanEval/149",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3660850524902344
  },
  {
    "name": "x_or_y",
    "task_id": "HumanEval/150",
    "Dis": 0.0,
    "Err": 0.236,
    "TotalTime": 1.2864787578582764
  },
  {
    "name": "double_the_difference",
    "task_id": "HumanEval/151",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5788366794586182
  },
  {
    "name": "compare",
    "task_id": "HumanEval/152",
    "Dis": 0.058666666666666666,
    "Err": 0.038,
    "TotalTime": 1.7837865352630615
  },
  {
    "name": "Strongest_Extension",
    "task_id": "HumanEval/153",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.7039844989776611
  },
  {
    "name": "cycpattern_check",
    "task_id": "HumanEval/154",
    "Dis": 0.19466666666666665,
    "Err": 0.13866666666666666,
    "TotalTime": 1.1052134037017822
  },
  {
    "name": "even_odd_count",
    "task_id": "HumanEval/155",
    "Dis": 0.0033333333333333335,
    "Err": 0.007333333333333333,
    "TotalTime": 0.8115394115447998
  },
  {
    "name": "right_angle_triangle",
    "task_id": "HumanEval/157",
    "Dis": 0.0,
    "Err": 0.0013333333333333333,
    "TotalTime": 0.9531958103179932
  },
  {
    "name": "find_max",
    "task_id": "HumanEval/158",
    "Dis": 0.004,
    "Err": 0.034,
    "TotalTime": 1.2706754207611084
  },
  {
    "name": "eat",
    "task_id": "HumanEval/159",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9544157981872559
  },
  {
    "name": "solve",
    "task_id": "HumanEval/161",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9447617530822754
  },
  {
    "name": "string_to_md5",
    "task_id": "HumanEval/162",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.0923833847045898
  },
  {
    "name": "generate_integers",
    "task_id": "HumanEval/163",
    "Dis": 0.0,
    "Err": 0.9713333333333334,
    "TotalTime": 0.8949885368347168
  }
]