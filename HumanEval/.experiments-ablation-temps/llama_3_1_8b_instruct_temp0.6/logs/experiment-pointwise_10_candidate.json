[
  {
    "name": "has_close_elements",
    "task_id": "HumanEval/0",
    "Dis": 0.0,
    "Err": 0.059,
    "TotalTime": 0.9623048305511475
  },
  {
    "name": "separate_paren_groups",
    "task_id": "HumanEval/1",
    "Dis": 0.752,
    "Err": 0.635,
    "TotalTime": 0.8032186031341553
  },
  {
    "name": "truncate_number",
    "task_id": "HumanEval/2",
    "Dis": 0.069,
    "Err": 0.176,
    "TotalTime": 0.6818406581878662
  },
  {
    "name": "below_zero",
    "task_id": "HumanEval/3",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.892646312713623
  },
  {
    "name": "mean_absolute_deviation",
    "task_id": "HumanEval/4",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9324090480804443
  },
  {
    "name": "intersperse",
    "task_id": "HumanEval/5",
    "Dis": 0.038,
    "Err": 0.02,
    "TotalTime": 0.8778855800628662
  },
  {
    "name": "parse_nested_parens",
    "task_id": "HumanEval/6",
    "Dis": 0.182,
    "Err": 0.437,
    "TotalTime": 0.7823936939239502
  },
  {
    "name": "filter_by_substring",
    "task_id": "HumanEval/7",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.157012701034546
  },
  {
    "name": "sum_product",
    "task_id": "HumanEval/8",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9306576251983643
  },
  {
    "name": "rolling_max",
    "task_id": "HumanEval/9",
    "Dis": 0.04,
    "Err": 0.066,
    "TotalTime": 0.8795394897460938
  },
  {
    "name": "make_palindrome",
    "task_id": "HumanEval/10",
    "Dis": 0.747,
    "Err": 0.624,
    "TotalTime": 0.7847168445587158
  },
  {
    "name": "string_xor",
    "task_id": "HumanEval/11",
    "Dis": 0.749,
    "Err": 0.746,
    "TotalTime": 0.9350829124450684
  },
  {
    "name": "longest",
    "task_id": "HumanEval/12",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9631674289703369
  },
  {
    "name": "greatest_common_divisor",
    "task_id": "HumanEval/13",
    "Dis": 0.108,
    "Err": 0.112,
    "TotalTime": 0.726032018661499
  },
  {
    "name": "all_prefixes",
    "task_id": "HumanEval/14",
    "Dis": 0.153,
    "Err": 0.06,
    "TotalTime": 0.8028666973114014
  },
  {
    "name": "string_sequence",
    "task_id": "HumanEval/15",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6911787986755371
  },
  {
    "name": "count_distinct_characters",
    "task_id": "HumanEval/16",
    "Dis": 0.257,
    "Err": 0.12,
    "TotalTime": 0.7878026962280273
  },
  {
    "name": "parse_music",
    "task_id": "HumanEval/17",
    "Dis": 0.334,
    "Err": 0.187,
    "TotalTime": 1.251417636871338
  },
  {
    "name": "how_many_times",
    "task_id": "HumanEval/18",
    "Dis": 0.173,
    "Err": 0.093,
    "TotalTime": 0.9323925971984863
  },
  {
    "name": "sort_numbers",
    "task_id": "HumanEval/19",
    "Dis": 0.134,
    "Err": 0.076,
    "TotalTime": 1.7732820510864258
  },
  {
    "name": "find_closest_elements",
    "task_id": "HumanEval/20",
    "Dis": 0.029,
    "Err": 0.037,
    "TotalTime": 0.9609625339508057
  },
  {
    "name": "rescale_to_unit",
    "task_id": "HumanEval/21",
    "Dis": 0.0,
    "Err": 0.001,
    "TotalTime": 0.9499382972717285
  },
  {
    "name": "filter_integers",
    "task_id": "HumanEval/22",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.873265266418457
  },
  {
    "name": "strlen",
    "task_id": "HumanEval/23",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.8071475028991699
  },
  {
    "name": "largest_divisor",
    "task_id": "HumanEval/24",
    "Dis": 0.081,
    "Err": 0.175,
    "TotalTime": 0.6777620315551758
  },
  {
    "name": "factorize",
    "task_id": "HumanEval/25",
    "Dis": 0.123,
    "Err": 0.081,
    "TotalTime": 1.4296443462371826
  },
  {
    "name": "remove_duplicates",
    "task_id": "HumanEval/26",
    "Dis": 0.0,
    "Err": 0.446,
    "TotalTime": 0.9360623359680176
  },
  {
    "name": "flip_case",
    "task_id": "HumanEval/27",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.776679277420044
  },
  {
    "name": "concatenate",
    "task_id": "HumanEval/28",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.0856266021728516
  },
  {
    "name": "filter_by_prefix",
    "task_id": "HumanEval/29",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3142545223236084
  },
  {
    "name": "get_positive",
    "task_id": "HumanEval/30",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9430580139160156
  },
  {
    "name": "is_prime",
    "task_id": "HumanEval/31",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.8896389007568359
  },
  {
    "name": "unique",
    "task_id": "HumanEval/34",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9378871917724609
  },
  {
    "name": "max_element",
    "task_id": "HumanEval/35",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9485146999359131
  },
  {
    "name": "sort_even",
    "task_id": "HumanEval/37",
    "Dis": 0.36,
    "Err": 0.199,
    "TotalTime": 0.9585599899291992
  },
  {
    "name": "triples_sum_to_zero",
    "task_id": "HumanEval/40",
    "Dis": 0.104,
    "Err": 0.079,
    "TotalTime": 0.892672061920166
  },
  {
    "name": "car_race_collision",
    "task_id": "HumanEval/41",
    "Dis": 0.664,
    "Err": 0.971,
    "TotalTime": 0.6819162368774414
  },
  {
    "name": "incr_list",
    "task_id": "HumanEval/42",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9350070953369141
  },
  {
    "name": "pairs_sum_to_zero",
    "task_id": "HumanEval/43",
    "Dis": 0.0,
    "Err": 0.011,
    "TotalTime": 0.8856844902038574
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/45",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.7054708003997803
  },
  {
    "name": "fib4",
    "task_id": "HumanEval/46",
    "Failed": "Exception occurred during compilation of LLM-generated code -- TimeoutError : "
  },
  {
    "name": "median",
    "task_id": "HumanEval/47",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9086899757385254
  },
  {
    "name": "is_palindrome",
    "task_id": "HumanEval/48",
    "Dis": 0.002,
    "Err": 0.002,
    "TotalTime": 0.7414343357086182
  },
  {
    "name": "modp",
    "task_id": "HumanEval/49",
    "Dis": 0.058,
    "Err": 0.215,
    "TotalTime": 0.8170256614685059
  },
  {
    "name": "remove_vowels",
    "task_id": "HumanEval/51",
    "Dis": 0.218,
    "Err": 0.102,
    "TotalTime": 0.7880513668060303
  },
  {
    "name": "below_threshold",
    "task_id": "HumanEval/52",
    "Dis": 0.004,
    "Err": 0.0,
    "TotalTime": 0.8938841819763184
  },
  {
    "name": "add",
    "task_id": "HumanEval/53",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6807041168212891
  },
  {
    "name": "same_chars",
    "task_id": "HumanEval/54",
    "Dis": 0.005,
    "Err": 0.0,
    "TotalTime": 0.9240305423736572
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/56",
    "Dis": 0.0,
    "Err": 0.397,
    "TotalTime": 0.7397918701171875
  },
  {
    "name": "monotonic",
    "task_id": "HumanEval/57",
    "Dis": 0.012,
    "Err": 0.009,
    "TotalTime": 0.8915932178497314
  },
  {
    "name": "common",
    "task_id": "HumanEval/58",
    "Dis": 0.229,
    "Err": 0.491,
    "TotalTime": 0.955902099609375
  },
  {
    "name": "largest_prime_factor",
    "task_id": "HumanEval/59",
    "Dis": 0.084,
    "Err": 0.072,
    "TotalTime": 1.4241738319396973
  },
  {
    "name": "sum_to_n",
    "task_id": "HumanEval/60",
    "Dis": 0.11,
    "Err": 0.184,
    "TotalTime": 0.6255085468292236
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/61",
    "Dis": 0.038,
    "Err": 0.446,
    "TotalTime": 0.7516045570373535
  },
  {
    "name": "derivative",
    "task_id": "HumanEval/62",
    "Dis": 0.53,
    "Err": 0.307,
    "TotalTime": 0.8353044986724854
  },
  {
    "name": "vowels_count",
    "task_id": "HumanEval/64",
    "Dis": 0.039,
    "Err": 0.02,
    "TotalTime": 0.7566239833831787
  },
  {
    "name": "circular_shift",
    "task_id": "HumanEval/65",
    "Dis": 0.301,
    "Err": 0.371,
    "TotalTime": 0.6941850185394287
  },
  {
    "name": "digitSum",
    "task_id": "HumanEval/66",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.7386846542358398
  },
  {
    "name": "fruit_distribution",
    "task_id": "HumanEval/67",
    "Dis": 0.55,
    "Err": 0.791,
    "TotalTime": 0.8038759231567383
  },
  {
    "name": "pluck",
    "task_id": "HumanEval/68",
    "Dis": 0.184,
    "Err": 0.078,
    "TotalTime": 0.8825547695159912
  },
  {
    "name": "search",
    "task_id": "HumanEval/69",
    "Dis": 0.111,
    "Err": 0.171,
    "TotalTime": 1.057178258895874
  },
  {
    "name": "strange_sort_list",
    "task_id": "HumanEval/70",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.8677880764007568
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/71",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.751662015914917
  },
  {
    "name": "will_it_fly",
    "task_id": "HumanEval/72",
    "Dis": 0.016,
    "Err": 0.005,
    "TotalTime": 0.9669458866119385
  },
  {
    "name": "smallest_change",
    "task_id": "HumanEval/73",
    "Dis": 0.624,
    "Err": 0.776,
    "TotalTime": 0.8465526103973389
  },
  {
    "name": "total_match",
    "task_id": "HumanEval/74",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.501117467880249
  },
  {
    "name": "iscube",
    "task_id": "HumanEval/77",
    "Dis": 0.385,
    "Err": 0.382,
    "TotalTime": 0.580470085144043
  },
  {
    "name": "hex_key",
    "task_id": "HumanEval/78",
    "Dis": 0.224,
    "Err": 0.182,
    "TotalTime": 0.8194212913513184
  },
  {
    "name": "decimal_to_binary",
    "task_id": "HumanEval/79",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6726360321044922
  },
  {
    "name": "is_happy",
    "task_id": "HumanEval/80",
    "Dis": 0.157,
    "Err": 0.08,
    "TotalTime": 0.7616891860961914
  },
  {
    "name": "numerical_letter_grade",
    "task_id": "HumanEval/81",
    "Dis": 0.528,
    "Err": 0.508,
    "TotalTime": 0.9269633293151855
  },
  {
    "name": "prime_length",
    "task_id": "HumanEval/82",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.828143835067749
  },
  {
    "name": "starts_one_ends",
    "task_id": "HumanEval/83",
    "Dis": 0.804,
    "Err": 0.988,
    "TotalTime": 0.6634354591369629
  },
  {
    "name": "solve",
    "task_id": "HumanEval/84",
    "Dis": 0.522,
    "Err": 0.872,
    "TotalTime": 0.646702766418457
  },
  {
    "name": "add",
    "task_id": "HumanEval/85",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.8731050491333008
  },
  {
    "name": "anti_shuffle",
    "task_id": "HumanEval/86",
    "Dis": 0.307,
    "Err": 0.397,
    "TotalTime": 0.7693278789520264
  },
  {
    "name": "get_row",
    "task_id": "HumanEval/87",
    "Dis": 0.128,
    "Err": 0.08,
    "TotalTime": 1.318542718887329
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/88",
    "Dis": 0.165,
    "Err": 0.084,
    "TotalTime": 0.9137344360351562
  },
  {
    "name": "encrypt",
    "task_id": "HumanEval/89",
    "Dis": 0.477,
    "Err": 0.431,
    "TotalTime": 0.761777400970459
  },
  {
    "name": "next_smallest",
    "task_id": "HumanEval/90",
    "Dis": 0.244,
    "Err": 0.172,
    "TotalTime": 0.8782804012298584
  },
  {
    "name": "is_bored",
    "task_id": "HumanEval/91",
    "Dis": 0.04,
    "Err": 0.151,
    "TotalTime": 0.7522890567779541
  },
  {
    "name": "any_int",
    "task_id": "HumanEval/92",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.7586896419525146
  },
  {
    "name": "encode",
    "task_id": "HumanEval/93",
    "Dis": 0.602,
    "Err": 0.68,
    "TotalTime": 0.7563190460205078
  },
  {
    "name": "skjkasdkd",
    "task_id": "HumanEval/94",
    "Dis": 0.054,
    "Err": 0.089,
    "TotalTime": 1.244934320449829
  },
  {
    "name": "check_dict_case",
    "task_id": "HumanEval/95",
    "Dis": 0.162,
    "Err": 0.124,
    "TotalTime": 0.9365119934082031
  },
  {
    "name": "count_up_to",
    "task_id": "HumanEval/96",
    "Dis": 0.062,
    "Err": 0.024,
    "TotalTime": 0.8214626312255859
  },
  {
    "name": "multiply",
    "task_id": "HumanEval/97",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6831774711608887
  },
  {
    "name": "count_upper",
    "task_id": "HumanEval/98",
    "Dis": 0.117,
    "Err": 0.095,
    "TotalTime": 0.7300348281860352
  },
  {
    "name": "closest_integer",
    "task_id": "HumanEval/99",
    "Dis": 0.383,
    "Err": 0.233,
    "TotalTime": 1.272465467453003
  },
  {
    "name": "make_a_pile",
    "task_id": "HumanEval/100",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "words_string",
    "task_id": "HumanEval/101",
    "Dis": 0.046,
    "Err": 0.021,
    "TotalTime": 0.775198221206665
  },
  {
    "name": "choose_num",
    "task_id": "HumanEval/102",
    "Dis": 0.352,
    "Err": 0.44,
    "TotalTime": 0.8307375907897949
  },
  {
    "name": "rounded_avg",
    "task_id": "HumanEval/103",
    "Dis": 0.487,
    "Err": 0.465,
    "TotalTime": 0.7252373695373535
  },
  {
    "name": "unique_digits",
    "task_id": "HumanEval/104",
    "Dis": 0.003,
    "Err": 0.001,
    "TotalTime": 1.073030710220337
  },
  {
    "name": "by_length",
    "task_id": "HumanEval/105",
    "Dis": 0.371,
    "Err": 0.252,
    "TotalTime": 0.9221372604370117
  },
  {
    "name": "f",
    "task_id": "HumanEval/106",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.7811346054077148
  },
  {
    "name": "even_odd_palindrome",
    "task_id": "HumanEval/107",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.7806475162506104
  },
  {
    "name": "count_nums",
    "task_id": "HumanEval/108",
    "Dis": 0.462,
    "Err": 0.507,
    "TotalTime": 0.9717280864715576
  },
  {
    "name": "move_one_ball",
    "task_id": "HumanEval/109",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "exchange",
    "task_id": "HumanEval/110",
    "Dis": 0.318,
    "Err": 0.251,
    "TotalTime": 1.3026776313781738
  },
  {
    "name": "histogram",
    "task_id": "HumanEval/111",
    "Dis": 0.003,
    "Err": 0.302,
    "TotalTime": 0.7763791084289551
  },
  {
    "name": "reverse_delete",
    "task_id": "HumanEval/112",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.8741450309753418
  },
  {
    "name": "odd_count",
    "task_id": "HumanEval/113",
    "Dis": 0.765,
    "Err": 0.605,
    "TotalTime": 1.3659284114837646
  },
  {
    "name": "minSubArraySum",
    "task_id": "HumanEval/114",
    "Dis": 0.403,
    "Err": 0.24,
    "TotalTime": 0.8763716220855713
  },
  {
    "name": "max_fill",
    "task_id": "HumanEval/115",
    "Dis": 0.606,
    "Err": 0.599,
    "TotalTime": 1.2379257678985596
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/116",
    "Dis": 0.067,
    "Err": 0.038,
    "TotalTime": 0.9063959121704102
  },
  {
    "name": "select_words",
    "task_id": "HumanEval/117",
    "Dis": 0.062,
    "Err": 0.044,
    "TotalTime": 0.8439457416534424
  },
  {
    "name": "get_closest_vowel",
    "task_id": "HumanEval/118",
    "Dis": 0.441,
    "Err": 0.337,
    "TotalTime": 0.7568914890289307
  },
  {
    "name": "match_parens",
    "task_id": "HumanEval/119",
    "Dis": 0.469,
    "Err": 0.434,
    "TotalTime": 1.012817621231079
  },
  {
    "name": "maximum",
    "task_id": "HumanEval/120",
    "Dis": 0.117,
    "Err": 0.593,
    "TotalTime": 0.9336037635803223
  },
  {
    "name": "solution",
    "task_id": "HumanEval/121",
    "Dis": 0.0,
    "Err": 0.038,
    "TotalTime": 0.8451170921325684
  },
  {
    "name": "add_elements",
    "task_id": "HumanEval/122",
    "Dis": 0.452,
    "Err": 0.354,
    "TotalTime": 0.9231579303741455
  },
  {
    "name": "get_odd_collatz",
    "task_id": "HumanEval/123",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "valid_date",
    "task_id": "HumanEval/124",
    "Dis": 0.063,
    "Err": 0.056,
    "TotalTime": 0.7592439651489258
  },
  {
    "name": "split_words",
    "task_id": "HumanEval/125",
    "Dis": 0.63,
    "Err": 0.5,
    "TotalTime": 0.7057721614837646
  },
  {
    "name": "is_sorted",
    "task_id": "HumanEval/126",
    "Dis": 0.095,
    "Err": 0.082,
    "TotalTime": 0.8675358295440674
  },
  {
    "name": "intersection",
    "task_id": "HumanEval/127",
    "Dis": 0.264,
    "Err": 0.644,
    "TotalTime": 1.7090661525726318
  },
  {
    "name": "prod_signs",
    "task_id": "HumanEval/128",
    "Dis": 0.21,
    "Err": 0.319,
    "TotalTime": 0.925347089767456
  },
  {
    "name": "minPath",
    "task_id": "HumanEval/129",
    "Dis": 0.88,
    "Err": 0.896,
    "TotalTime": 2.78692889213562
  },
  {
    "name": "tri",
    "task_id": "HumanEval/130",
    "Dis": 0.853,
    "Err": 0.981,
    "TotalTime": 1.4010164737701416
  },
  {
    "name": "digits",
    "task_id": "HumanEval/131",
    "Dis": 0.22,
    "Err": 0.172,
    "TotalTime": 0.6571476459503174
  },
  {
    "name": "is_nested",
    "task_id": "HumanEval/132",
    "Dis": 0.208,
    "Err": 0.25,
    "TotalTime": 0.7187421321868896
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/133",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9106764793395996
  },
  {
    "name": "check_if_last_char_is_a_letter",
    "task_id": "HumanEval/134",
    "Dis": 0.29,
    "Err": 0.343,
    "TotalTime": 0.7366328239440918
  },
  {
    "name": "can_arrange",
    "task_id": "HumanEval/135",
    "Dis": 0.508,
    "Err": 0.587,
    "TotalTime": 0.8712940216064453
  },
  {
    "name": "largest_smallest_integers",
    "task_id": "HumanEval/136",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.902198314666748
  },
  {
    "name": "compare_one",
    "task_id": "HumanEval/137",
    "Dis": 0.45,
    "Err": 0.303,
    "TotalTime": 0.8498806953430176
  },
  {
    "name": "is_equal_to_sum_even",
    "task_id": "HumanEval/138",
    "Dis": 0.148,
    "Err": 0.11,
    "TotalTime": 2.494446039199829
  },
  {
    "name": "special_factorial",
    "task_id": "HumanEval/139",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "fix_spaces",
    "task_id": "HumanEval/140",
    "Dis": 0.454,
    "Err": 0.386,
    "TotalTime": 0.7331738471984863
  },
  {
    "name": "file_name_check",
    "task_id": "HumanEval/141",
    "Dis": 0.013,
    "Err": 0.007,
    "TotalTime": 0.7346808910369873
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/142",
    "Dis": 0.641,
    "Err": 0.49,
    "TotalTime": 0.8787033557891846
  },
  {
    "name": "words_in_sentence",
    "task_id": "HumanEval/143",
    "Dis": 0.099,
    "Err": 0.049,
    "TotalTime": 0.8922460079193115
  },
  {
    "name": "simplify",
    "task_id": "HumanEval/144",
    "Dis": 0.0,
    "Err": 0.002,
    "TotalTime": 12.664399147033691
  },
  {
    "name": "order_by_points",
    "task_id": "HumanEval/145",
    "Dis": 0.74,
    "Err": 0.91,
    "TotalTime": 0.8658308982849121
  },
  {
    "name": "specialFilter",
    "task_id": "HumanEval/146",
    "Dis": 0.153,
    "Err": 0.064,
    "TotalTime": 0.88057541847229
  },
  {
    "name": "bf",
    "task_id": "HumanEval/148",
    "Dis": 0.201,
    "Err": 0.083,
    "TotalTime": 0.879002571105957
  },
  {
    "name": "sorted_list_sum",
    "task_id": "HumanEval/149",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.0156285762786865
  },
  {
    "name": "x_or_y",
    "task_id": "HumanEval/150",
    "Dis": 0.0,
    "Err": 0.219,
    "TotalTime": 0.9289040565490723
  },
  {
    "name": "double_the_difference",
    "task_id": "HumanEval/151",
    "Dis": 0.285,
    "Err": 0.21,
    "TotalTime": 1.1311466693878174
  },
  {
    "name": "compare",
    "task_id": "HumanEval/152",
    "Dis": 0.474,
    "Err": 0.46,
    "TotalTime": 1.2381925582885742
  },
  {
    "name": "Strongest_Extension",
    "task_id": "HumanEval/153",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2861204147338867
  },
  {
    "name": "cycpattern_check",
    "task_id": "HumanEval/154",
    "Dis": 0.023,
    "Err": 0.037,
    "TotalTime": 0.8799688816070557
  },
  {
    "name": "even_odd_count",
    "task_id": "HumanEval/155",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6359083652496338
  },
  {
    "name": "right_angle_triangle",
    "task_id": "HumanEval/157",
    "Dis": 0.132,
    "Err": 0.06,
    "TotalTime": 0.7168362140655518
  },
  {
    "name": "find_max",
    "task_id": "HumanEval/158",
    "Dis": 0.066,
    "Err": 0.066,
    "TotalTime": 0.9232223033905029
  },
  {
    "name": "eat",
    "task_id": "HumanEval/159",
    "Dis": 0.712,
    "Err": 0.734,
    "TotalTime": 0.7188141345977783
  },
  {
    "name": "solve",
    "task_id": "HumanEval/161",
    "Dis": 0.327,
    "Err": 0.225,
    "TotalTime": 0.7340822219848633
  },
  {
    "name": "string_to_md5",
    "task_id": "HumanEval/162",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.7941195964813232
  },
  {
    "name": "generate_integers",
    "task_id": "HumanEval/163",
    "Dis": 0.195,
    "Err": 0.845,
    "TotalTime": 0.6909074783325195
  }
]