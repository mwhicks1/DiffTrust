[
  {
    "name": "has_close_elements",
    "task_id": "HumanEval/0",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 44.31748986244202
  },
  {
    "name": "separate_paren_groups",
    "task_id": "HumanEval/1",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 46.690276861190796
  },
  {
    "name": "truncate_number",
    "task_id": "HumanEval/2",
    "Dis": 0.0,
    "Err": 0.221,
    "TotalTime": 43.76252865791321
  },
  {
    "name": "below_zero",
    "task_id": "HumanEval/3",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 44.20085430145264
  },
  {
    "name": "mean_absolute_deviation",
    "task_id": "HumanEval/4",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 47.345404624938965
  },
  {
    "name": "intersperse",
    "task_id": "HumanEval/5",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 44.010446310043335
  },
  {
    "name": "parse_nested_parens",
    "task_id": "HumanEval/6",
    "Dis": 0.0,
    "Err": 0.379,
    "TotalTime": 45.012505531311035
  },
  {
    "name": "filter_by_substring",
    "task_id": "HumanEval/7",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 43.097201108932495
  },
  {
    "name": "sum_product",
    "task_id": "HumanEval/8",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 44.76160502433777
  },
  {
    "name": "rolling_max",
    "task_id": "HumanEval/9",
    "Dis": 0.0,
    "Err": 0.042,
    "TotalTime": 44.094616651535034
  },
  {
    "name": "make_palindrome",
    "task_id": "HumanEval/10",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 53.10912537574768
  },
  {
    "name": "string_xor",
    "task_id": "HumanEval/11",
    "Dis": 0.0,
    "Err": 0.904,
    "TotalTime": 45.23584008216858
  },
  {
    "name": "longest",
    "task_id": "HumanEval/12",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 44.222736120224
  },
  {
    "name": "greatest_common_divisor",
    "task_id": "HumanEval/13",
    "Dis": 0.0,
    "Err": 0.191,
    "TotalTime": 44.648295164108276
  },
  {
    "name": "all_prefixes",
    "task_id": "HumanEval/14",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 43.6454439163208
  },
  {
    "name": "string_sequence",
    "task_id": "HumanEval/15",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 46.245991230010986
  },
  {
    "name": "count_distinct_characters",
    "task_id": "HumanEval/16",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 43.64975118637085
  },
  {
    "name": "parse_music",
    "task_id": "HumanEval/17",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 45.885289430618286
  },
  {
    "name": "how_many_times",
    "task_id": "HumanEval/18",
    "Dis": 0.0,
    "Err": 0.073,
    "TotalTime": 45.18104648590088
  },
  {
    "name": "sort_numbers",
    "task_id": "HumanEval/19",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 47.93366312980652
  },
  {
    "name": "find_closest_elements",
    "task_id": "HumanEval/20",
    "Dis": 0.0,
    "Err": 0.004,
    "TotalTime": 47.04591917991638
  },
  {
    "name": "rescale_to_unit",
    "task_id": "HumanEval/21",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 45.96157884597778
  },
  {
    "name": "filter_integers",
    "task_id": "HumanEval/22",
    "Dis": 0.0,
    "Err": 0.077,
    "TotalTime": 43.65488791465759
  },
  {
    "name": "strlen",
    "task_id": "HumanEval/23",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 42.58714246749878
  },
  {
    "name": "largest_divisor",
    "task_id": "HumanEval/24",
    "Dis": 0.043,
    "Err": 0.239,
    "TotalTime": 44.073477029800415
  },
  {
    "name": "factorize",
    "task_id": "HumanEval/25",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 45.386306047439575
  },
  {
    "name": "remove_duplicates",
    "task_id": "HumanEval/26",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 43.92842245101929
  },
  {
    "name": "flip_case",
    "task_id": "HumanEval/27",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 43.26540994644165
  },
  {
    "name": "concatenate",
    "task_id": "HumanEval/28",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 43.145100116729736
  },
  {
    "name": "filter_by_prefix",
    "task_id": "HumanEval/29",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 43.998194217681885
  },
  {
    "name": "get_positive",
    "task_id": "HumanEval/30",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 44.046156883239746
  },
  {
    "name": "is_prime",
    "task_id": "HumanEval/31",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 45.99864411354065
  },
  {
    "name": "unique",
    "task_id": "HumanEval/34",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 42.92553663253784
  },
  {
    "name": "max_element",
    "task_id": "HumanEval/35",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 43.88938808441162
  },
  {
    "name": "sort_even",
    "task_id": "HumanEval/37",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 49.29892301559448
  },
  {
    "name": "triples_sum_to_zero",
    "task_id": "HumanEval/40",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 54.330199241638184
  },
  {
    "name": "car_race_collision",
    "task_id": "HumanEval/41",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 48.59649682044983
  },
  {
    "name": "incr_list",
    "task_id": "HumanEval/42",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 43.54674816131592
  },
  {
    "name": "pairs_sum_to_zero",
    "task_id": "HumanEval/43",
    "Dis": 0.002,
    "Err": 0.007,
    "TotalTime": 49.11824321746826
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/45",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 43.04922556877136
  },
  {
    "name": "fib4",
    "task_id": "HumanEval/46",
    "Dis": 0.0,
    "Err": 0.03,
    "TotalTime": 50.95396304130554
  },
  {
    "name": "median",
    "task_id": "HumanEval/47",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 47.93062448501587
  },
  {
    "name": "is_palindrome",
    "task_id": "HumanEval/48",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 43.61130166053772
  },
  {
    "name": "modp",
    "task_id": "HumanEval/49",
    "Dis": 0.0,
    "Err": 0.2,
    "TotalTime": 49.206252574920654
  },
  {
    "name": "remove_vowels",
    "task_id": "HumanEval/51",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 46.02710676193237
  },
  {
    "name": "below_threshold",
    "task_id": "HumanEval/52",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 44.510111570358276
  },
  {
    "name": "add",
    "task_id": "HumanEval/53",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 43.738158226013184
  },
  {
    "name": "same_chars",
    "task_id": "HumanEval/54",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 48.439462661743164
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/56",
    "Dis": 0.0,
    "Err": 0.422,
    "TotalTime": 47.82685732841492
  },
  {
    "name": "monotonic",
    "task_id": "HumanEval/57",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 45.248905658721924
  },
  {
    "name": "common",
    "task_id": "HumanEval/58",
    "Dis": 0.0,
    "Err": 0.389,
    "TotalTime": 45.655733585357666
  },
  {
    "name": "sum_to_n",
    "task_id": "HumanEval/60",
    "Dis": 0.0,
    "Err": 0.206,
    "TotalTime": 43.5465133190155
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/61",
    "Dis": 0.0,
    "Err": 0.416,
    "TotalTime": 45.28434681892395
  },
  {
    "name": "derivative",
    "task_id": "HumanEval/62",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 47.126638889312744
  },
  {
    "name": "vowels_count",
    "task_id": "HumanEval/64",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 45.48058199882507
  },
  {
    "name": "circular_shift",
    "task_id": "HumanEval/65",
    "Dis": 0.0,
    "Err": 0.138,
    "TotalTime": 46.69510316848755
  },
  {
    "name": "digitSum",
    "task_id": "HumanEval/66",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 46.84335255622864
  },
  {
    "name": "fruit_distribution",
    "task_id": "HumanEval/67",
    "Dis": 0.0,
    "Err": 0.719,
    "TotalTime": 46.92093253135681
  },
  {
    "name": "pluck",
    "task_id": "HumanEval/68",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 48.776718616485596
  },
  {
    "name": "search",
    "task_id": "HumanEval/69",
    "Dis": 0.0,
    "Err": 0.221,
    "TotalTime": 51.17755389213562
  },
  {
    "name": "strange_sort_list",
    "task_id": "HumanEval/70",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 47.035632371902466
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/71",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 45.442791223526
  },
  {
    "name": "will_it_fly",
    "task_id": "HumanEval/72",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 46.790180683135986
  },
  {
    "name": "smallest_change",
    "task_id": "HumanEval/73",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 48.5276095867157
  },
  {
    "name": "total_match",
    "task_id": "HumanEval/74",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 47.37815570831299
  },
  {
    "name": "iscube",
    "task_id": "HumanEval/77",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 47.7603542804718
  },
  {
    "name": "hex_key",
    "task_id": "HumanEval/78",
    "Dis": 0.0,
    "Err": 0.04,
    "TotalTime": 50.185590744018555
  },
  {
    "name": "decimal_to_binary",
    "task_id": "HumanEval/79",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 46.70439600944519
  },
  {
    "name": "is_happy",
    "task_id": "HumanEval/80",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 51.10153031349182
  },
  {
    "name": "numerical_letter_grade",
    "task_id": "HumanEval/81",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 49.90480375289917
  },
  {
    "name": "prime_length",
    "task_id": "HumanEval/82",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 44.65792918205261
  },
  {
    "name": "starts_one_ends",
    "task_id": "HumanEval/83",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 51.00551390647888
  },
  {
    "name": "solve",
    "task_id": "HumanEval/84",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 46.30678105354309
  },
  {
    "name": "add",
    "task_id": "HumanEval/85",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 46.55258059501648
  },
  {
    "name": "anti_shuffle",
    "task_id": "HumanEval/86",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 46.30686640739441
  },
  {
    "name": "get_row",
    "task_id": "HumanEval/87",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 51.68440365791321
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/88",
    "Dis": 0.0,
    "Err": 0.018,
    "TotalTime": 48.60870814323425
  },
  {
    "name": "encrypt",
    "task_id": "HumanEval/89",
    "Dis": 0.0,
    "Err": 0.385,
    "TotalTime": 49.587804555892944
  },
  {
    "name": "next_smallest",
    "task_id": "HumanEval/90",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 47.1550087928772
  },
  {
    "name": "is_bored",
    "task_id": "HumanEval/91",
    "Dis": 0.001,
    "Err": 0.008,
    "TotalTime": 47.78234648704529
  },
  {
    "name": "any_int",
    "task_id": "HumanEval/92",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 47.483875036239624
  },
  {
    "name": "encode",
    "task_id": "HumanEval/93",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 49.26487851142883
  },
  {
    "name": "skjkasdkd",
    "task_id": "HumanEval/94",
    "Dis": 0.0,
    "Err": 0.014,
    "TotalTime": 53.33088994026184
  },
  {
    "name": "check_dict_case",
    "task_id": "HumanEval/95",
    "Dis": 0.0,
    "Err": 0.006,
    "TotalTime": 45.327943325042725
  },
  {
    "name": "count_up_to",
    "task_id": "HumanEval/96",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 47.14811635017395
  },
  {
    "name": "multiply",
    "task_id": "HumanEval/97",
    "Dis": 0.0,
    "Err": 0.231,
    "TotalTime": 51.247745513916016
  },
  {
    "name": "count_upper",
    "task_id": "HumanEval/98",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 47.206204891204834
  },
  {
    "name": "closest_integer",
    "task_id": "HumanEval/99",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 48.92627191543579
  },
  {
    "name": "make_a_pile",
    "task_id": "HumanEval/100",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 49.62244153022766
  },
  {
    "name": "words_string",
    "task_id": "HumanEval/101",
    "Dis": 0.101,
    "Err": 0.056,
    "TotalTime": 44.917749643325806
  },
  {
    "name": "choose_num",
    "task_id": "HumanEval/102",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 45.28406357765198
  },
  {
    "name": "rounded_avg",
    "task_id": "HumanEval/103",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 55.35914397239685
  },
  {
    "name": "unique_digits",
    "task_id": "HumanEval/104",
    "Dis": 0.0,
    "Err": 0.094,
    "TotalTime": 47.870920181274414
  },
  {
    "name": "by_length",
    "task_id": "HumanEval/105",
    "Dis": 0.014,
    "Err": 0.009,
    "TotalTime": 50.13457751274109
  },
  {
    "name": "f",
    "task_id": "HumanEval/106",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 49.79040336608887
  },
  {
    "name": "even_odd_palindrome",
    "task_id": "HumanEval/107",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 46.7737991809845
  },
  {
    "name": "count_nums",
    "task_id": "HumanEval/108",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 47.07778882980347
  },
  {
    "name": "move_one_ball",
    "task_id": "HumanEval/109",
    "Dis": 0.053,
    "Err": 0.032,
    "TotalTime": 94.76543402671814
  },
  {
    "name": "exchange",
    "task_id": "HumanEval/110",
    "Dis": 0.0,
    "Err": 0.019,
    "TotalTime": 51.478139877319336
  },
  {
    "name": "histogram",
    "task_id": "HumanEval/111",
    "Dis": 0.0,
    "Err": 0.315,
    "TotalTime": 46.57242774963379
  },
  {
    "name": "reverse_delete",
    "task_id": "HumanEval/112",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 46.236501693725586
  },
  {
    "name": "odd_count",
    "task_id": "HumanEval/113",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 50.46734023094177
  },
  {
    "name": "minSubArraySum",
    "task_id": "HumanEval/114",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 48.33445429801941
  },
  {
    "name": "max_fill",
    "task_id": "HumanEval/115",
    "Dis": 0.0,
    "Err": 0.289,
    "TotalTime": 50.96890640258789
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/116",
    "Dis": 0.163,
    "Err": 0.095,
    "TotalTime": 53.713138580322266
  },
  {
    "name": "select_words",
    "task_id": "HumanEval/117",
    "Dis": 0.0,
    "Err": 0.052,
    "TotalTime": 48.23113751411438
  },
  {
    "name": "get_closest_vowel",
    "task_id": "HumanEval/118",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 52.80619955062866
  },
  {
    "name": "match_parens",
    "task_id": "HumanEval/119",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 53.169726848602295
  },
  {
    "name": "maximum",
    "task_id": "HumanEval/120",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 50.70348286628723
  },
  {
    "name": "solution",
    "task_id": "HumanEval/121",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 48.24737524986267
  },
  {
    "name": "add_elements",
    "task_id": "HumanEval/122",
    "Dis": 0.0,
    "Err": 0.489,
    "TotalTime": 45.30806112289429
  },
  {
    "name": "valid_date",
    "task_id": "HumanEval/124",
    "Dis": 0.0,
    "Err": 0.035,
    "TotalTime": 52.45150017738342
  },
  {
    "name": "split_words",
    "task_id": "HumanEval/125",
    "Dis": 0.022,
    "Err": 0.052,
    "TotalTime": 49.30368161201477
  },
  {
    "name": "is_sorted",
    "task_id": "HumanEval/126",
    "Dis": 0.0,
    "Err": 0.008,
    "TotalTime": 52.181432247161865
  },
  {
    "name": "intersection",
    "task_id": "HumanEval/127",
    "Dis": 0.0,
    "Err": 0.711,
    "TotalTime": 54.33285474777222
  },
  {
    "name": "prod_signs",
    "task_id": "HumanEval/128",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 49.364699602127075
  },
  {
    "name": "tri",
    "task_id": "HumanEval/130",
    "Dis": 0.171,
    "Err": 0.325,
    "TotalTime": 54.37862205505371
  },
  {
    "name": "digits",
    "task_id": "HumanEval/131",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 43.84242296218872
  },
  {
    "name": "is_nested",
    "task_id": "HumanEval/132",
    "Dis": 0.031,
    "Err": 0.107,
    "TotalTime": 90.53546977043152
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/133",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 49.5359582901001
  },
  {
    "name": "check_if_last_char_is_a_letter",
    "task_id": "HumanEval/134",
    "Dis": 0.005,
    "Err": 0.009,
    "TotalTime": 48.25417113304138
  },
  {
    "name": "can_arrange",
    "task_id": "HumanEval/135",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 48.552478313446045
  },
  {
    "name": "largest_smallest_integers",
    "task_id": "HumanEval/136",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 46.28426694869995
  },
  {
    "name": "compare_one",
    "task_id": "HumanEval/137",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 46.88322615623474
  },
  {
    "name": "is_equal_to_sum_even",
    "task_id": "HumanEval/138",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 51.17274618148804
  },
  {
    "name": "fix_spaces",
    "task_id": "HumanEval/140",
    "Dis": 0.0,
    "Err": 0.008,
    "TotalTime": 51.45866084098816
  },
  {
    "name": "file_name_check",
    "task_id": "HumanEval/141",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 47.91107726097107
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/142",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 49.630581855773926
  },
  {
    "name": "words_in_sentence",
    "task_id": "HumanEval/143",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 46.37613868713379
  },
  {
    "name": "simplify",
    "task_id": "HumanEval/144",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 59.51479482650757
  },
  {
    "name": "order_by_points",
    "task_id": "HumanEval/145",
    "Dis": 0.128,
    "Err": 0.069,
    "TotalTime": 90.05363321304321
  },
  {
    "name": "specialFilter",
    "task_id": "HumanEval/146",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 46.97799491882324
  },
  {
    "name": "bf",
    "task_id": "HumanEval/148",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 49.00117611885071
  },
  {
    "name": "sorted_list_sum",
    "task_id": "HumanEval/149",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 49.909663677215576
  },
  {
    "name": "x_or_y",
    "task_id": "HumanEval/150",
    "Dis": 0.0,
    "Err": 0.228,
    "TotalTime": 44.98036575317383
  },
  {
    "name": "compare",
    "task_id": "HumanEval/152",
    "Dis": 0.0,
    "Err": 0.29,
    "TotalTime": 56.1935920715332
  },
  {
    "name": "Strongest_Extension",
    "task_id": "HumanEval/153",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 53.52483820915222
  },
  {
    "name": "cycpattern_check",
    "task_id": "HumanEval/154",
    "Dis": 0.019,
    "Err": 0.041,
    "TotalTime": 49.631980419158936
  },
  {
    "name": "even_odd_count",
    "task_id": "HumanEval/155",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 48.08813285827637
  },
  {
    "name": "right_angle_triangle",
    "task_id": "HumanEval/157",
    "Dis": 0.0,
    "Err": 0.002,
    "TotalTime": 46.13842701911926
  },
  {
    "name": "eat",
    "task_id": "HumanEval/159",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 52.675660371780396
  },
  {
    "name": "solve",
    "task_id": "HumanEval/161",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 46.74767279624939
  },
  {
    "name": "string_to_md5",
    "task_id": "HumanEval/162",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 45.23074674606323
  },
  {
    "name": "generate_integers",
    "task_id": "HumanEval/163",
    "Dis": 0.175,
    "Err": 0.27,
    "TotalTime": 50.22856593132019
  },
  {
    "name": "has_close_elements",
    "task_id": "HumanEval/0",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.7148566246032715
  },
  {
    "name": "separate_paren_groups",
    "task_id": "HumanEval/1",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5437910556793213
  },
  {
    "name": "truncate_number",
    "task_id": "HumanEval/2",
    "Dis": 0.0,
    "Err": 0.209,
    "TotalTime": 0.4605293273925781
  },
  {
    "name": "below_zero",
    "task_id": "HumanEval/3",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6175756454467773
  },
  {
    "name": "mean_absolute_deviation",
    "task_id": "HumanEval/4",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6629030704498291
  },
  {
    "name": "intersperse",
    "task_id": "HumanEval/5",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6027286052703857
  },
  {
    "name": "parse_nested_parens",
    "task_id": "HumanEval/6",
    "Dis": 0.0,
    "Err": 0.394,
    "TotalTime": 0.5489802360534668
  },
  {
    "name": "filter_by_substring",
    "task_id": "HumanEval/7",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.8436417579650879
  },
  {
    "name": "sum_product",
    "task_id": "HumanEval/8",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6552584171295166
  },
  {
    "name": "rolling_max",
    "task_id": "HumanEval/9",
    "Dis": 0.0,
    "Err": 0.048,
    "TotalTime": 0.6237838268280029
  },
  {
    "name": "make_palindrome",
    "task_id": "HumanEval/10",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.550987958908081
  },
  {
    "name": "string_xor",
    "task_id": "HumanEval/11",
    "Dis": 0.0,
    "Err": 0.929,
    "TotalTime": 0.6340878009796143
  },
  {
    "name": "longest",
    "task_id": "HumanEval/12",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6957569122314453
  },
  {
    "name": "greatest_common_divisor",
    "task_id": "HumanEval/13",
    "Dis": 0.0,
    "Err": 0.182,
    "TotalTime": 0.4834914207458496
  },
  {
    "name": "all_prefixes",
    "task_id": "HumanEval/14",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.543013334274292
  },
  {
    "name": "string_sequence",
    "task_id": "HumanEval/15",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.46860241889953613
  },
  {
    "name": "count_distinct_characters",
    "task_id": "HumanEval/16",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5346946716308594
  },
  {
    "name": "parse_music",
    "task_id": "HumanEval/17",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9677062034606934
  },
  {
    "name": "how_many_times",
    "task_id": "HumanEval/18",
    "Dis": 0.0,
    "Err": 0.072,
    "TotalTime": 0.6342151165008545
  },
  {
    "name": "sort_numbers",
    "task_id": "HumanEval/19",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3210647106170654
  },
  {
    "name": "find_closest_elements",
    "task_id": "HumanEval/20",
    "Dis": 0.0,
    "Err": 0.004,
    "TotalTime": 0.6770484447479248
  },
  {
    "name": "rescale_to_unit",
    "task_id": "HumanEval/21",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6899077892303467
  },
  {
    "name": "filter_integers",
    "task_id": "HumanEval/22",
    "Dis": 0.0,
    "Err": 0.066,
    "TotalTime": 0.6301360130310059
  },
  {
    "name": "strlen",
    "task_id": "HumanEval/23",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5178506374359131
  },
  {
    "name": "largest_divisor",
    "task_id": "HumanEval/24",
    "Dis": 0.04,
    "Err": 0.214,
    "TotalTime": 0.46224069595336914
  },
  {
    "name": "factorize",
    "task_id": "HumanEval/25",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.49564075469970703
  },
  {
    "name": "remove_duplicates",
    "task_id": "HumanEval/26",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6374776363372803
  },
  {
    "name": "flip_case",
    "task_id": "HumanEval/27",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5278589725494385
  },
  {
    "name": "concatenate",
    "task_id": "HumanEval/28",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.7412848472595215
  },
  {
    "name": "filter_by_prefix",
    "task_id": "HumanEval/29",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9802777767181396
  },
  {
    "name": "get_positive",
    "task_id": "HumanEval/30",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6410558223724365
  },
  {
    "name": "is_prime",
    "task_id": "HumanEval/31",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.631272554397583
  },
  {
    "name": "unique",
    "task_id": "HumanEval/34",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6611056327819824
  },
  {
    "name": "max_element",
    "task_id": "HumanEval/35",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6663908958435059
  },
  {
    "name": "sort_even",
    "task_id": "HumanEval/37",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.666797399520874
  },
  {
    "name": "triples_sum_to_zero",
    "task_id": "HumanEval/40",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.630061149597168
  },
  {
    "name": "car_race_collision",
    "task_id": "HumanEval/41",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.4565885066986084
  },
  {
    "name": "incr_list",
    "task_id": "HumanEval/42",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6696960926055908
  },
  {
    "name": "pairs_sum_to_zero",
    "task_id": "HumanEval/43",
    "Dis": 0.006,
    "Err": 0.015,
    "TotalTime": 0.6276638507843018
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/45",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.4893028736114502
  },
  {
    "name": "fib4",
    "task_id": "HumanEval/46",
    "Dis": 0.0,
    "Err": 0.033,
    "TotalTime": 0.48857831954956055
  },
  {
    "name": "median",
    "task_id": "HumanEval/47",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6355571746826172
  },
  {
    "name": "is_palindrome",
    "task_id": "HumanEval/48",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5122208595275879
  },
  {
    "name": "modp",
    "task_id": "HumanEval/49",
    "Dis": 0.0,
    "Err": 0.187,
    "TotalTime": 0.49346208572387695
  },
  {
    "name": "remove_vowels",
    "task_id": "HumanEval/51",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5269722938537598
  },
  {
    "name": "below_threshold",
    "task_id": "HumanEval/52",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.616051435470581
  },
  {
    "name": "add",
    "task_id": "HumanEval/53",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.45764899253845215
  },
  {
    "name": "same_chars",
    "task_id": "HumanEval/54",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6121289730072021
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/56",
    "Dis": 0.0,
    "Err": 0.401,
    "TotalTime": 0.5132365226745605
  },
  {
    "name": "monotonic",
    "task_id": "HumanEval/57",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.611931562423706
  },
  {
    "name": "common",
    "task_id": "HumanEval/58",
    "Dis": 0.0,
    "Err": 0.363,
    "TotalTime": 0.7075450420379639
  },
  {
    "name": "sum_to_n",
    "task_id": "HumanEval/60",
    "Dis": 0.0,
    "Err": 0.205,
    "TotalTime": 0.45354700088500977
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/61",
    "Dis": 0.0,
    "Err": 0.406,
    "TotalTime": 0.5701909065246582
  },
  {
    "name": "derivative",
    "task_id": "HumanEval/62",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6006121635437012
  },
  {
    "name": "vowels_count",
    "task_id": "HumanEval/64",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5334100723266602
  },
  {
    "name": "circular_shift",
    "task_id": "HumanEval/65",
    "Dis": 0.0,
    "Err": 0.137,
    "TotalTime": 0.47595930099487305
  },
  {
    "name": "digitSum",
    "task_id": "HumanEval/66",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5194470882415771
  },
  {
    "name": "fruit_distribution",
    "task_id": "HumanEval/67",
    "Dis": 0.0,
    "Err": 0.716,
    "TotalTime": 0.5709319114685059
  },
  {
    "name": "pluck",
    "task_id": "HumanEval/68",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.615217924118042
  },
  {
    "name": "search",
    "task_id": "HumanEval/69",
    "Dis": 0.0,
    "Err": 0.189,
    "TotalTime": 0.7621986865997314
  },
  {
    "name": "strange_sort_list",
    "task_id": "HumanEval/70",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6411044597625732
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/71",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5002174377441406
  },
  {
    "name": "will_it_fly",
    "task_id": "HumanEval/72",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6802382469177246
  },
  {
    "name": "smallest_change",
    "task_id": "HumanEval/73",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5491232872009277
  },
  {
    "name": "total_match",
    "task_id": "HumanEval/74",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.176008701324463
  },
  {
    "name": "iscube",
    "task_id": "HumanEval/77",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.43743062019348145
  },
  {
    "name": "hex_key",
    "task_id": "HumanEval/78",
    "Dis": 0.0,
    "Err": 0.033,
    "TotalTime": 0.5052087306976318
  },
  {
    "name": "decimal_to_binary",
    "task_id": "HumanEval/79",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.42675256729125977
  },
  {
    "name": "is_happy",
    "task_id": "HumanEval/80",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5079255104064941
  },
  {
    "name": "numerical_letter_grade",
    "task_id": "HumanEval/81",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6437299251556396
  },
  {
    "name": "prime_length",
    "task_id": "HumanEval/82",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5095317363739014
  },
  {
    "name": "starts_one_ends",
    "task_id": "HumanEval/83",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.44277048110961914
  },
  {
    "name": "solve",
    "task_id": "HumanEval/84",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.44985294342041016
  },
  {
    "name": "add",
    "task_id": "HumanEval/85",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5732219219207764
  },
  {
    "name": "anti_shuffle",
    "task_id": "HumanEval/86",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5223653316497803
  },
  {
    "name": "get_row",
    "task_id": "HumanEval/87",
    "Dis": 0.0,
    "Err": 0.001,
    "TotalTime": 0.9521012306213379
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/88",
    "Dis": 0.0,
    "Err": 0.031,
    "TotalTime": 0.6362216472625732
  },
  {
    "name": "encrypt",
    "task_id": "HumanEval/89",
    "Dis": 0.0,
    "Err": 0.39,
    "TotalTime": 0.5240819454193115
  },
  {
    "name": "next_smallest",
    "task_id": "HumanEval/90",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6256248950958252
  },
  {
    "name": "is_bored",
    "task_id": "HumanEval/91",
    "Dis": 0.003,
    "Err": 0.008,
    "TotalTime": 0.5338931083679199
  },
  {
    "name": "any_int",
    "task_id": "HumanEval/92",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5077924728393555
  },
  {
    "name": "encode",
    "task_id": "HumanEval/93",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5372695922851562
  },
  {
    "name": "skjkasdkd",
    "task_id": "HumanEval/94",
    "Dis": 0.0,
    "Err": 0.008,
    "TotalTime": 0.8449172973632812
  },
  {
    "name": "check_dict_case",
    "task_id": "HumanEval/95",
    "Dis": 0.0,
    "Err": 0.011,
    "TotalTime": 0.6562445163726807
  },
  {
    "name": "count_up_to",
    "task_id": "HumanEval/96",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5088765621185303
  },
  {
    "name": "multiply",
    "task_id": "HumanEval/97",
    "Dis": 0.0,
    "Err": 0.2,
    "TotalTime": 0.4688737392425537
  },
  {
    "name": "count_upper",
    "task_id": "HumanEval/98",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5064127445220947
  },
  {
    "name": "closest_integer",
    "task_id": "HumanEval/99",
    "Dis": 0.0,
    "Err": 0.002,
    "TotalTime": 0.948552131652832
  },
  {
    "name": "make_a_pile",
    "task_id": "HumanEval/100",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.4405694007873535
  },
  {
    "name": "words_string",
    "task_id": "HumanEval/101",
    "Dis": 0.092,
    "Err": 0.054,
    "TotalTime": 0.526170015335083
  },
  {
    "name": "choose_num",
    "task_id": "HumanEval/102",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.46687865257263184
  },
  {
    "name": "rounded_avg",
    "task_id": "HumanEval/103",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.489901065826416
  },
  {
    "name": "unique_digits",
    "task_id": "HumanEval/104",
    "Dis": 0.0,
    "Err": 0.086,
    "TotalTime": 0.6714739799499512
  },
  {
    "name": "by_length",
    "task_id": "HumanEval/105",
    "Dis": 0.019,
    "Err": 0.006,
    "TotalTime": 0.6291379928588867
  },
  {
    "name": "f",
    "task_id": "HumanEval/106",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.4985368251800537
  },
  {
    "name": "even_odd_palindrome",
    "task_id": "HumanEval/107",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.4888427257537842
  },
  {
    "name": "count_nums",
    "task_id": "HumanEval/108",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6710104942321777
  },
  {
    "name": "move_one_ball",
    "task_id": "HumanEval/109",
    "Dis": 0.049,
    "Err": 0.03,
    "TotalTime": 0.6112439632415771
  },
  {
    "name": "exchange",
    "task_id": "HumanEval/110",
    "Dis": 0.0,
    "Err": 0.009,
    "TotalTime": 0.9415271282196045
  },
  {
    "name": "histogram",
    "task_id": "HumanEval/111",
    "Dis": 0.0,
    "Err": 0.333,
    "TotalTime": 0.5409927368164062
  },
  {
    "name": "reverse_delete",
    "task_id": "HumanEval/112",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6212608814239502
  },
  {
    "name": "odd_count",
    "task_id": "HumanEval/113",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.98636794090271
  },
  {
    "name": "minSubArraySum",
    "task_id": "HumanEval/114",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6323268413543701
  },
  {
    "name": "max_fill",
    "task_id": "HumanEval/115",
    "Dis": 0.0,
    "Err": 0.306,
    "TotalTime": 0.938037633895874
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/116",
    "Dis": 0.167,
    "Err": 0.096,
    "TotalTime": 0.6590771675109863
  },
  {
    "name": "select_words",
    "task_id": "HumanEval/117",
    "Dis": 0.0,
    "Err": 0.053,
    "TotalTime": 0.5596256256103516
  },
  {
    "name": "get_closest_vowel",
    "task_id": "HumanEval/118",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5174455642700195
  },
  {
    "name": "match_parens",
    "task_id": "HumanEval/119",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.7524876594543457
  },
  {
    "name": "maximum",
    "task_id": "HumanEval/120",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6625959873199463
  },
  {
    "name": "solution",
    "task_id": "HumanEval/121",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.583420991897583
  },
  {
    "name": "add_elements",
    "task_id": "HumanEval/122",
    "Dis": 0.0,
    "Err": 0.495,
    "TotalTime": 0.6488378047943115
  },
  {
    "name": "valid_date",
    "task_id": "HumanEval/124",
    "Dis": 0.0,
    "Err": 0.022,
    "TotalTime": 0.5299293994903564
  },
  {
    "name": "split_words",
    "task_id": "HumanEval/125",
    "Dis": 0.031,
    "Err": 0.05,
    "TotalTime": 0.5252423286437988
  },
  {
    "name": "is_sorted",
    "task_id": "HumanEval/126",
    "Dis": 0.0,
    "Err": 0.005,
    "TotalTime": 0.6193752288818359
  },
  {
    "name": "intersection",
    "task_id": "HumanEval/127",
    "Dis": 0.0,
    "Err": 0.717,
    "TotalTime": 1.3574399948120117
  },
  {
    "name": "prod_signs",
    "task_id": "HumanEval/128",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6285712718963623
  },
  {
    "name": "tri",
    "task_id": "HumanEval/130",
    "Dis": 0.175,
    "Err": 0.343,
    "TotalTime": 0.4848477840423584
  },
  {
    "name": "digits",
    "task_id": "HumanEval/131",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.44135570526123047
  },
  {
    "name": "is_nested",
    "task_id": "HumanEval/132",
    "Dis": 0.036,
    "Err": 0.097,
    "TotalTime": 0.532498836517334
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/133",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6315417289733887
  },
  {
    "name": "check_if_last_char_is_a_letter",
    "task_id": "HumanEval/134",
    "Dis": 0.007,
    "Err": 0.013,
    "TotalTime": 0.5120329856872559
  },
  {
    "name": "can_arrange",
    "task_id": "HumanEval/135",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6110830307006836
  },
  {
    "name": "largest_smallest_integers",
    "task_id": "HumanEval/136",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6540560722351074
  },
  {
    "name": "compare_one",
    "task_id": "HumanEval/137",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6361808776855469
  },
  {
    "name": "is_equal_to_sum_even",
    "task_id": "HumanEval/138",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.437000036239624
  },
  {
    "name": "fix_spaces",
    "task_id": "HumanEval/140",
    "Dis": 0.0,
    "Err": 0.003,
    "TotalTime": 0.5257296562194824
  },
  {
    "name": "file_name_check",
    "task_id": "HumanEval/141",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5210990905761719
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/142",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6760585308074951
  },
  {
    "name": "words_in_sentence",
    "task_id": "HumanEval/143",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5467276573181152
  },
  {
    "name": "simplify",
    "task_id": "HumanEval/144",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 11.72805142402649
  },
  {
    "name": "order_by_points",
    "task_id": "HumanEval/145",
    "Dis": 0.135,
    "Err": 0.072,
    "TotalTime": 0.7302401065826416
  },
  {
    "name": "specialFilter",
    "task_id": "HumanEval/146",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6234021186828613
  },
  {
    "name": "bf",
    "task_id": "HumanEval/148",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6108944416046143
  },
  {
    "name": "sorted_list_sum",
    "task_id": "HumanEval/149",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.7376108169555664
  },
  {
    "name": "x_or_y",
    "task_id": "HumanEval/150",
    "Dis": 0.0,
    "Err": 0.218,
    "TotalTime": 0.5179226398468018
  },
  {
    "name": "double_the_difference",
    "task_id": "HumanEval/151",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 50.37738800048828
  },
  {
    "name": "compare",
    "task_id": "HumanEval/152",
    "Dis": 0.0,
    "Err": 0.325,
    "TotalTime": 0.9744884967803955
  },
  {
    "name": "Strongest_Extension",
    "task_id": "HumanEval/153",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.9159860610961914
  },
  {
    "name": "cycpattern_check",
    "task_id": "HumanEval/154",
    "Dis": 0.025,
    "Err": 0.03,
    "TotalTime": 0.6328914165496826
  },
  {
    "name": "even_odd_count",
    "task_id": "HumanEval/155",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.4505431652069092
  },
  {
    "name": "right_angle_triangle",
    "task_id": "HumanEval/157",
    "Dis": 0.0,
    "Err": 0.001,
    "TotalTime": 0.5082917213439941
  },
  {
    "name": "find_max",
    "task_id": "HumanEval/158",
    "Dis": 0.001,
    "Err": 0.0,
    "TotalTime": 44.6599760055542
  },
  {
    "name": "eat",
    "task_id": "HumanEval/159",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.49584031105041504
  },
  {
    "name": "solve",
    "task_id": "HumanEval/161",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5307295322418213
  },
  {
    "name": "string_to_md5",
    "task_id": "HumanEval/162",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5784730911254883
  },
  {
    "name": "generate_integers",
    "task_id": "HumanEval/163",
    "Dis": 0.185,
    "Err": 0.279,
    "TotalTime": 0.48096394538879395
  },
  {
    "name": "has_close_elements",
    "task_id": "HumanEval/0",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 82.4813392162323
  },
  {
    "name": "separate_paren_groups",
    "task_id": "HumanEval/1",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 97.47344088554382
  },
  {
    "name": "has_close_elements",
    "task_id": "HumanEval/0",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5345773696899414
  },
  {
    "name": "separate_paren_groups",
    "task_id": "HumanEval/1",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.360886573791504
  },
  {
    "name": "truncate_number",
    "task_id": "HumanEval/2",
    "Dis": 0.0,
    "Err": 0.229,
    "TotalTime": 127.08763790130615
  },
  {
    "name": "below_zero",
    "task_id": "HumanEval/3",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 127.81401777267456
  },
  {
    "name": "mean_absolute_deviation",
    "task_id": "HumanEval/4",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 139.08501195907593
  },
  {
    "name": "intersperse",
    "task_id": "HumanEval/5",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 128.07341980934143
  },
  {
    "name": "parse_nested_parens",
    "task_id": "HumanEval/6",
    "Dis": 0.0,
    "Err": 0.392,
    "TotalTime": 158.28617668151855
  },
  {
    "name": "filter_by_substring",
    "task_id": "HumanEval/7",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 130.98933625221252
  },
  {
    "name": "sum_product",
    "task_id": "HumanEval/8",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 148.39182353019714
  },
  {
    "name": "rolling_max",
    "task_id": "HumanEval/9",
    "Dis": 0.003,
    "Err": 0.04,
    "TotalTime": 128.24202132225037
  },
  {
    "name": "make_palindrome",
    "task_id": "HumanEval/10",
    "Dis": 0.022,
    "Err": 0.013,
    "TotalTime": 251.37552976608276
  },
  {
    "name": "string_xor",
    "task_id": "HumanEval/11",
    "Dis": 0.066,
    "Err": 0.906,
    "TotalTime": 164.4114100933075
  },
  {
    "name": "longest",
    "task_id": "HumanEval/12",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 130.855406999588
  },
  {
    "name": "greatest_common_divisor",
    "task_id": "HumanEval/13",
    "Dis": 0.0,
    "Err": 0.195,
    "TotalTime": 117.59726548194885
  },
  {
    "name": "all_prefixes",
    "task_id": "HumanEval/14",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 101.30884742736816
  },
  {
    "name": "string_sequence",
    "task_id": "HumanEval/15",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 104.53059029579163
  },
  {
    "name": "count_distinct_characters",
    "task_id": "HumanEval/16",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 107.24527144432068
  },
  {
    "name": "parse_music",
    "task_id": "HumanEval/17",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 174.82138204574585
  },
  {
    "name": "how_many_times",
    "task_id": "HumanEval/18",
    "Dis": 0.0,
    "Err": 0.083,
    "TotalTime": 137.89821004867554
  },
  {
    "name": "sort_numbers",
    "task_id": "HumanEval/19",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 156.38822436332703
  },
  {
    "name": "find_closest_elements",
    "task_id": "HumanEval/20",
    "Dis": 0.0,
    "Err": 0.005,
    "TotalTime": 168.0772271156311
  },
  {
    "name": "rescale_to_unit",
    "task_id": "HumanEval/21",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 156.41836380958557
  },
  {
    "name": "strlen",
    "task_id": "HumanEval/23",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 122.59324836730957
  },
  {
    "name": "largest_divisor",
    "task_id": "HumanEval/24",
    "Dis": 0.029,
    "Err": 0.233,
    "TotalTime": 164.00723457336426
  },
  {
    "name": "factorize",
    "task_id": "HumanEval/25",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 184.12914872169495
  },
  {
    "name": "flip_case",
    "task_id": "HumanEval/27",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 131.17119908332825
  },
  {
    "name": "concatenate",
    "task_id": "HumanEval/28",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 120.4406406879425
  },
  {
    "name": "filter_by_prefix",
    "task_id": "HumanEval/29",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 132.7877070903778
  },
  {
    "name": "get_positive",
    "task_id": "HumanEval/30",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 137.57668018341064
  },
  {
    "name": "is_prime",
    "task_id": "HumanEval/31",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 159.09379601478577
  },
  {
    "name": "unique",
    "task_id": "HumanEval/34",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 129.63832306861877
  },
  {
    "name": "max_element",
    "task_id": "HumanEval/35",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 138.65988731384277
  },
  {
    "name": "sort_even",
    "task_id": "HumanEval/37",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 220.63864469528198
  },
  {
    "name": "triples_sum_to_zero",
    "task_id": "HumanEval/40",
    "Dis": 0.001,
    "Err": 0.0,
    "TotalTime": 290.9522762298584
  },
  {
    "name": "car_race_collision",
    "task_id": "HumanEval/41",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 214.03967428207397
  },
  {
    "name": "incr_list",
    "task_id": "HumanEval/42",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 115.76300120353699
  },
  {
    "name": "pairs_sum_to_zero",
    "task_id": "HumanEval/43",
    "Dis": 0.011,
    "Err": 0.009,
    "TotalTime": 233.08871722221375
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/45",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 86.87542462348938
  },
  {
    "name": "fib4",
    "task_id": "HumanEval/46",
    "Dis": 0.0,
    "Err": 0.024,
    "TotalTime": 182.49194526672363
  },
  {
    "name": "median",
    "task_id": "HumanEval/47",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 219.67604970932007
  },
  {
    "name": "is_palindrome",
    "task_id": "HumanEval/48",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 99.35893177986145
  },
  {
    "name": "modp",
    "task_id": "HumanEval/49",
    "Dis": 0.0,
    "Err": 0.196,
    "TotalTime": 201.52657413482666
  },
  {
    "name": "remove_vowels",
    "task_id": "HumanEval/51",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 165.82367515563965
  },
  {
    "name": "below_threshold",
    "task_id": "HumanEval/52",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 122.287513256073
  },
  {
    "name": "add",
    "task_id": "HumanEval/53",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 100.36235761642456
  },
  {
    "name": "same_chars",
    "task_id": "HumanEval/54",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 213.34320378303528
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/56",
    "Dis": 0.0,
    "Err": 0.419,
    "TotalTime": 141.1256628036499
  },
  {
    "name": "monotonic",
    "task_id": "HumanEval/57",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 144.12373900413513
  },
  {
    "name": "common",
    "task_id": "HumanEval/58",
    "Dis": 0.0,
    "Err": 0.37,
    "TotalTime": 135.7525520324707
  },
  {
    "name": "sum_to_n",
    "task_id": "HumanEval/60",
    "Dis": 0.0,
    "Err": 0.226,
    "TotalTime": 99.8072075843811
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/61",
    "Dis": 0.0,
    "Err": 0.393,
    "TotalTime": 134.32978892326355
  },
  {
    "name": "derivative",
    "task_id": "HumanEval/62",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 123.05240416526794
  },
  {
    "name": "vowels_count",
    "task_id": "HumanEval/64",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 165.09153842926025
  },
  {
    "name": "circular_shift",
    "task_id": "HumanEval/65",
    "Dis": 0.01,
    "Err": 0.131,
    "TotalTime": 159.37012124061584
  },
  {
    "name": "digitSum",
    "task_id": "HumanEval/66",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 154.76229906082153
  },
  {
    "name": "fruit_distribution",
    "task_id": "HumanEval/67",
    "Dis": 0.072,
    "Err": 0.706,
    "TotalTime": 183.0809416770935
  },
  {
    "name": "pluck",
    "task_id": "HumanEval/68",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 205.34677696228027
  },
  {
    "name": "has_close_elements",
    "task_id": "HumanEval/0",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6681146621704102
  },
  {
    "name": "separate_paren_groups",
    "task_id": "HumanEval/1",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5290830135345459
  },
  {
    "name": "truncate_number",
    "task_id": "HumanEval/2",
    "Dis": 0.0,
    "Err": 0.234,
    "TotalTime": 0.4510035514831543
  },
  {
    "name": "below_zero",
    "task_id": "HumanEval/3",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6052470207214355
  },
  {
    "name": "mean_absolute_deviation",
    "task_id": "HumanEval/4",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6333351135253906
  },
  {
    "name": "intersperse",
    "task_id": "HumanEval/5",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.584752082824707
  },
  {
    "name": "parse_nested_parens",
    "task_id": "HumanEval/6",
    "Dis": 0.0,
    "Err": 0.407,
    "TotalTime": 0.5341670513153076
  },
  {
    "name": "filter_by_substring",
    "task_id": "HumanEval/7",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.7998032569885254
  },
  {
    "name": "sum_product",
    "task_id": "HumanEval/8",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6117730140686035
  },
  {
    "name": "rolling_max",
    "task_id": "HumanEval/9",
    "Dis": 0.0,
    "Err": 0.049,
    "TotalTime": 0.61785888671875
  },
  {
    "name": "make_palindrome",
    "task_id": "HumanEval/10",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5342295169830322
  },
  {
    "name": "string_xor",
    "task_id": "HumanEval/11",
    "Dis": 0.0,
    "Err": 0.907,
    "TotalTime": 0.6152839660644531
  },
  {
    "name": "longest",
    "task_id": "HumanEval/12",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.6565852165222168
  },
  {
    "name": "greatest_common_divisor",
    "task_id": "HumanEval/13",
    "Dis": 0.0,
    "Err": 0.207,
    "TotalTime": 0.46042633056640625
  },
  {
    "name": "all_prefixes",
    "task_id": "HumanEval/14",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5218393802642822
  },
  {
    "name": "string_sequence",
    "task_id": "HumanEval/15",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.4420759677886963
  },
  {
    "name": "count_distinct_characters",
    "task_id": "HumanEval/16",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 0.5247557163238525
  },
  {
    "name": "has_close_elements",
    "task_id": "HumanEval/0",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.357168197631836
  },
  {
    "name": "separate_paren_groups",
    "task_id": "HumanEval/1",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2378528118133545
  },
  {
    "name": "truncate_number",
    "task_id": "HumanEval/2",
    "Dis": 0.0,
    "Err": 0.222,
    "TotalTime": 1.1387734413146973
  },
  {
    "name": "below_zero",
    "task_id": "HumanEval/3",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.308532953262329
  },
  {
    "name": "mean_absolute_deviation",
    "task_id": "HumanEval/4",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3400638103485107
  },
  {
    "name": "intersperse",
    "task_id": "HumanEval/5",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2815277576446533
  },
  {
    "name": "parse_nested_parens",
    "task_id": "HumanEval/6",
    "Dis": 0.0,
    "Err": 0.384,
    "TotalTime": 1.243473768234253
  },
  {
    "name": "filter_by_substring",
    "task_id": "HumanEval/7",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.512986421585083
  },
  {
    "name": "sum_product",
    "task_id": "HumanEval/8",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3244268894195557
  },
  {
    "name": "rolling_max",
    "task_id": "HumanEval/9",
    "Dis": 0.005,
    "Err": 0.058,
    "TotalTime": 1.3182575702667236
  },
  {
    "name": "make_palindrome",
    "task_id": "HumanEval/10",
    "Dis": 0.028,
    "Err": 0.011,
    "TotalTime": 1.2452561855316162
  },
  {
    "name": "string_xor",
    "task_id": "HumanEval/11",
    "Dis": 0.071,
    "Err": 0.926,
    "TotalTime": 1.3138439655303955
  },
  {
    "name": "longest",
    "task_id": "HumanEval/12",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.362921953201294
  },
  {
    "name": "greatest_common_divisor",
    "task_id": "HumanEval/13",
    "Dis": 0.0,
    "Err": 0.191,
    "TotalTime": 1.1533699035644531
  },
  {
    "name": "all_prefixes",
    "task_id": "HumanEval/14",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2089242935180664
  },
  {
    "name": "string_sequence",
    "task_id": "HumanEval/15",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1529619693756104
  },
  {
    "name": "count_distinct_characters",
    "task_id": "HumanEval/16",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2087526321411133
  },
  {
    "name": "parse_music",
    "task_id": "HumanEval/17",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.6272401809692383
  },
  {
    "name": "how_many_times",
    "task_id": "HumanEval/18",
    "Dis": 0.0,
    "Err": 0.073,
    "TotalTime": 1.2933948040008545
  },
  {
    "name": "sort_numbers",
    "task_id": "HumanEval/19",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.9627299308776855
  },
  {
    "name": "find_closest_elements",
    "task_id": "HumanEval/20",
    "Dis": 0.0,
    "Err": 0.008,
    "TotalTime": 1.3908593654632568
  },
  {
    "name": "rescale_to_unit",
    "task_id": "HumanEval/21",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4360039234161377
  },
  {
    "name": "filter_integers",
    "task_id": "HumanEval/22",
    "Dis": 0.0,
    "Err": 0.087,
    "TotalTime": 74.70304036140442
  },
  {
    "name": "strlen",
    "task_id": "HumanEval/23",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2578442096710205
  },
  {
    "name": "largest_divisor",
    "task_id": "HumanEval/24",
    "Dis": 0.039,
    "Err": 0.237,
    "TotalTime": 1.238537311553955
  },
  {
    "name": "factorize",
    "task_id": "HumanEval/25",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2509489059448242
  },
  {
    "name": "remove_duplicates",
    "task_id": "HumanEval/26",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 79.58947992324829
  },
  {
    "name": "flip_case",
    "task_id": "HumanEval/27",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2947864532470703
  },
  {
    "name": "concatenate",
    "task_id": "HumanEval/28",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4991881847381592
  },
  {
    "name": "filter_by_prefix",
    "task_id": "HumanEval/29",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.7263176441192627
  },
  {
    "name": "get_positive",
    "task_id": "HumanEval/30",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4774596691131592
  },
  {
    "name": "is_prime",
    "task_id": "HumanEval/31",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3148763179779053
  },
  {
    "name": "unique",
    "task_id": "HumanEval/34",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4178683757781982
  },
  {
    "name": "max_element",
    "task_id": "HumanEval/35",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4294748306274414
  },
  {
    "name": "sort_even",
    "task_id": "HumanEval/37",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4513227939605713
  },
  {
    "name": "triples_sum_to_zero",
    "task_id": "HumanEval/40",
    "Dis": 0.001,
    "Err": 0.001,
    "TotalTime": 1.41302490234375
  },
  {
    "name": "car_race_collision",
    "task_id": "HumanEval/41",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2083826065063477
  },
  {
    "name": "incr_list",
    "task_id": "HumanEval/42",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4137682914733887
  },
  {
    "name": "pairs_sum_to_zero",
    "task_id": "HumanEval/43",
    "Dis": 0.007,
    "Err": 0.008,
    "TotalTime": 1.3931024074554443
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/45",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2408361434936523
  },
  {
    "name": "fib4",
    "task_id": "HumanEval/46",
    "Dis": 0.0,
    "Err": 0.032,
    "TotalTime": 1.2638070583343506
  },
  {
    "name": "median",
    "task_id": "HumanEval/47",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4217407703399658
  },
  {
    "name": "is_palindrome",
    "task_id": "HumanEval/48",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2823641300201416
  },
  {
    "name": "modp",
    "task_id": "HumanEval/49",
    "Dis": 0.0,
    "Err": 0.203,
    "TotalTime": 1.2716493606567383
  },
  {
    "name": "remove_vowels",
    "task_id": "HumanEval/51",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3140285015106201
  },
  {
    "name": "below_threshold",
    "task_id": "HumanEval/52",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4188613891601562
  },
  {
    "name": "add",
    "task_id": "HumanEval/53",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.257190227508545
  },
  {
    "name": "same_chars",
    "task_id": "HumanEval/54",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4048869609832764
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/56",
    "Dis": 0.0,
    "Err": 0.396,
    "TotalTime": 1.357309103012085
  },
  {
    "name": "monotonic",
    "task_id": "HumanEval/57",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.423032283782959
  },
  {
    "name": "common",
    "task_id": "HumanEval/58",
    "Dis": 0.0,
    "Err": 0.363,
    "TotalTime": 1.5066444873809814
  },
  {
    "name": "sum_to_n",
    "task_id": "HumanEval/60",
    "Dis": 0.0,
    "Err": 0.221,
    "TotalTime": 1.1243855953216553
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/61",
    "Dis": 0.0,
    "Err": 0.387,
    "TotalTime": 1.2120521068572998
  },
  {
    "name": "derivative",
    "task_id": "HumanEval/62",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2725698947906494
  },
  {
    "name": "vowels_count",
    "task_id": "HumanEval/64",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1889774799346924
  },
  {
    "name": "circular_shift",
    "task_id": "HumanEval/65",
    "Dis": 0.01,
    "Err": 0.108,
    "TotalTime": 1.135225772857666
  },
  {
    "name": "digitSum",
    "task_id": "HumanEval/66",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1829745769500732
  },
  {
    "name": "fruit_distribution",
    "task_id": "HumanEval/67",
    "Dis": 0.07,
    "Err": 0.699,
    "TotalTime": 1.2412829399108887
  },
  {
    "name": "pluck",
    "task_id": "HumanEval/68",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3079373836517334
  },
  {
    "name": "search",
    "task_id": "HumanEval/69",
    "Dis": 0.009,
    "Err": 0.185,
    "TotalTime": 140.24660563468933
  },
  {
    "name": "strange_sort_list",
    "task_id": "HumanEval/70",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 107.70958304405212
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/71",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 93.58473992347717
  },
  {
    "name": "will_it_fly",
    "task_id": "HumanEval/72",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 110.45167136192322
  },
  {
    "name": "smallest_change",
    "task_id": "HumanEval/73",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 132.34772396087646
  },
  {
    "name": "total_match",
    "task_id": "HumanEval/74",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 113.80665183067322
  },
  {
    "name": "iscube",
    "task_id": "HumanEval/77",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 131.9080400466919
  },
  {
    "name": "hex_key",
    "task_id": "HumanEval/78",
    "Dis": 0.0,
    "Err": 0.034,
    "TotalTime": 137.7228183746338
  },
  {
    "name": "decimal_to_binary",
    "task_id": "HumanEval/79",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 97.35591506958008
  },
  {
    "name": "is_happy",
    "task_id": "HumanEval/80",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 136.89738869667053
  },
  {
    "name": "numerical_letter_grade",
    "task_id": "HumanEval/81",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 150.022141456604
  },
  {
    "name": "prime_length",
    "task_id": "HumanEval/82",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 83.62224793434143
  },
  {
    "name": "starts_one_ends",
    "task_id": "HumanEval/83",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 159.1333248615265
  },
  {
    "name": "solve",
    "task_id": "HumanEval/84",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 119.16391777992249
  },
  {
    "name": "add",
    "task_id": "HumanEval/85",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 107.94518756866455
  },
  {
    "name": "anti_shuffle",
    "task_id": "HumanEval/86",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 104.00550198554993
  },
  {
    "name": "get_row",
    "task_id": "HumanEval/87",
    "Dis": 0.0,
    "Err": 0.002,
    "TotalTime": 163.52686834335327
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/88",
    "Dis": 0.0,
    "Err": 0.024,
    "TotalTime": 127.80062079429626
  },
  {
    "name": "encrypt",
    "task_id": "HumanEval/89",
    "Dis": 0.015,
    "Err": 0.366,
    "TotalTime": 161.37853145599365
  },
  {
    "name": "next_smallest",
    "task_id": "HumanEval/90",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 117.06443738937378
  },
  {
    "name": "is_bored",
    "task_id": "HumanEval/91",
    "Dis": 0.002,
    "Err": 0.011,
    "TotalTime": 116.60237145423889
  },
  {
    "name": "any_int",
    "task_id": "HumanEval/92",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 97.8730080127716
  },
  {
    "name": "encode",
    "task_id": "HumanEval/93",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 129.58394598960876
  },
  {
    "name": "skjkasdkd",
    "task_id": "HumanEval/94",
    "Dis": 0.002,
    "Err": 0.011,
    "TotalTime": 179.99928832054138
  },
  {
    "name": "check_dict_case",
    "task_id": "HumanEval/95",
    "Dis": 0.0,
    "Err": 0.011,
    "TotalTime": 101.94498348236084
  },
  {
    "name": "count_up_to",
    "task_id": "HumanEval/96",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 110.57301497459412
  },
  {
    "name": "multiply",
    "task_id": "HumanEval/97",
    "Dis": 0.0,
    "Err": 0.217,
    "TotalTime": 123.28539991378784
  },
  {
    "name": "count_upper",
    "task_id": "HumanEval/98",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 83.93502688407898
  },
  {
    "name": "closest_integer",
    "task_id": "HumanEval/99",
    "Dis": 0.0,
    "Err": 0.001,
    "TotalTime": 127.93316149711609
  },
  {
    "name": "make_a_pile",
    "task_id": "HumanEval/100",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 135.19133257865906
  },
  {
    "name": "rounded_avg",
    "task_id": "HumanEval/103",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 117.50398302078247
  },
  {
    "name": "unique_digits",
    "task_id": "HumanEval/104",
    "Dis": 0.01,
    "Err": 0.079,
    "TotalTime": 129.06645703315735
  },
  {
    "name": "by_length",
    "task_id": "HumanEval/105",
    "Dis": 0.01,
    "Err": 0.001,
    "TotalTime": 147.47548055648804
  },
  {
    "name": "f",
    "task_id": "HumanEval/106",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 148.58181643486023
  },
  {
    "name": "even_odd_palindrome",
    "task_id": "HumanEval/107",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 118.33932042121887
  },
  {
    "name": "count_nums",
    "task_id": "HumanEval/108",
    "Dis": 0.015,
    "Err": 0.004,
    "TotalTime": 134.70679140090942
  },
  {
    "name": "move_one_ball",
    "task_id": "HumanEval/109",
    "Dis": 0.03,
    "Err": 0.027,
    "TotalTime": 246.85309958457947
  },
  {
    "name": "exchange",
    "task_id": "HumanEval/110",
    "Dis": 0.001,
    "Err": 0.013,
    "TotalTime": 158.79721426963806
  },
  {
    "name": "histogram",
    "task_id": "HumanEval/111",
    "Dis": 0.003,
    "Err": 0.317,
    "TotalTime": 110.86810064315796
  },
  {
    "name": "reverse_delete",
    "task_id": "HumanEval/112",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 109.22571182250977
  },
  {
    "name": "minSubArraySum",
    "task_id": "HumanEval/114",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 115.64842510223389
  },
  {
    "name": "max_fill",
    "task_id": "HumanEval/115",
    "Dis": 0.0,
    "Err": 0.281,
    "TotalTime": 165.74677443504333
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/116",
    "Dis": 0.193,
    "Err": 0.111,
    "TotalTime": 183.11850714683533
  },
  {
    "name": "select_words",
    "task_id": "HumanEval/117",
    "Dis": 0.0,
    "Err": 0.059,
    "TotalTime": 116.61419725418091
  },
  {
    "name": "get_closest_vowel",
    "task_id": "HumanEval/118",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 157.87727332115173
  },
  {
    "name": "match_parens",
    "task_id": "HumanEval/119",
    "Dis": 0.049,
    "Err": 0.022,
    "TotalTime": 147.342298746109
  },
  {
    "name": "maximum",
    "task_id": "HumanEval/120",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 136.66195511817932
  },
  {
    "name": "solution",
    "task_id": "HumanEval/121",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 122.99534726142883
  },
  {
    "name": "add_elements",
    "task_id": "HumanEval/122",
    "Dis": 0.0,
    "Err": 0.487,
    "TotalTime": 89.83007669448853
  },
  {
    "name": "valid_date",
    "task_id": "HumanEval/124",
    "Dis": 0.0,
    "Err": 0.027,
    "TotalTime": 175.60256242752075
  },
  {
    "name": "split_words",
    "task_id": "HumanEval/125",
    "Dis": 0.054,
    "Err": 0.066,
    "TotalTime": 118.32993936538696
  },
  {
    "name": "is_sorted",
    "task_id": "HumanEval/126",
    "Dis": 0.001,
    "Err": 0.001,
    "TotalTime": 160.4946813583374
  },
  {
    "name": "intersection",
    "task_id": "HumanEval/127",
    "Dis": 0.014,
    "Err": 0.718,
    "TotalTime": 172.23676538467407
  },
  {
    "name": "prod_signs",
    "task_id": "HumanEval/128",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 140.87872290611267
  },
  {
    "name": "has_close_elements",
    "task_id": "HumanEval/0",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3926467895507812
  },
  {
    "name": "separate_paren_groups",
    "task_id": "HumanEval/1",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2928147315979004
  },
  {
    "name": "truncate_number",
    "task_id": "HumanEval/2",
    "Dis": 0.0,
    "Err": 0.194,
    "TotalTime": 1.146303653717041
  },
  {
    "name": "below_zero",
    "task_id": "HumanEval/3",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3045003414154053
  },
  {
    "name": "mean_absolute_deviation",
    "task_id": "HumanEval/4",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3403794765472412
  },
  {
    "name": "intersperse",
    "task_id": "HumanEval/5",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.320338487625122
  },
  {
    "name": "parse_nested_parens",
    "task_id": "HumanEval/6",
    "Dis": 0.0,
    "Err": 0.404,
    "TotalTime": 1.2467353343963623
  },
  {
    "name": "filter_by_substring",
    "task_id": "HumanEval/7",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5231726169586182
  },
  {
    "name": "sum_product",
    "task_id": "HumanEval/8",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3920226097106934
  },
  {
    "name": "rolling_max",
    "task_id": "HumanEval/9",
    "Dis": 0.002,
    "Err": 0.033,
    "TotalTime": 1.4268085956573486
  },
  {
    "name": "make_palindrome",
    "task_id": "HumanEval/10",
    "Dis": 0.023,
    "Err": 0.014,
    "TotalTime": 1.3659827709197998
  },
  {
    "name": "string_xor",
    "task_id": "HumanEval/11",
    "Dis": 0.063,
    "Err": 0.91,
    "TotalTime": 1.4142580032348633
  },
  {
    "name": "longest",
    "task_id": "HumanEval/12",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5153987407684326
  },
  {
    "name": "greatest_common_divisor",
    "task_id": "HumanEval/13",
    "Dis": 0.0,
    "Err": 0.195,
    "TotalTime": 1.2424798011779785
  },
  {
    "name": "all_prefixes",
    "task_id": "HumanEval/14",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2447328567504883
  },
  {
    "name": "string_sequence",
    "task_id": "HumanEval/15",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.197493076324463
  },
  {
    "name": "count_distinct_characters",
    "task_id": "HumanEval/16",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3155229091644287
  },
  {
    "name": "parse_music",
    "task_id": "HumanEval/17",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.7309541702270508
  },
  {
    "name": "how_many_times",
    "task_id": "HumanEval/18",
    "Dis": 0.0,
    "Err": 0.077,
    "TotalTime": 1.4021532535552979
  },
  {
    "name": "sort_numbers",
    "task_id": "HumanEval/19",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.096945285797119
  },
  {
    "name": "find_closest_elements",
    "task_id": "HumanEval/20",
    "Dis": 0.001,
    "Err": 0.006,
    "TotalTime": 1.4828557968139648
  },
  {
    "name": "rescale_to_unit",
    "task_id": "HumanEval/21",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4469404220581055
  },
  {
    "name": "filter_integers",
    "task_id": "HumanEval/22",
    "Dis": 0.0,
    "Err": 0.074,
    "TotalTime": 1.3983511924743652
  },
  {
    "name": "strlen",
    "task_id": "HumanEval/23",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.276489496231079
  },
  {
    "name": "largest_divisor",
    "task_id": "HumanEval/24",
    "Dis": 0.035,
    "Err": 0.211,
    "TotalTime": 1.2072536945343018
  },
  {
    "name": "factorize",
    "task_id": "HumanEval/25",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2291927337646484
  },
  {
    "name": "remove_duplicates",
    "task_id": "HumanEval/26",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3951871395111084
  },
  {
    "name": "flip_case",
    "task_id": "HumanEval/27",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3272836208343506
  },
  {
    "name": "concatenate",
    "task_id": "HumanEval/28",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4914071559906006
  },
  {
    "name": "filter_by_prefix",
    "task_id": "HumanEval/29",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.7439801692962646
  },
  {
    "name": "get_positive",
    "task_id": "HumanEval/30",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4303815364837646
  },
  {
    "name": "is_prime",
    "task_id": "HumanEval/31",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4226391315460205
  },
  {
    "name": "unique",
    "task_id": "HumanEval/34",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4449787139892578
  },
  {
    "name": "max_element",
    "task_id": "HumanEval/35",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4198758602142334
  },
  {
    "name": "sort_even",
    "task_id": "HumanEval/37",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.407435655593872
  },
  {
    "name": "triples_sum_to_zero",
    "task_id": "HumanEval/40",
    "Dis": 0.002,
    "Err": 0.0,
    "TotalTime": 1.3715152740478516
  },
  {
    "name": "car_race_collision",
    "task_id": "HumanEval/41",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2679133415222168
  },
  {
    "name": "incr_list",
    "task_id": "HumanEval/42",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4539101123809814
  },
  {
    "name": "pairs_sum_to_zero",
    "task_id": "HumanEval/43",
    "Dis": 0.007,
    "Err": 0.001,
    "TotalTime": 1.4376976490020752
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/45",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.273578405380249
  },
  {
    "name": "fib4",
    "task_id": "HumanEval/46",
    "Dis": 0.0,
    "Err": 0.04,
    "TotalTime": 1.2713959217071533
  },
  {
    "name": "median",
    "task_id": "HumanEval/47",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5181376934051514
  },
  {
    "name": "is_palindrome",
    "task_id": "HumanEval/48",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3347351551055908
  },
  {
    "name": "modp",
    "task_id": "HumanEval/49",
    "Dis": 0.0,
    "Err": 0.212,
    "TotalTime": 1.2976691722869873
  },
  {
    "name": "remove_vowels",
    "task_id": "HumanEval/51",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3407888412475586
  },
  {
    "name": "below_threshold",
    "task_id": "HumanEval/52",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4600989818572998
  },
  {
    "name": "add",
    "task_id": "HumanEval/53",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2661423683166504
  },
  {
    "name": "same_chars",
    "task_id": "HumanEval/54",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4265003204345703
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/56",
    "Dis": 0.0,
    "Err": 0.405,
    "TotalTime": 1.3618273735046387
  },
  {
    "name": "monotonic",
    "task_id": "HumanEval/57",
    "Dis": 0.0,
    "Err": 0.001,
    "TotalTime": 1.4568405151367188
  },
  {
    "name": "common",
    "task_id": "HumanEval/58",
    "Dis": 0.0,
    "Err": 0.381,
    "TotalTime": 1.5239088535308838
  },
  {
    "name": "sum_to_n",
    "task_id": "HumanEval/60",
    "Dis": 0.0,
    "Err": 0.173,
    "TotalTime": 1.2587261199951172
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/61",
    "Dis": 0.0,
    "Err": 0.439,
    "TotalTime": 1.3267335891723633
  },
  {
    "name": "derivative",
    "task_id": "HumanEval/62",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4052491188049316
  },
  {
    "name": "vowels_count",
    "task_id": "HumanEval/64",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3023815155029297
  },
  {
    "name": "circular_shift",
    "task_id": "HumanEval/65",
    "Dis": 0.017,
    "Err": 0.139,
    "TotalTime": 1.277780532836914
  },
  {
    "name": "digitSum",
    "task_id": "HumanEval/66",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.319913625717163
  },
  {
    "name": "fruit_distribution",
    "task_id": "HumanEval/67",
    "Dis": 0.054,
    "Err": 0.714,
    "TotalTime": 1.3897438049316406
  },
  {
    "name": "pluck",
    "task_id": "HumanEval/68",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4272654056549072
  },
  {
    "name": "search",
    "task_id": "HumanEval/69",
    "Dis": 0.004,
    "Err": 0.186,
    "TotalTime": 1.5578079223632812
  },
  {
    "name": "strange_sort_list",
    "task_id": "HumanEval/70",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4038984775543213
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/71",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3062317371368408
  },
  {
    "name": "will_it_fly",
    "task_id": "HumanEval/72",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.470257043838501
  },
  {
    "name": "smallest_change",
    "task_id": "HumanEval/73",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3538086414337158
  },
  {
    "name": "total_match",
    "task_id": "HumanEval/74",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.983665943145752
  },
  {
    "name": "iscube",
    "task_id": "HumanEval/77",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2419321537017822
  },
  {
    "name": "hex_key",
    "task_id": "HumanEval/78",
    "Dis": 0.0,
    "Err": 0.037,
    "TotalTime": 1.316805124282837
  },
  {
    "name": "decimal_to_binary",
    "task_id": "HumanEval/79",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2357983589172363
  },
  {
    "name": "is_happy",
    "task_id": "HumanEval/80",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3082897663116455
  },
  {
    "name": "numerical_letter_grade",
    "task_id": "HumanEval/81",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4640696048736572
  },
  {
    "name": "prime_length",
    "task_id": "HumanEval/82",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2923188209533691
  },
  {
    "name": "starts_one_ends",
    "task_id": "HumanEval/83",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2403905391693115
  },
  {
    "name": "solve",
    "task_id": "HumanEval/84",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.254812240600586
  },
  {
    "name": "add",
    "task_id": "HumanEval/85",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3652451038360596
  },
  {
    "name": "anti_shuffle",
    "task_id": "HumanEval/86",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3024051189422607
  },
  {
    "name": "get_row",
    "task_id": "HumanEval/87",
    "Dis": 0.0,
    "Err": 0.001,
    "TotalTime": 1.7435290813446045
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/88",
    "Dis": 0.0,
    "Err": 0.019,
    "TotalTime": 1.4457485675811768
  },
  {
    "name": "encrypt",
    "task_id": "HumanEval/89",
    "Dis": 0.007,
    "Err": 0.373,
    "TotalTime": 1.3203139305114746
  },
  {
    "name": "next_smallest",
    "task_id": "HumanEval/90",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4004640579223633
  },
  {
    "name": "is_bored",
    "task_id": "HumanEval/91",
    "Dis": 0.004,
    "Err": 0.008,
    "TotalTime": 1.3586857318878174
  },
  {
    "name": "any_int",
    "task_id": "HumanEval/92",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3242981433868408
  },
  {
    "name": "encode",
    "task_id": "HumanEval/93",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3662302494049072
  },
  {
    "name": "skjkasdkd",
    "task_id": "HumanEval/94",
    "Dis": 0.005,
    "Err": 0.012,
    "TotalTime": 2.6897809505462646
  },
  {
    "name": "check_dict_case",
    "task_id": "HumanEval/95",
    "Dis": 0.0,
    "Err": 0.005,
    "TotalTime": 1.4532794952392578
  },
  {
    "name": "count_up_to",
    "task_id": "HumanEval/96",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3416836261749268
  },
  {
    "name": "multiply",
    "task_id": "HumanEval/97",
    "Dis": 0.0,
    "Err": 0.239,
    "TotalTime": 1.246246576309204
  },
  {
    "name": "count_upper",
    "task_id": "HumanEval/98",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3113362789154053
  },
  {
    "name": "closest_integer",
    "task_id": "HumanEval/99",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.7370216846466064
  },
  {
    "name": "make_a_pile",
    "task_id": "HumanEval/100",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2483508586883545
  },
  {
    "name": "words_string",
    "task_id": "HumanEval/101",
    "Dis": 0.102,
    "Err": 0.072,
    "TotalTime": 299.90718364715576
  },
  {
    "name": "choose_num",
    "task_id": "HumanEval/102",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 292.8202259540558
  },
  {
    "name": "rounded_avg",
    "task_id": "HumanEval/103",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3135621547698975
  },
  {
    "name": "unique_digits",
    "task_id": "HumanEval/104",
    "Dis": 0.011,
    "Err": 0.099,
    "TotalTime": 1.56632661819458
  },
  {
    "name": "by_length",
    "task_id": "HumanEval/105",
    "Dis": 0.01,
    "Err": 0.007,
    "TotalTime": 1.4930777549743652
  },
  {
    "name": "f",
    "task_id": "HumanEval/106",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.276886224746704
  },
  {
    "name": "even_odd_palindrome",
    "task_id": "HumanEval/107",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3450641632080078
  },
  {
    "name": "count_nums",
    "task_id": "HumanEval/108",
    "Dis": 0.021,
    "Err": 0.006,
    "TotalTime": 1.577343463897705
  },
  {
    "name": "move_one_ball",
    "task_id": "HumanEval/109",
    "Dis": 0.053,
    "Err": 0.028,
    "TotalTime": 1.525691270828247
  },
  {
    "name": "exchange",
    "task_id": "HumanEval/110",
    "Dis": 0.001,
    "Err": 0.013,
    "TotalTime": 1.8686692714691162
  },
  {
    "name": "histogram",
    "task_id": "HumanEval/111",
    "Dis": 0.002,
    "Err": 0.324,
    "TotalTime": 1.3525917530059814
  },
  {
    "name": "reverse_delete",
    "task_id": "HumanEval/112",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.439249038696289
  },
  {
    "name": "odd_count",
    "task_id": "HumanEval/113",
    "Dis": 0.001,
    "Err": 0.0,
    "TotalTime": 487.5938153266907
  },
  {
    "name": "minSubArraySum",
    "task_id": "HumanEval/114",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4518022537231445
  },
  {
    "name": "max_fill",
    "task_id": "HumanEval/115",
    "Dis": 0.0,
    "Err": 0.267,
    "TotalTime": 1.746659278869629
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/116",
    "Dis": 0.164,
    "Err": 0.102,
    "TotalTime": 1.4626662731170654
  },
  {
    "name": "select_words",
    "task_id": "HumanEval/117",
    "Dis": 0.0,
    "Err": 0.035,
    "TotalTime": 1.3954026699066162
  },
  {
    "name": "get_closest_vowel",
    "task_id": "HumanEval/118",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3439040184020996
  },
  {
    "name": "match_parens",
    "task_id": "HumanEval/119",
    "Dis": 0.04,
    "Err": 0.023,
    "TotalTime": 1.5756778717041016
  },
  {
    "name": "maximum",
    "task_id": "HumanEval/120",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4575564861297607
  },
  {
    "name": "solution",
    "task_id": "HumanEval/121",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.389653205871582
  },
  {
    "name": "add_elements",
    "task_id": "HumanEval/122",
    "Dis": 0.0,
    "Err": 0.516,
    "TotalTime": 1.4478850364685059
  },
  {
    "name": "valid_date",
    "task_id": "HumanEval/124",
    "Dis": 0.0,
    "Err": 0.034,
    "TotalTime": 1.3618431091308594
  },
  {
    "name": "split_words",
    "task_id": "HumanEval/125",
    "Dis": 0.042,
    "Err": 0.046,
    "TotalTime": 1.3369619846343994
  },
  {
    "name": "is_sorted",
    "task_id": "HumanEval/126",
    "Dis": 0.001,
    "Err": 0.005,
    "TotalTime": 1.4667143821716309
  },
  {
    "name": "intersection",
    "task_id": "HumanEval/127",
    "Dis": 0.016,
    "Err": 0.748,
    "TotalTime": 2.912879228591919
  },
  {
    "name": "prod_signs",
    "task_id": "HumanEval/128",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4194777011871338
  },
  {
    "name": "has_close_elements",
    "task_id": "HumanEval/0",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5163962841033936
  },
  {
    "name": "separate_paren_groups",
    "task_id": "HumanEval/1",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3504056930541992
  },
  {
    "name": "truncate_number",
    "task_id": "HumanEval/2",
    "Dis": 0.0,
    "Err": 0.243,
    "TotalTime": 1.296402931213379
  },
  {
    "name": "below_zero",
    "task_id": "HumanEval/3",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4395828247070312
  },
  {
    "name": "mean_absolute_deviation",
    "task_id": "HumanEval/4",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4853794574737549
  },
  {
    "name": "intersperse",
    "task_id": "HumanEval/5",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4072585105895996
  },
  {
    "name": "parse_nested_parens",
    "task_id": "HumanEval/6",
    "Dis": 0.0,
    "Err": 0.438,
    "TotalTime": 1.4154777526855469
  },
  {
    "name": "filter_by_substring",
    "task_id": "HumanEval/7",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.7006003856658936
  },
  {
    "name": "sum_product",
    "task_id": "HumanEval/8",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4745516777038574
  },
  {
    "name": "rolling_max",
    "task_id": "HumanEval/9",
    "Dis": 0.004,
    "Err": 0.043,
    "TotalTime": 1.4443631172180176
  },
  {
    "name": "make_palindrome",
    "task_id": "HumanEval/10",
    "Dis": 0.024,
    "Err": 0.014,
    "TotalTime": 1.3679497241973877
  },
  {
    "name": "string_xor",
    "task_id": "HumanEval/11",
    "Dis": 0.071,
    "Err": 0.917,
    "TotalTime": 1.4544167518615723
  },
  {
    "name": "longest",
    "task_id": "HumanEval/12",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5475447177886963
  },
  {
    "name": "greatest_common_divisor",
    "task_id": "HumanEval/13",
    "Dis": 0.0,
    "Err": 0.18,
    "TotalTime": 1.28639554977417
  },
  {
    "name": "all_prefixes",
    "task_id": "HumanEval/14",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3583407402038574
  },
  {
    "name": "string_sequence",
    "task_id": "HumanEval/15",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2977056503295898
  },
  {
    "name": "count_distinct_characters",
    "task_id": "HumanEval/16",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3559045791625977
  },
  {
    "name": "parse_music",
    "task_id": "HumanEval/17",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.7906343936920166
  },
  {
    "name": "how_many_times",
    "task_id": "HumanEval/18",
    "Dis": 0.0,
    "Err": 0.072,
    "TotalTime": 1.4444386959075928
  },
  {
    "name": "sort_numbers",
    "task_id": "HumanEval/19",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.2260680198669434
  },
  {
    "name": "find_closest_elements",
    "task_id": "HumanEval/20",
    "Dis": 0.003,
    "Err": 0.003,
    "TotalTime": 1.533541202545166
  },
  {
    "name": "rescale_to_unit",
    "task_id": "HumanEval/21",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4923121929168701
  },
  {
    "name": "filter_integers",
    "task_id": "HumanEval/22",
    "Dis": 0.0,
    "Err": 0.082,
    "TotalTime": 1.4493744373321533
  },
  {
    "name": "strlen",
    "task_id": "HumanEval/23",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3157200813293457
  },
  {
    "name": "largest_divisor",
    "task_id": "HumanEval/24",
    "Dis": 0.032,
    "Err": 0.225,
    "TotalTime": 1.2424166202545166
  },
  {
    "name": "factorize",
    "task_id": "HumanEval/25",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3133375644683838
  },
  {
    "name": "remove_duplicates",
    "task_id": "HumanEval/26",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5009148120880127
  },
  {
    "name": "flip_case",
    "task_id": "HumanEval/27",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3451976776123047
  },
  {
    "name": "concatenate",
    "task_id": "HumanEval/28",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.61336088180542
  },
  {
    "name": "filter_by_prefix",
    "task_id": "HumanEval/29",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.8497579097747803
  },
  {
    "name": "get_positive",
    "task_id": "HumanEval/30",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5224971771240234
  },
  {
    "name": "is_prime",
    "task_id": "HumanEval/31",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4839634895324707
  },
  {
    "name": "unique",
    "task_id": "HumanEval/34",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4964680671691895
  },
  {
    "name": "max_element",
    "task_id": "HumanEval/35",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.501418113708496
  },
  {
    "name": "sort_even",
    "task_id": "HumanEval/37",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5539159774780273
  },
  {
    "name": "triples_sum_to_zero",
    "task_id": "HumanEval/40",
    "Dis": 0.001,
    "Err": 0.0,
    "TotalTime": 1.5120272636413574
  },
  {
    "name": "car_race_collision",
    "task_id": "HumanEval/41",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.260124683380127
  },
  {
    "name": "incr_list",
    "task_id": "HumanEval/42",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4762580394744873
  },
  {
    "name": "pairs_sum_to_zero",
    "task_id": "HumanEval/43",
    "Dis": 0.008,
    "Err": 0.008,
    "TotalTime": 1.4802496433258057
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/45",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3011057376861572
  },
  {
    "name": "fib4",
    "task_id": "HumanEval/46",
    "Dis": 0.0,
    "Err": 0.024,
    "TotalTime": 1.3314740657806396
  },
  {
    "name": "median",
    "task_id": "HumanEval/47",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.48195219039917
  },
  {
    "name": "is_palindrome",
    "task_id": "HumanEval/48",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3240652084350586
  },
  {
    "name": "modp",
    "task_id": "HumanEval/49",
    "Dis": 0.0,
    "Err": 0.219,
    "TotalTime": 1.3182036876678467
  },
  {
    "name": "remove_vowels",
    "task_id": "HumanEval/51",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3550422191619873
  },
  {
    "name": "below_threshold",
    "task_id": "HumanEval/52",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4736521244049072
  },
  {
    "name": "add",
    "task_id": "HumanEval/53",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2850685119628906
  },
  {
    "name": "same_chars",
    "task_id": "HumanEval/54",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4427483081817627
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/56",
    "Dis": 0.0,
    "Err": 0.417,
    "TotalTime": 1.3531858921051025
  },
  {
    "name": "monotonic",
    "task_id": "HumanEval/57",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4507288932800293
  },
  {
    "name": "common",
    "task_id": "HumanEval/58",
    "Dis": 0.0,
    "Err": 0.393,
    "TotalTime": 1.553126335144043
  },
  {
    "name": "sum_to_n",
    "task_id": "HumanEval/60",
    "Dis": 0.0,
    "Err": 0.207,
    "TotalTime": 1.2688629627227783
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/61",
    "Dis": 0.0,
    "Err": 0.421,
    "TotalTime": 1.3639824390411377
  },
  {
    "name": "derivative",
    "task_id": "HumanEval/62",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.412754774093628
  },
  {
    "name": "vowels_count",
    "task_id": "HumanEval/64",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3487224578857422
  },
  {
    "name": "circular_shift",
    "task_id": "HumanEval/65",
    "Dis": 0.016,
    "Err": 0.119,
    "TotalTime": 1.2956299781799316
  },
  {
    "name": "digitSum",
    "task_id": "HumanEval/66",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.347287654876709
  },
  {
    "name": "fruit_distribution",
    "task_id": "HumanEval/67",
    "Dis": 0.082,
    "Err": 0.722,
    "TotalTime": 1.4297943115234375
  },
  {
    "name": "pluck",
    "task_id": "HumanEval/68",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5469276905059814
  },
  {
    "name": "search",
    "task_id": "HumanEval/69",
    "Dis": 0.007,
    "Err": 0.158,
    "TotalTime": 1.6111419200897217
  },
  {
    "name": "strange_sort_list",
    "task_id": "HumanEval/70",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4863300323486328
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/71",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3326630592346191
  },
  {
    "name": "will_it_fly",
    "task_id": "HumanEval/72",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5351014137268066
  },
  {
    "name": "smallest_change",
    "task_id": "HumanEval/73",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3822970390319824
  },
  {
    "name": "total_match",
    "task_id": "HumanEval/74",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 2.085514545440674
  },
  {
    "name": "iscube",
    "task_id": "HumanEval/77",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2571494579315186
  },
  {
    "name": "hex_key",
    "task_id": "HumanEval/78",
    "Dis": 0.0,
    "Err": 0.041,
    "TotalTime": 1.3515894412994385
  },
  {
    "name": "decimal_to_binary",
    "task_id": "HumanEval/79",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2425708770751953
  },
  {
    "name": "is_happy",
    "task_id": "HumanEval/80",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3518154621124268
  },
  {
    "name": "numerical_letter_grade",
    "task_id": "HumanEval/81",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5075583457946777
  },
  {
    "name": "prime_length",
    "task_id": "HumanEval/82",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.31009840965271
  },
  {
    "name": "starts_one_ends",
    "task_id": "HumanEval/83",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.308767557144165
  },
  {
    "name": "solve",
    "task_id": "HumanEval/84",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2275128364562988
  },
  {
    "name": "add",
    "task_id": "HumanEval/85",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.39475679397583
  },
  {
    "name": "anti_shuffle",
    "task_id": "HumanEval/86",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3594422340393066
  },
  {
    "name": "get_row",
    "task_id": "HumanEval/87",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.8786029815673828
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/88",
    "Dis": 0.0,
    "Err": 0.015,
    "TotalTime": 1.4917230606079102
  },
  {
    "name": "encrypt",
    "task_id": "HumanEval/89",
    "Dis": 0.017,
    "Err": 0.379,
    "TotalTime": 1.36667799949646
  },
  {
    "name": "next_smallest",
    "task_id": "HumanEval/90",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4811766147613525
  },
  {
    "name": "is_bored",
    "task_id": "HumanEval/91",
    "Dis": 0.0,
    "Err": 0.008,
    "TotalTime": 1.3749194145202637
  },
  {
    "name": "any_int",
    "task_id": "HumanEval/92",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3399620056152344
  },
  {
    "name": "encode",
    "task_id": "HumanEval/93",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3966889381408691
  },
  {
    "name": "skjkasdkd",
    "task_id": "HumanEval/94",
    "Dis": 0.007,
    "Err": 0.02,
    "TotalTime": 2.8274552822113037
  },
  {
    "name": "check_dict_case",
    "task_id": "HumanEval/95",
    "Dis": 0.0,
    "Err": 0.007,
    "TotalTime": 1.4937055110931396
  },
  {
    "name": "count_up_to",
    "task_id": "HumanEval/96",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3664376735687256
  },
  {
    "name": "multiply",
    "task_id": "HumanEval/97",
    "Dis": 0.0,
    "Err": 0.216,
    "TotalTime": 1.263472557067871
  },
  {
    "name": "count_upper",
    "task_id": "HumanEval/98",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.349987506866455
  },
  {
    "name": "closest_integer",
    "task_id": "HumanEval/99",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.8114104270935059
  },
  {
    "name": "make_a_pile",
    "task_id": "HumanEval/100",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2740695476531982
  },
  {
    "name": "words_string",
    "task_id": "HumanEval/101",
    "Dis": 0.109,
    "Err": 0.073,
    "TotalTime": 1.3335726261138916
  },
  {
    "name": "choose_num",
    "task_id": "HumanEval/102",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3071486949920654
  },
  {
    "name": "rounded_avg",
    "task_id": "HumanEval/103",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3034627437591553
  },
  {
    "name": "unique_digits",
    "task_id": "HumanEval/104",
    "Dis": 0.019,
    "Err": 0.099,
    "TotalTime": 1.5450880527496338
  },
  {
    "name": "by_length",
    "task_id": "HumanEval/105",
    "Dis": 0.007,
    "Err": 0.006,
    "TotalTime": 1.489302396774292
  },
  {
    "name": "f",
    "task_id": "HumanEval/106",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.322545051574707
  },
  {
    "name": "even_odd_palindrome",
    "task_id": "HumanEval/107",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3019211292266846
  },
  {
    "name": "count_nums",
    "task_id": "HumanEval/108",
    "Dis": 0.011,
    "Err": 0.006,
    "TotalTime": 1.5752334594726562
  },
  {
    "name": "move_one_ball",
    "task_id": "HumanEval/109",
    "Dis": 0.054,
    "Err": 0.037,
    "TotalTime": 1.5090060234069824
  },
  {
    "name": "exchange",
    "task_id": "HumanEval/110",
    "Dis": 0.001,
    "Err": 0.016,
    "TotalTime": 1.9252946376800537
  },
  {
    "name": "histogram",
    "task_id": "HumanEval/111",
    "Dis": 0.003,
    "Err": 0.312,
    "TotalTime": 1.348404884338379
  },
  {
    "name": "reverse_delete",
    "task_id": "HumanEval/112",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4458646774291992
  },
  {
    "name": "odd_count",
    "task_id": "HumanEval/113",
    "Dis": 0.002,
    "Err": 0.0,
    "TotalTime": 1.8854930400848389
  },
  {
    "name": "minSubArraySum",
    "task_id": "HumanEval/114",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5264451503753662
  },
  {
    "name": "max_fill",
    "task_id": "HumanEval/115",
    "Dis": 0.0,
    "Err": 0.303,
    "TotalTime": 1.8214905261993408
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/116",
    "Dis": 0.18,
    "Err": 0.11,
    "TotalTime": 1.5029377937316895
  },
  {
    "name": "select_words",
    "task_id": "HumanEval/117",
    "Dis": 0.0,
    "Err": 0.057,
    "TotalTime": 1.4143846035003662
  },
  {
    "name": "get_closest_vowel",
    "task_id": "HumanEval/118",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3497443199157715
  },
  {
    "name": "match_parens",
    "task_id": "HumanEval/119",
    "Dis": 0.053,
    "Err": 0.022,
    "TotalTime": 1.6366674900054932
  },
  {
    "name": "maximum",
    "task_id": "HumanEval/120",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.518570899963379
  },
  {
    "name": "solution",
    "task_id": "HumanEval/121",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4290082454681396
  },
  {
    "name": "add_elements",
    "task_id": "HumanEval/122",
    "Dis": 0.0,
    "Err": 0.493,
    "TotalTime": 1.489422082901001
  },
  {
    "name": "valid_date",
    "task_id": "HumanEval/124",
    "Dis": 0.0,
    "Err": 0.022,
    "TotalTime": 1.381608247756958
  },
  {
    "name": "split_words",
    "task_id": "HumanEval/125",
    "Dis": 0.04,
    "Err": 0.047,
    "TotalTime": 1.3432793617248535
  },
  {
    "name": "is_sorted",
    "task_id": "HumanEval/126",
    "Dis": 0.001,
    "Err": 0.002,
    "TotalTime": 1.5029375553131104
  },
  {
    "name": "intersection",
    "task_id": "HumanEval/127",
    "Dis": 0.022,
    "Err": 0.738,
    "TotalTime": 3.0593013763427734
  },
  {
    "name": "prod_signs",
    "task_id": "HumanEval/128",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.477081298828125
  },
  {
    "name": "digits",
    "task_id": "HumanEval/131",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 144.91160202026367
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/133",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 223.29195499420166
  },
  {
    "name": "check_if_last_char_is_a_letter",
    "task_id": "HumanEval/134",
    "Dis": 0.001,
    "Err": 0.003,
    "TotalTime": 246.9498679637909
  },
  {
    "name": "has_close_elements",
    "task_id": "HumanEval/0",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.4158706665039062
  },
  {
    "name": "separate_paren_groups",
    "task_id": "HumanEval/1",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2171852588653564
  },
  {
    "name": "truncate_number",
    "task_id": "HumanEval/2",
    "Dis": 0.0,
    "Err": 0.216,
    "TotalTime": 1.126650333404541
  },
  {
    "name": "below_zero",
    "task_id": "HumanEval/3",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.298795223236084
  },
  {
    "name": "mean_absolute_deviation",
    "task_id": "HumanEval/4",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.318777322769165
  },
  {
    "name": "intersperse",
    "task_id": "HumanEval/5",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2608978748321533
  },
  {
    "name": "parse_nested_parens",
    "task_id": "HumanEval/6",
    "Dis": 0.0,
    "Err": 0.357,
    "TotalTime": 1.215909481048584
  },
  {
    "name": "filter_by_substring",
    "task_id": "HumanEval/7",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5117173194885254
  },
  {
    "name": "sum_product",
    "task_id": "HumanEval/8",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3116497993469238
  },
  {
    "name": "rolling_max",
    "task_id": "HumanEval/9",
    "Dis": 0.0,
    "Err": 0.051,
    "TotalTime": 1.2797050476074219
  },
  {
    "name": "make_palindrome",
    "task_id": "HumanEval/10",
    "Dis": 0.028,
    "Err": 0.013,
    "TotalTime": 1.2198941707611084
  },
  {
    "name": "string_xor",
    "task_id": "HumanEval/11",
    "Dis": 0.071,
    "Err": 0.912,
    "TotalTime": 1.291167974472046
  },
  {
    "name": "longest",
    "task_id": "HumanEval/12",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3209803104400635
  },
  {
    "name": "greatest_common_divisor",
    "task_id": "HumanEval/13",
    "Dis": 0.0,
    "Err": 0.184,
    "TotalTime": 1.1352474689483643
  },
  {
    "name": "all_prefixes",
    "task_id": "HumanEval/14",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2453556060791016
  },
  {
    "name": "string_sequence",
    "task_id": "HumanEval/15",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1260571479797363
  },
  {
    "name": "count_distinct_characters",
    "task_id": "HumanEval/16",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.185814619064331
  },
  {
    "name": "parse_music",
    "task_id": "HumanEval/17",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.5943994522094727
  },
  {
    "name": "how_many_times",
    "task_id": "HumanEval/18",
    "Dis": 0.0,
    "Err": 0.077,
    "TotalTime": 1.276111364364624
  },
  {
    "name": "sort_numbers",
    "task_id": "HumanEval/19",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.9159440994262695
  },
  {
    "name": "find_closest_elements",
    "task_id": "HumanEval/20",
    "Dis": 0.0,
    "Err": 0.007,
    "TotalTime": 1.3386032581329346
  },
  {
    "name": "rescale_to_unit",
    "task_id": "HumanEval/21",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3180978298187256
  },
  {
    "name": "filter_integers",
    "task_id": "HumanEval/22",
    "Dis": 0.0,
    "Err": 0.065,
    "TotalTime": 1.303715705871582
  },
  {
    "name": "strlen",
    "task_id": "HumanEval/23",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3552229404449463
  },
  {
    "name": "largest_divisor",
    "task_id": "HumanEval/24",
    "Dis": 0.029,
    "Err": 0.211,
    "TotalTime": 1.1434080600738525
  },
  {
    "name": "factorize",
    "task_id": "HumanEval/25",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1817619800567627
  },
  {
    "name": "remove_duplicates",
    "task_id": "HumanEval/26",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3916206359863281
  },
  {
    "name": "flip_case",
    "task_id": "HumanEval/27",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2943367958068848
  },
  {
    "name": "concatenate",
    "task_id": "HumanEval/28",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.50071382522583
  },
  {
    "name": "filter_by_prefix",
    "task_id": "HumanEval/29",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.6133787631988525
  },
  {
    "name": "get_positive",
    "task_id": "HumanEval/30",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2997610569000244
  },
  {
    "name": "is_prime",
    "task_id": "HumanEval/31",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1814963817596436
  },
  {
    "name": "unique",
    "task_id": "HumanEval/34",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2959113121032715
  },
  {
    "name": "max_element",
    "task_id": "HumanEval/35",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3372271060943604
  },
  {
    "name": "sort_even",
    "task_id": "HumanEval/37",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3449199199676514
  },
  {
    "name": "triples_sum_to_zero",
    "task_id": "HumanEval/40",
    "Dis": 0.001,
    "Err": 0.0,
    "TotalTime": 1.3828356266021729
  },
  {
    "name": "car_race_collision",
    "task_id": "HumanEval/41",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.145205020904541
  },
  {
    "name": "incr_list",
    "task_id": "HumanEval/42",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2921147346496582
  },
  {
    "name": "pairs_sum_to_zero",
    "task_id": "HumanEval/43",
    "Dis": 0.004,
    "Err": 0.009,
    "TotalTime": 1.3102350234985352
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/45",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1170506477355957
  },
  {
    "name": "fib4",
    "task_id": "HumanEval/46",
    "Dis": 0.0,
    "Err": 0.035,
    "TotalTime": 1.1154184341430664
  },
  {
    "name": "median",
    "task_id": "HumanEval/47",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3121018409729004
  },
  {
    "name": "is_palindrome",
    "task_id": "HumanEval/48",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1532979011535645
  },
  {
    "name": "modp",
    "task_id": "HumanEval/49",
    "Dis": 0.0,
    "Err": 0.214,
    "TotalTime": 1.1656115055084229
  },
  {
    "name": "remove_vowels",
    "task_id": "HumanEval/51",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.184300184249878
  },
  {
    "name": "below_threshold",
    "task_id": "HumanEval/52",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2948267459869385
  },
  {
    "name": "add",
    "task_id": "HumanEval/53",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1249346733093262
  },
  {
    "name": "same_chars",
    "task_id": "HumanEval/54",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.278526782989502
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/56",
    "Dis": 0.0,
    "Err": 0.421,
    "TotalTime": 1.1970956325531006
  },
  {
    "name": "monotonic",
    "task_id": "HumanEval/57",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3065078258514404
  },
  {
    "name": "common",
    "task_id": "HumanEval/58",
    "Dis": 0.0,
    "Err": 0.395,
    "TotalTime": 1.4108726978302002
  },
  {
    "name": "sum_to_n",
    "task_id": "HumanEval/60",
    "Dis": 0.0,
    "Err": 0.196,
    "TotalTime": 1.107222318649292
  },
  {
    "name": "correct_bracketing",
    "task_id": "HumanEval/61",
    "Dis": 0.0,
    "Err": 0.425,
    "TotalTime": 1.2012808322906494
  },
  {
    "name": "derivative",
    "task_id": "HumanEval/62",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2716200351715088
  },
  {
    "name": "vowels_count",
    "task_id": "HumanEval/64",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.198268175125122
  },
  {
    "name": "circular_shift",
    "task_id": "HumanEval/65",
    "Dis": 0.006,
    "Err": 0.123,
    "TotalTime": 1.141005039215088
  },
  {
    "name": "digitSum",
    "task_id": "HumanEval/66",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1632609367370605
  },
  {
    "name": "fruit_distribution",
    "task_id": "HumanEval/67",
    "Dis": 0.063,
    "Err": 0.698,
    "TotalTime": 1.2504653930664062
  },
  {
    "name": "pluck",
    "task_id": "HumanEval/68",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2820444107055664
  },
  {
    "name": "search",
    "task_id": "HumanEval/69",
    "Dis": 0.006,
    "Err": 0.168,
    "TotalTime": 1.4251999855041504
  },
  {
    "name": "strange_sort_list",
    "task_id": "HumanEval/70",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2534289360046387
  },
  {
    "name": "triangle_area",
    "task_id": "HumanEval/71",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1611523628234863
  },
  {
    "name": "will_it_fly",
    "task_id": "HumanEval/72",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3422274589538574
  },
  {
    "name": "smallest_change",
    "task_id": "HumanEval/73",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2391560077667236
  },
  {
    "name": "total_match",
    "task_id": "HumanEval/74",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.8060340881347656
  },
  {
    "name": "iscube",
    "task_id": "HumanEval/77",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1611363887786865
  },
  {
    "name": "hex_key",
    "task_id": "HumanEval/78",
    "Dis": 0.0,
    "Err": 0.041,
    "TotalTime": 1.1842153072357178
  },
  {
    "name": "decimal_to_binary",
    "task_id": "HumanEval/79",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.099088430404663
  },
  {
    "name": "is_happy",
    "task_id": "HumanEval/80",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1828067302703857
  },
  {
    "name": "numerical_letter_grade",
    "task_id": "HumanEval/81",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.3232755661010742
  },
  {
    "name": "prime_length",
    "task_id": "HumanEval/82",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1722068786621094
  },
  {
    "name": "starts_one_ends",
    "task_id": "HumanEval/83",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1208996772766113
  },
  {
    "name": "solve",
    "task_id": "HumanEval/84",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.18424654006958
  },
  {
    "name": "add",
    "task_id": "HumanEval/85",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2367243766784668
  },
  {
    "name": "anti_shuffle",
    "task_id": "HumanEval/86",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1880788803100586
  },
  {
    "name": "get_row",
    "task_id": "HumanEval/87",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.707120656967163
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/88",
    "Dis": 0.0,
    "Err": 0.019,
    "TotalTime": 1.3064327239990234
  },
  {
    "name": "encrypt",
    "task_id": "HumanEval/89",
    "Dis": 0.009,
    "Err": 0.392,
    "TotalTime": 1.332820177078247
  },
  {
    "name": "next_smallest",
    "task_id": "HumanEval/90",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.293649435043335
  },
  {
    "name": "is_bored",
    "task_id": "HumanEval/91",
    "Dis": 0.001,
    "Err": 0.013,
    "TotalTime": 1.213578462600708
  },
  {
    "name": "any_int",
    "task_id": "HumanEval/92",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1642813682556152
  },
  {
    "name": "encode",
    "task_id": "HumanEval/93",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1974806785583496
  },
  {
    "name": "skjkasdkd",
    "task_id": "HumanEval/94",
    "Dis": 0.006,
    "Err": 0.023,
    "TotalTime": 2.4331984519958496
  },
  {
    "name": "check_dict_case",
    "task_id": "HumanEval/95",
    "Dis": 0.0,
    "Err": 0.007,
    "TotalTime": 1.321622610092163
  },
  {
    "name": "count_up_to",
    "task_id": "HumanEval/96",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1911978721618652
  },
  {
    "name": "multiply",
    "task_id": "HumanEval/97",
    "Dis": 0.0,
    "Err": 0.236,
    "TotalTime": 1.119619607925415
  },
  {
    "name": "count_upper",
    "task_id": "HumanEval/98",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1677238941192627
  },
  {
    "name": "closest_integer",
    "task_id": "HumanEval/99",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.6294012069702148
  },
  {
    "name": "make_a_pile",
    "task_id": "HumanEval/100",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.0925524234771729
  },
  {
    "name": "words_string",
    "task_id": "HumanEval/101",
    "Dis": 0.1,
    "Err": 0.063,
    "TotalTime": 1.1881520748138428
  },
  {
    "name": "choose_num",
    "task_id": "HumanEval/102",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2531256675720215
  },
  {
    "name": "rounded_avg",
    "task_id": "HumanEval/103",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2772512435913086
  },
  {
    "name": "unique_digits",
    "task_id": "HumanEval/104",
    "Dis": 0.006,
    "Err": 0.079,
    "TotalTime": 1.4405105113983154
  },
  {
    "name": "by_length",
    "task_id": "HumanEval/105",
    "Dis": 0.01,
    "Err": 0.005,
    "TotalTime": 1.3045830726623535
  },
  {
    "name": "f",
    "task_id": "HumanEval/106",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1646041870117188
  },
  {
    "name": "even_odd_palindrome",
    "task_id": "HumanEval/107",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1656248569488525
  },
  {
    "name": "count_nums",
    "task_id": "HumanEval/108",
    "Dis": 0.012,
    "Err": 0.005,
    "TotalTime": 1.3716018199920654
  },
  {
    "name": "move_one_ball",
    "task_id": "HumanEval/109",
    "Dis": 0.048,
    "Err": 0.03,
    "TotalTime": 1.3161683082580566
  },
  {
    "name": "exchange",
    "task_id": "HumanEval/110",
    "Dis": 0.0,
    "Err": 0.01,
    "TotalTime": 1.655479907989502
  },
  {
    "name": "histogram",
    "task_id": "HumanEval/111",
    "Dis": 0.004,
    "Err": 0.315,
    "TotalTime": 1.1928191184997559
  },
  {
    "name": "reverse_delete",
    "task_id": "HumanEval/112",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2802996635437012
  },
  {
    "name": "odd_count",
    "task_id": "HumanEval/113",
    "Dis": 0.004,
    "Err": 0.001,
    "TotalTime": 1.686201810836792
  },
  {
    "name": "minSubArraySum",
    "task_id": "HumanEval/114",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2903647422790527
  },
  {
    "name": "max_fill",
    "task_id": "HumanEval/115",
    "Dis": 0.0,
    "Err": 0.286,
    "TotalTime": 1.5904946327209473
  },
  {
    "name": "sort_array",
    "task_id": "HumanEval/116",
    "Dis": 0.177,
    "Err": 0.117,
    "TotalTime": 1.3221585750579834
  },
  {
    "name": "select_words",
    "task_id": "HumanEval/117",
    "Dis": 0.0,
    "Err": 0.055,
    "TotalTime": 1.230405330657959
  },
  {
    "name": "get_closest_vowel",
    "task_id": "HumanEval/118",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.1787495613098145
  },
  {
    "name": "match_parens",
    "task_id": "HumanEval/119",
    "Dis": 0.041,
    "Err": 0.03,
    "TotalTime": 1.4160246849060059
  },
  {
    "name": "maximum",
    "task_id": "HumanEval/120",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.306487798690796
  },
  {
    "name": "solution",
    "task_id": "HumanEval/121",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 1.2432103157043457
  },
  {
    "name": "add_elements",
    "task_id": "HumanEval/122",
    "Dis": 0.0,
    "Err": 0.483,
    "TotalTime": 1.3166673183441162
  },
  {
    "name": "largest_prime_factor",
    "task_id": "HumanEval/59",
    "Dis": 0.006,
    "Failed": "Timeout of 60.0 s. has been hit during error computation"
  },
  {
    "name": "get_odd_collatz",
    "task_id": "HumanEval/123",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "minPath",
    "task_id": "HumanEval/129",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "tri",
    "task_id": "HumanEval/130",
    "Failed": "Exception occurred during when querying the LLM -- APIStatusError : {'type': 'error', 'error': {'details': None, 'type': 'overloaded_error', 'message': 'Overloaded'}}"
  },
  {
    "name": "can_arrange",
    "task_id": "HumanEval/135",
    "Failed": "Exception occurred during when querying the LLM -- APIStatusError : {'type': 'error', 'error': {'details': None, 'type': 'overloaded_error', 'message': 'Overloaded'}}"
  },
  {
    "name": "tri",
    "task_id": "HumanEval/130",
    "Dis": 0.194,
    "Err": 0.343,
    "TotalTime": 286.7840917110443
  },
  {
    "name": "can_arrange",
    "task_id": "HumanEval/135",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 186.1924421787262
  },
  {
    "name": "largest_smallest_integers",
    "task_id": "HumanEval/136",
    "Dis": 0.001,
    "Err": 0.002,
    "TotalTime": 132.08034420013428
  },
  {
    "name": "compare_one",
    "task_id": "HumanEval/137",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 160.70256876945496
  },
  {
    "name": "is_equal_to_sum_even",
    "task_id": "HumanEval/138",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 227.71093320846558
  },
  {
    "name": "special_factorial",
    "task_id": "HumanEval/139",
    "Failed": "Timeout of 60.0 s. has been hit during disagreement computation"
  },
  {
    "name": "fix_spaces",
    "task_id": "HumanEval/140",
    "Dis": 0.0,
    "Err": 0.005,
    "TotalTime": 202.2625288963318
  },
  {
    "name": "file_name_check",
    "task_id": "HumanEval/141",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 201.1892638206482
  },
  {
    "name": "sum_squares",
    "task_id": "HumanEval/142",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 239.88163471221924
  },
  {
    "name": "words_in_sentence",
    "task_id": "HumanEval/143",
    "Dis": 0.0,
    "Err": 0.0,
    "TotalTime": 170.28878211975098
  },
  {
    "name": "simplify",
    "task_id": "HumanEval/144",
    "Failed": "Exception occurred during when querying the LLM -- BadRequestError : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
  },
  {
    "name": "order_by_points",
    "task_id": "HumanEval/145",
    "Failed": "Exception occurred during when querying the LLM -- BadRequestError : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
  },
  {
    "name": "specialFilter",
    "task_id": "HumanEval/146",
    "Failed": "Exception occurred during when querying the LLM -- BadRequestError : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
  },
  {
    "name": "bf",
    "task_id": "HumanEval/148",
    "Failed": "Exception occurred during when querying the LLM -- BadRequestError : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
  },
  {
    "name": "sorted_list_sum",
    "task_id": "HumanEval/149",
    "Failed": "Exception occurred during when querying the LLM -- BadRequestError : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
  },
  {
    "name": "x_or_y",
    "task_id": "HumanEval/150",
    "Failed": "Exception occurred during when querying the LLM -- BadRequestError : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
  },
  {
    "name": "double_the_difference",
    "task_id": "HumanEval/151",
    "Failed": "Exception occurred during when querying the LLM -- BadRequestError : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
  },
  {
    "name": "compare",
    "task_id": "HumanEval/152",
    "Failed": "Exception occurred during when querying the LLM -- BadRequestError : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
  },
  {
    "name": "Strongest_Extension",
    "task_id": "HumanEval/153",
    "Failed": "Exception occurred during when querying the LLM -- BadRequestError : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
  },
  {
    "name": "cycpattern_check",
    "task_id": "HumanEval/154",
    "Failed": "Exception occurred during when querying the LLM -- BadRequestError : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
  },
  {
    "name": "even_odd_count",
    "task_id": "HumanEval/155",
    "Failed": "Exception occurred during when querying the LLM -- BadRequestError : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
  },
  {
    "name": "right_angle_triangle",
    "task_id": "HumanEval/157",
    "Failed": "Exception occurred during when querying the LLM -- BadRequestError : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
  },
  {
    "name": "find_max",
    "task_id": "HumanEval/158",
    "Failed": "Exception occurred during when querying the LLM -- BadRequestError : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
  },
  {
    "name": "eat",
    "task_id": "HumanEval/159",
    "Failed": "Exception occurred during when querying the LLM -- BadRequestError : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
  },
  {
    "name": "solve",
    "task_id": "HumanEval/161",
    "Failed": "Exception occurred during when querying the LLM -- BadRequestError : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
  },
  {
    "name": "string_to_md5",
    "task_id": "HumanEval/162",
    "Failed": "Exception occurred during when querying the LLM -- BadRequestError : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
  },
  {
    "name": "generate_integers",
    "task_id": "HumanEval/163",
    "Failed": "Exception occurred during when querying the LLM -- BadRequestError : Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
  }
]